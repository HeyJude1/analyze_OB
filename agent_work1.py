#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
OpenBLASä¼˜åŒ–åˆ†æ - çœŸæ­£çš„LangGraph Supervisorå·¥ä½œæµ
åŸºäºå®˜æ–¹Supervisoræ¨¡å¼å®ç°æ™ºèƒ½å†³ç­–çš„å¤šAgentåä½œç³»ç»Ÿ
"""

import os
import time
import json
from typing import Dict, List, Literal
from typing_extensions import TypedDict
from datetime import datetime
from dotenv import load_dotenv

from langgraph.graph import StateGraph, START, END
from langchain.output_parsers import StructuredOutputParser, ResponseSchema

from agent1 import (
    AgentFactory,
    FileManager,
    supervisor_router,
    create_supervisor_agent
)

load_dotenv()


# ===== å·¥ä½œæµçŠ¶æ€ =====
class WorkState(TypedDict):
    """å·¥ä½œæµçŠ¶æ€"""
    # åŸºç¡€ä»»åŠ¡ä¿¡æ¯
    report_folder: str
    algorithms: List[str]
    current_algorithm: str
    current_phase: str
    
    # æ‰§è¡ŒçŠ¶æ€è·Ÿè¸ª
    completed_algorithms: List[str]
    completed_tasks: List[str]
    skipped_algorithms: List[str]
    
    # é”™è¯¯å’Œé‡è¯•ç®¡ç†
    errors: List[str]
    retry_count: int
    last_error: str
    
    # æ™ºèƒ½å†³ç­–æ”¯æŒ
    execution_history: List[Dict]
    performance_metrics: Dict
    resource_status: Dict
    
    # ä»»åŠ¡ä¾èµ–çŠ¶æ€
    scout_completed: bool
    available_algorithms: List[str]
    pending_files_count: int
    pending_summary_count: int
    
    # è´¨é‡æ§åˆ¶
    quality_scores: Dict[str, float]
    confidence_levels: Dict[str, float]


# ===== å·¥ä½œæµ =====
class Workflow:
    """å·¥ä½œæµ"""
    
    def __init__(self):
        self.factory = AgentFactory()
        self.file_mgr = FileManager()
        
        # åˆ›å»ºæ™ºèƒ½ä¸“å®¶Agents
        self.scout = self.factory.create_scout_agent()
        self.analyzer = self.factory.create_analyzer_agent()
        self.individual_summarizer = self.factory.create_individual_summarizer_agent()
        self.final_summarizer = self.factory.create_final_summarizer_agent()
        
        # æ„å»ºæ™ºèƒ½å·¥ä½œæµ
        self.workflow = self._build_intelligent_workflow()
        
        # æ€§èƒ½ç›‘æ§
        self.start_time = None
        self.decision_count = 0
    
    def _build_intelligent_workflow(self) -> StateGraph:
        """æ„å»ºçœŸæ­£çš„Supervisoræ™ºèƒ½å·¥ä½œæµ"""
        workflow = StateGraph(WorkState)
        
        # æ·»åŠ æ ¸å¿ƒèŠ‚ç‚¹
        workflow.add_node("supervisor", self.supervisor_node)
        workflow.add_node("scout_agent", self.scout_agent_node)
        workflow.add_node("analyzer_agent", self.analyzer_agent_node)
        workflow.add_node("individual_summarizer_agent", self.individual_summarizer_agent_node)
        workflow.add_node("final_summarizer_agent", self.final_summarizer_agent_node)
        
        # è®¾ç½®å…¥å£ - ç›´æ¥è¿›å…¥Supervisorè¿›è¡Œæ™ºèƒ½å†³ç­–
        workflow.add_edge(START, "supervisor")
        
        # ğŸ§  æ ¸å¿ƒï¼šSupervisoræ™ºèƒ½è·¯ç”±å†³ç­–
        workflow.add_conditional_edges(
            "supervisor",
            supervisor_router,  # ä½¿ç”¨LLMè¿›è¡Œæ™ºèƒ½å†³ç­–
            {
                "scout": "scout_agent",
                "analyzer": "analyzer_agent",
                "individual_summarizer": "individual_summarizer_agent",
                "final_summarizer": "final_summarizer_agent",
                "FINISH": END
            }
        )
        
        # æ‰€æœ‰Agentå®Œæˆåéƒ½å›åˆ°Supervisoré‡æ–°è¯„ä¼°
        for agent_node in ["scout_agent", "analyzer_agent", 
                          "individual_summarizer_agent", "final_summarizer_agent"]:
            workflow.add_edge(agent_node, "supervisor")
        
        return workflow.compile()
    
    def supervisor_node(self, state: WorkState) -> WorkState:
        """æ™ºèƒ½SupervisorèŠ‚ç‚¹ - çŠ¶æ€åˆ†æå’Œå†³ç­–å‡†å¤‡"""
        self.decision_count += 1
        
        print(f"\nğŸ§  [Supervisor #{self.decision_count}] æ™ºèƒ½åˆ†æå½“å‰çŠ¶æ€...")
        
        # æ›´æ–°æ‰§è¡Œæ—¶é•¿
        if self.start_time:
            execution_time = time.time() - self.start_time
            state["performance_metrics"] = state.get("performance_metrics", {})
            state["performance_metrics"]["execution_time"] = execution_time
        
        # æ™ºèƒ½çŠ¶æ€åˆ†æ
        completed_count = len(state.get("completed_algorithms", []))
        total_count = len(state.get("algorithms", []))
        error_count = len(state.get("errors", []))
        
        print(f"ğŸ“Š è¿›åº¦åˆ†æ: {completed_count}/{total_count} ç®—å­å®Œæˆ")
        print(f"âš ï¸ é”™è¯¯ç»Ÿè®¡: {error_count} ä¸ªé”™è¯¯")
        print(f"ğŸ”„ å½“å‰ç®—å­: {state.get('current_algorithm', 'None')}")
        print(f"ğŸ“ å½“å‰é˜¶æ®µ: {state.get('current_phase', 'None')}")
        
        # è®°å½•å†³ç­–ä¸Šä¸‹æ–‡
        decision_context = {
            "decision_id": self.decision_count,
            "state_snapshot": {
                "completed_algorithms": state.get("completed_algorithms", []),
                "current_algorithm": state.get("current_algorithm"),
                "current_phase": state.get("current_phase"),
                "retry_count": state.get("retry_count", 0),
                "error_count": error_count
            }
        }
        
        # è®°å½•Supervisorå†³ç­–æ—¥å¿—
        self.file_mgr.log_supervisor_decision(
            state["report_folder"], 
            decision_context
        )
        
        return state
    
    def scout_agent_node(self, state: WorkState) -> WorkState:
        """Scout AgentèŠ‚ç‚¹ - æ™ºèƒ½æ–‡ä»¶å‘ç°"""
        print(f"ğŸ” [Scout Agent] å¼€å§‹æ™ºèƒ½ç®—å­å‘ç°...")
        
        try:
            state["current_phase"] = "scout"
            
            # è°ƒç”¨Scout Agent
            scout_input = """æ‰§è¡Œæ™ºèƒ½ç®—å­å‘ç°ä»»åŠ¡ï¼š
            
ğŸ¯ ä»»åŠ¡ç›®æ ‡ï¼š
- æ‰«æ /home/dgc/mjs/project/analyze_OB/openblas-output/GENERIC/kernel ç›®å½•
- æ™ºèƒ½è¯†åˆ«å’Œåˆ†ç±»æ‰€æœ‰ç®—å­ç§ç±»
- ç”Ÿæˆé«˜è´¨é‡çš„ç®—å­åˆ†ç±»æŠ¥å‘Š
- è¯„ä¼°åˆ†ç±»å‡†ç¡®åº¦å’Œç½®ä¿¡åº¦

ğŸ§  æ™ºèƒ½è¦æ±‚ï¼š
- æ ¹æ®ç›®å½•å¤§å°è‡ªåŠ¨è°ƒæ•´æ‰«æç­–ç•¥
- ä½¿ç”¨æ¨¡å¼åŒ¹é…å’Œå¯å‘å¼è§„åˆ™
- å¤„ç†è¾¹ç•Œæƒ…å†µå’Œå¼‚å¸¸æ–‡ä»¶
- æä¾›åˆ†ç±»ç½®ä¿¡åº¦è¯„åˆ†

è¯·å¼€å§‹æ™ºèƒ½æ‰«æå’Œåˆ†ç±»ã€‚"""
            
            result = self.scout.invoke({"input": scout_input})
            time.sleep(2)  # APIé™åˆ¶ç¼“è§£
            
            # è§£æç»“æœå¹¶ä¿å­˜
            discovery_data = self._extract_json_from_result(result)
            
            if "algorithms" in discovery_data:
                # æ›´æ–°çŠ¶æ€
                algorithms = [algo["algorithm"] for algo in discovery_data["algorithms"]]
                state["algorithms"] = algorithms
                state["available_algorithms"] = algorithms.copy()
                state["scout_completed"] = True
                state["completed_tasks"].append("scout_discovery")
                
                # ä¿å­˜å‘ç°ç»“æœ
                discovery_path = self.file_mgr.get_discovery_output_path(
                    state["report_folder"], "all_algorithms"
                )
                success = self.file_mgr.save_content(
                    discovery_path, 
                    json.dumps(discovery_data, ensure_ascii=False, indent=2)
                )
                
                if success:
                    print(f"âœ… Scoutå®Œæˆ: å‘ç° {len(algorithms)} ç§ç®—å­")
                    
                    # æ›´æ–°è´¨é‡è¯„åˆ†
                    confidence = discovery_data.get("confidence_score", 0.8)
                    state["confidence_levels"] = state.get("confidence_levels", {})
                    state["confidence_levels"]["scout"] = confidence
                else:
                    raise Exception("ä¿å­˜å‘ç°ç»“æœå¤±è´¥")
            else:
                raise Exception("Scoutç»“æœæ ¼å¼é”™è¯¯")
                
        except Exception as e:
            error_msg = f"Scout Agentå¤±è´¥: {str(e)}"
            print(f"âŒ {error_msg}")
            state["errors"].append(error_msg)
            state["last_error"] = error_msg
            state["retry_count"] = state.get("retry_count", 0) + 1
        
        return state
    
    def analyzer_agent_node(self, state: WorkState) -> WorkState:
        """Analyzer AgentèŠ‚ç‚¹ - æ™ºèƒ½ä»£ç åˆ†æ"""
        current_algo = state.get("current_algorithm")
        if not current_algo:
            # æ™ºèƒ½é€‰æ‹©ä¸‹ä¸€ä¸ªå¾…åˆ†æçš„ç®—å­
            available = state.get("available_algorithms", [])
            completed = state.get("completed_algorithms", [])
            remaining = [algo for algo in available if algo not in completed]
            
            if remaining:
                current_algo = remaining[0]
                state["current_algorithm"] = current_algo
            else:
                state["errors"].append("æ²¡æœ‰å¯åˆ†æçš„ç®—å­")
                return state
        
        print(f"ğŸ“Š [Analyzer Agent] æ™ºèƒ½åˆ†æç®—å­: {current_algo}")
        
        try:
            state["current_phase"] = "analyzer"
            
            # è·å–ç®—å­æ–‡ä»¶åˆ—è¡¨
            discovery_path = self.file_mgr.get_discovery_output_path(
                state["report_folder"], "all_algorithms"
            )
            
            with open(discovery_path, 'r', encoding='utf-8') as f:
                discovery_data = json.load(f)
            
            # æ‰¾åˆ°å½“å‰ç®—å­çš„æ–‡ä»¶
            target_files = []
            for algo_info in discovery_data["algorithms"]:
                if algo_info["algorithm"] == current_algo:
                    target_files = algo_info["files"]
                    break
            
            if not target_files:
                raise Exception(f"æœªæ‰¾åˆ°{current_algo}çš„æ–‡ä»¶åˆ—è¡¨")
            
            # æ™ºèƒ½åˆ†ææ¯ä¸ªæ–‡ä»¶
            analysis_path = self.file_mgr.get_analysis_output_path(
                state["report_folder"], current_algo
            )
            
            all_analyses = []
            total_files = len(target_files)
            
            for i, file_info in enumerate(target_files):
                file_name = file_info["name"]
                print(f"  ğŸ“„ æ™ºèƒ½åˆ†æ {i+1}/{total_files}: {file_name}")
                
                analyzer_input = f"""æ‰§è¡Œ{current_algo}ç®—å­æ–‡ä»¶çš„æ™ºèƒ½æ·±åº¦åˆ†æï¼š

ğŸ“ ç›®æ ‡æ–‡ä»¶: {file_name}

ğŸ§  æ™ºèƒ½åˆ†æè¦æ±‚ï¼š
- æ ¹æ®ä»£ç å¤æ‚åº¦è‡ªåŠ¨è°ƒæ•´åˆ†ææ·±åº¦
- è¯†åˆ«æ‰€æœ‰ä¼˜åŒ–ç­–ç•¥å¹¶è¯„ä¼°ç½®ä¿¡åº¦
- æä¾›ä»£ç å¤æ‚åº¦å’Œä¼˜åŒ–æ½œåŠ›è¯„ä¼°
- ç”Ÿæˆé«˜è´¨é‡çš„åˆ†ææŠ¥å‘Š

ğŸ¯ åˆ†ææ¡†æ¶ï¼š
- ç®—æ³•å±‚ï¼šè®¡ç®—é€»è¾‘ã€æ•°æ®ç»“æ„ã€ç®—æ³•è®¾è®¡ä¼˜åŒ–
- ä»£ç å±‚ï¼šå¾ªç¯ã€åˆ†æ”¯ã€å†…å­˜è®¿é—®ã€ç¼–è¯‘å™¨ä¼˜åŒ–  
- æŒ‡ä»¤å±‚ï¼šSIMDã€å‘é‡åŒ–ã€ç‰¹æ®ŠæŒ‡ä»¤ã€æ±‡ç¼–ä¼˜åŒ–

è¯·å¼€å§‹æ™ºèƒ½æ·±åº¦åˆ†æã€‚"""
                
                result = self.analyzer.invoke({"input": analyzer_input})
                time.sleep(2)
                
                file_analysis = self._extract_json_from_result(result)
                all_analyses.append(file_analysis)
                
                # å¢é‡ä¿å­˜
                analysis_data = {
                    "algorithm": current_algo,
                    "total_files": total_files,
                    "analyzed_files": len(all_analyses),
                    "individual_analyses": all_analyses,
                    "timestamp": datetime.now().isoformat()
                }
                
                self.file_mgr.save_content(
                    analysis_path, 
                    json.dumps(analysis_data, ensure_ascii=False, indent=2)
                )
            
            # æ›´æ–°çŠ¶æ€
            state["completed_tasks"].append(f"analyze_{current_algo}")
            state["pending_files_count"] = state.get("pending_files_count", 0) - total_files
            
            # è®¡ç®—å¹³å‡è´¨é‡åˆ†æ•°
            complexity_scores = [a.get("complexity_score", 5) for a in all_analyses if "complexity_score" in a]
            avg_complexity = sum(complexity_scores) / len(complexity_scores) if complexity_scores else 5
            
            state["quality_scores"] = state.get("quality_scores", {})
            state["quality_scores"][f"analyzer_{current_algo}"] = min(avg_complexity / 10, 1.0)
            
            print(f"âœ… Analyzerå®Œæˆ: {current_algo} ({total_files} ä¸ªæ–‡ä»¶)")
            
        except Exception as e:
            error_msg = f"Analyzer Agentå¤±è´¥ ({current_algo}): {str(e)}"
            print(f"âŒ {error_msg}")
            state["errors"].append(error_msg)
            state["last_error"] = error_msg
            state["retry_count"] = state.get("retry_count", 0) + 1
        
        return state
    
    def individual_summarizer_agent_node(self, state: WorkState) -> WorkState:
        """Individual Summarizer AgentèŠ‚ç‚¹ - æ™ºèƒ½ç­–ç•¥æ•´åˆ"""
        current_algo = state.get("current_algorithm")
        if not current_algo:
            state["errors"].append("Individual Summarizer: æ²¡æœ‰æŒ‡å®šç®—å­")
            return state
        
        print(f"ğŸ“ [Individual Summarizer] æ™ºèƒ½æ•´åˆç®—å­: {current_algo}")
        
        try:
            state["current_phase"] = "individual_summary"
            
            # è¯»å–åˆ†æç»“æœ
            analysis_path = self.file_mgr.get_analysis_output_path(
                state["report_folder"], current_algo
            )
            
            with open(analysis_path, 'r', encoding='utf-8') as f:
                analysis_data = json.load(f)
            
            summarizer_input = f"""æ‰§è¡Œ{current_algo}ç®—å­çš„æ™ºèƒ½ç­–ç•¥æ•´åˆï¼š

ğŸ“Š è¾“å…¥æ•°æ®ï¼š
{json.dumps(analysis_data, ensure_ascii=False, indent=2)}

ğŸ§  æ™ºèƒ½æ•´åˆè¦æ±‚ï¼š
- è‡ªåŠ¨è¯†åˆ«ç›¸ä¼¼å’Œé‡å¤çš„ä¼˜åŒ–ç­–ç•¥
- æ™ºèƒ½åˆå¹¶ç­–ç•¥ï¼Œä¿æŒæœ€ä½³æè¿°å’Œå‘½å
- è¯„ä¼°æ•´åˆè´¨é‡å¹¶æä¾›æ”¹è¿›å»ºè®®
- æ¶ˆé™¤å†—ä½™ï¼Œæå‡ç­–ç•¥åº“çš„ç®€æ´æ€§

ğŸ¯ æ•´åˆç›®æ ‡ï¼š
- ç”Ÿæˆé«˜è´¨é‡çš„ç®—å­ä¼˜åŒ–ç­–ç•¥æ€»ç»“
- ç»Ÿä¸€å‘½åè§„èŒƒï¼Œæå‡å¯è¯»æ€§
- ä¿ç•™å…³é”®å·®å¼‚ï¼Œé¿å…è¿‡åº¦ç®€åŒ–

è¯·å¼€å§‹æ™ºèƒ½ç­–ç•¥æ•´åˆã€‚"""
            
            result = self.individual_summarizer.invoke({"input": summarizer_input})
            time.sleep(2)
            
            summary_data = self._extract_json_from_result(result)
            
            # ä¿å­˜æ€»ç»“ç»“æœ
            summary_path = self.file_mgr.get_individual_summary_path(
                state["report_folder"], current_algo
            )
            
            success = self.file_mgr.save_content(
                summary_path,
                json.dumps(summary_data, ensure_ascii=False, indent=2)
            )
            
            if success:
                # æ›´æ–°çŠ¶æ€
                state["completed_tasks"].append(f"individual_summary_{current_algo}")
                state["completed_algorithms"].append(current_algo)
                state["pending_summary_count"] = state.get("pending_summary_count", 0) - 1
                
                # è®°å½•è´¨é‡åˆ†æ•°
                quality_score = summary_data.get("quality_score", 0.8)
                state["quality_scores"] = state.get("quality_scores", {})
                state["quality_scores"][f"summary_{current_algo}"] = quality_score
                
                print(f"âœ… Individual Summaryå®Œæˆ: {current_algo}")
                
                # é‡ç½®å½“å‰ç®—å­ï¼Œè®©Supervisoré€‰æ‹©ä¸‹ä¸€ä¸ª
                state["current_algorithm"] = None
                state["retry_count"] = 0
            else:
                raise Exception("ä¿å­˜æ€»ç»“ç»“æœå¤±è´¥")
                
        except Exception as e:
            error_msg = f"Individual Summarizerå¤±è´¥ ({current_algo}): {str(e)}"
            print(f"âŒ {error_msg}")
            state["errors"].append(error_msg)
            state["last_error"] = error_msg
            state["retry_count"] = state.get("retry_count", 0) + 1
        
        return state
    
    def final_summarizer_agent_node(self, state: WorkState) -> WorkState:
        """Final Summarizer AgentèŠ‚ç‚¹ - æ™ºèƒ½è·¨ç®—å­æ€»ç»“"""
        print(f"ğŸ¯ [Final Summarizer] æ™ºèƒ½è·¨ç®—å­æ€»ç»“...")
        
        try:
            state["current_phase"] = "final_summary"
            
            completed_algorithms = state.get("completed_algorithms", [])
            if not completed_algorithms:
                raise Exception("æ²¡æœ‰å·²å®Œæˆçš„ç®—å­å¯ä¾›æ€»ç»“")
            
            # æ”¶é›†æ‰€æœ‰ç®—å­çš„æ€»ç»“æ•°æ®
            all_summaries = {}
            for algo in completed_algorithms:
                summary_path = self.file_mgr.get_individual_summary_path(
                    state["report_folder"], algo
                )
                
                with open(summary_path, 'r', encoding='utf-8') as f:
                    all_summaries[algo] = json.load(f)
            
            final_input = f"""æ‰§è¡ŒOpenBLASä¼˜åŒ–ç­–ç•¥çš„æ™ºèƒ½è·¨ç®—å­æ€»ç»“ï¼š

ğŸ“Š è¾“å…¥æ•°æ® - æ‰€æœ‰ç®—å­æ€»ç»“ï¼š
{json.dumps(all_summaries, ensure_ascii=False, indent=2)}

ğŸ§  æ™ºèƒ½æ€»ç»“è¦æ±‚ï¼š
- è¯†åˆ«è·¨ç®—å­çš„é€šç”¨ä¼˜åŒ–æ¨¡å¼å’Œè§„å¾‹
- æ„å»ºå®Œæ•´çš„ä¼˜åŒ–ç­–ç•¥åˆ†ç±»ä½“ç³»
- æä¾›ç­–ç•¥è¦†ç›–åº¦åˆ†æå’Œè´¨é‡è¯„ä¼°
- ç”Ÿæˆå®ç”¨çš„æœ€ä½³å®è·µå»ºè®®

ğŸ¯ æ€»ç»“ç›®æ ‡ï¼š
- æ„å»ºOpenBLASä¼˜åŒ–ç­–ç•¥çŸ¥è¯†åº“
- å‘ç°é€šç”¨ä¼˜åŒ–è§„å¾‹å’Œæœ€ä½³å®è·µ
- æä¾›ç­–ç•¥åº”ç”¨æŒ‡å¯¼å’Œå»ºè®®
- è¯„ä¼°ä¼˜åŒ–ç­–ç•¥çš„å®Œæ•´æ€§å’Œå®ç”¨æ€§

è¯·å¼€å§‹æ™ºèƒ½è·¨ç®—å­æ€»ç»“ã€‚"""
            
            result = self.final_summarizer.invoke({"input": final_input})
            time.sleep(2)
            
            final_data = self._extract_json_from_result(result)
            
            # ä¿å­˜æœ€ç»ˆæ€»ç»“
            final_path = self.file_mgr.get_final_summary_path(state["report_folder"])
            success = self.file_mgr.save_content(
                final_path,
                json.dumps(final_data, ensure_ascii=False, indent=2)
            )
            
            if success:
                state["completed_tasks"].append("final_summary")
                
                # è®°å½•æœ€ç»ˆè´¨é‡åˆ†æ•°
                coverage_score = len(completed_algorithms) / len(state.get("algorithms", [1]))
                state["quality_scores"] = state.get("quality_scores", {})
                state["quality_scores"]["final_summary"] = coverage_score
                
                print(f"âœ… Final Summaryå®Œæˆ: æ•´åˆäº† {len(completed_algorithms)} ä¸ªç®—å­")
            else:
                raise Exception("ä¿å­˜æœ€ç»ˆæ€»ç»“å¤±è´¥")
                
        except Exception as e:
            error_msg = f"Final Summarizerå¤±è´¥: {str(e)}"
            print(f"âŒ {error_msg}")
            state["errors"].append(error_msg)
            state["last_error"] = error_msg
            state["retry_count"] = state.get("retry_count", 0) + 1
        
        return state
    
    def _extract_json_from_result(self, result):
        """ä»Agentç»“æœä¸­æå–JSON - å¢å¼ºç‰ˆ"""
        try:
            if isinstance(result, dict) and "output" in result:
                output_content = result["output"]
                
                # å°è¯•å¤šç§JSONæå–æ–¹å¼
                if "```json" in output_content:
                    json_start = output_content.find("```json") + 7
                    json_end = output_content.find("```", json_start)
                    json_str = output_content[json_start:json_end].strip()
                elif "```" in output_content:
                    json_start = output_content.find("```") + 3
                    json_end = output_content.find("```", json_start)
                    json_str = output_content[json_start:json_end].strip()
                else:
                    # å°è¯•ç›´æ¥è§£ææ•´ä¸ªè¾“å‡º
                    json_str = output_content.strip()
                
                return json.loads(json_str)
                
            elif isinstance(result, dict):
                return result
            else:
                return {"error": "æ— æ³•è§£æç»“æœ", "raw": str(result)}
                
        except json.JSONDecodeError as e:
            return {"error": f"JSONè§£æå¤±è´¥: {str(e)}", "raw": str(result)}
        except Exception as e:
            return {"error": f"ç»“æœæå–å¤±è´¥: {str(e)}", "raw": str(result)}
    
    def run(self, algorithms: List[str] = None) -> dict:
        """è¿è¡Œæ™ºèƒ½Supervisorå·¥ä½œæµ"""
        self.start_time = time.time()
        
        # åˆ›å»ºæŠ¥å‘Šæ–‡ä»¶å¤¹
        report_folder = f"results/{time.strftime('%Y%m%d_%H%M%S')}_supervisor"
        self.file_mgr.ensure_directories(report_folder)
        
        print(f"ğŸ§  å¯åŠ¨çœŸæ­£çš„Supervisorå·¥ä½œæµ")
        print(f"ğŸ“ æŠ¥å‘Šæ–‡ä»¶å¤¹: {report_folder}")
        
        # åˆå§‹åŒ–æ™ºèƒ½çŠ¶æ€
        initial_state = {
            "report_folder": report_folder,
            "algorithms": algorithms or [],
            "current_algorithm": None,
            "current_phase": "initialization",
            
            "completed_algorithms": [],
            "completed_tasks": [],
            "skipped_algorithms": [],
            
            "errors": [],
            "retry_count": 0,
            "last_error": "",
            
            "execution_history": [],
            "performance_metrics": {},
            "resource_status": {"api_status": "æ­£å¸¸", "file_system_status": "æ­£å¸¸"},
            
            "scout_completed": False,
            "available_algorithms": [],
            "pending_files_count": 0,
            "pending_summary_count": 0,
            
            "quality_scores": {},
            "confidence_levels": {}
        }
        
        try:
            # ğŸ§  å¯åŠ¨æ™ºèƒ½å·¥ä½œæµ - Supervisorå°†æ™ºèƒ½å†³ç­–æ¯ä¸€æ­¥
            final_state = self.workflow.invoke(initial_state)
            
            # è®¡ç®—æœ€ç»ˆç»Ÿè®¡
            execution_time = time.time() - self.start_time
            completed_count = len(final_state.get("completed_algorithms", []))
            total_algorithms = len(final_state.get("algorithms", []))
            error_count = len(final_state.get("errors", []))
            
            # ç”Ÿæˆæ™ºèƒ½åˆ†ææŠ¥å‘Š
            performance_report = {
                "execution_time": execution_time,
                "decision_count": self.decision_count,
                "completed_algorithms": completed_count,
                "total_algorithms": total_algorithms,
                "success_rate": completed_count / max(total_algorithms, 1),
                "error_count": error_count,
                "quality_scores": final_state.get("quality_scores", {}),
                "confidence_levels": final_state.get("confidence_levels", {}),
                "avg_quality": sum(final_state.get("quality_scores", {}).values()) / max(len(final_state.get("quality_scores", {})), 1)
            }
            
            print(f"\nğŸ¯ Supervisorå·¥ä½œæµå®Œæˆ")
            print(f"â±ï¸ æ‰§è¡Œæ—¶é—´: {execution_time:.1f}ç§’")
            print(f"ğŸ§  æ™ºèƒ½å†³ç­–æ¬¡æ•°: {self.decision_count}")
            print(f"âœ… æˆåŠŸç‡: {performance_report['success_rate']:.1%}")
            print(f"ğŸ“Š å¹³å‡è´¨é‡åˆ†æ•°: {performance_report['avg_quality']:.2f}")
            
            return {
                "success": completed_count > 0,
                "completed_algorithms": final_state.get("completed_algorithms", []),
                "final_summary_completed": "final_summary" in final_state.get("completed_tasks", []),
                "report_folder": report_folder,
                "errors": final_state.get("errors", []),
                "performance_report": performance_report,
                "supervisor_decisions": self.decision_count
            }
            
        except Exception as e:
            error_msg = f"Supervisorå·¥ä½œæµæ‰§è¡Œå¤±è´¥: {str(e)}"
            print(f"âŒ {error_msg}")
            
            return {
                "success": False,
                "completed_algorithms": [],
                "final_summary_completed": False,
                "report_folder": report_folder,
                "errors": [error_msg],
                "performance_report": {"execution_time": time.time() - self.start_time},
                "supervisor_decisions": self.decision_count
            }


def main():
    """ä¸»å‡½æ•° - çœŸæ­£çš„Supervisoræ¨¡å¼æ¼”ç¤º"""
    if not os.getenv("DASHSCOPE_API_KEY"):
        print("âŒ é”™è¯¯: è¯·è®¾ç½®DASHSCOPE_API_KEYç¯å¢ƒå˜é‡")
        return
    
    if not os.path.exists("/home/dgc/mjs/project/analyze_OB/openblas-output/GENERIC/kernel"):
        print("âŒ é”™è¯¯: æœªæ‰¾åˆ°openblas-output/GENERIC/kernelç›®å½•")
        return
    
    workflow = Workflow()
    
    print("ğŸ§  OpenBLASä¼˜åŒ–åˆ†æ - çœŸæ­£çš„Supervisoræ¨¡å¼")
    print("1. å¿«é€Ÿåˆ†æ (gemm, axpy, dot) - Supervisoræ™ºèƒ½è°ƒåº¦")
    print("2. å…¨éƒ¨åˆ†æ (æ™ºèƒ½å‘ç°æ‰€æœ‰ç®—å­) - å®Œå…¨è‡ªä¸»å†³ç­–")
    print("3. è‡ªå®šä¹‰ç®—å­åˆ—è¡¨ - Supervisorä¼˜åŒ–æ‰§è¡Œ")
    
    choice = input("è¯·é€‰æ‹© (1-3): ").strip()
    
    if choice == "1":
        algorithms = ['gemm', 'axpy', 'dot']
        print("ğŸ§  Supervisorå°†æ™ºèƒ½è°ƒåº¦å¿«é€Ÿåˆ†æ...")
    elif choice == "2":
        print("ğŸ§  Supervisorå°†è‡ªä¸»å‘ç°å¹¶åˆ†ææ‰€æœ‰ç®—å­...")
        algorithms = None  # è®©Supervisorè‡ªä¸»å‘ç°
    elif choice == "3":
        algo_input = input("è¯·è¾“å…¥ç®—å­åˆ—è¡¨ (ç”¨é€—å·åˆ†éš”): ").strip()
        algorithms = [algo.strip() for algo in algo_input.split(",") if algo.strip()]
        print(f"ğŸ§  Supervisorå°†æ™ºèƒ½åˆ†æ: {algorithms}")
    else:
        print("âŒ æ— æ•ˆé€‰æ‹©")
        return
    
    try:
        print(f"\nğŸš€ å¯åŠ¨çœŸæ­£çš„Supervisorå·¥ä½œæµ...")
        result = workflow.run(algorithms)
        
        print(f"\nğŸ“Š Supervisoråˆ†æå®Œæˆ")
        print(f"âœ… æˆåŠŸ: {result['success']}")
        print(f"ğŸ“ æŠ¥å‘Šä½ç½®: {result['report_folder']}")
        print(f"ğŸ§  æ™ºèƒ½å†³ç­–æ¬¡æ•°: {result['supervisor_decisions']}")
        
        if result["performance_report"]:
            perf = result["performance_report"]
            print(f"â±ï¸ æ‰§è¡Œæ—¶é—´: {perf.get('execution_time', 0):.1f}ç§’")
            print(f"ğŸ“ˆ æˆåŠŸç‡: {perf.get('success_rate', 0):.1%}")
            print(f"ğŸ“Š å¹³å‡è´¨é‡: {perf.get('avg_quality', 0):.2f}")
        
        if result["errors"]:
            print(f"\nâš ï¸ é”™è¯¯: {len(result['errors'])} ä¸ª")
            for error in result["errors"][-3:]:  # æ˜¾ç¤ºæœ€å3ä¸ªé”™è¯¯
                print(f"  - {error}")
        
        if result["final_summary_completed"]:
            final_path = FileManager.get_final_summary_path(result["report_folder"])
            print(f"\nğŸ‰ æ™ºèƒ½åˆ†æå®Œæˆï¼æŸ¥çœ‹æœ€ç»ˆæŠ¥å‘Š: {final_path}")
        
    except Exception as e:
        print(f"\nâŒ Supervisorå·¥ä½œæµæ‰§è¡Œå¤±è´¥: {str(e)}")


if __name__ == "__main__":
    main()
