[
  {
    "problem_type": "geometry",
    "language": "cpp",
    "name": "13_geometry_closest_pair_2d",
    "parallelism_model": "omp",
    "prompt": "#include <omp.h>\n\nstruct Point {\n\tdouble x, y;\n};\n\ndouble distance(Point const& p1, Point const& p2) {\n\treturn std::sqrt(std::pow(p2.x-p1.x, 2) + std::pow(p2.y-p1.y, 2));\n}\n\n/* Return the distance between the closest two points in the vector points.\n   Use OpenMP to compute in parallel.\n   Example: \n\n   input: [{2, 3}, {12, 30}, {40, 50}, {5, 1}, {12, 10}, {3, 4}]\n   output: 1.41421\n*/\ndouble closestPair(std::vector<Point> const& points) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n\tdouble min_dist = std::numeric_limits<double>::max();\n\t#pragma omp parallel for schedule(guided) reduction(min:min_dist)\n\tfor (size_t i = 0; i < points.size(); ++i) {\n\t\tfor (size_t j = i + 1; j < points.size(); ++j) {\n\t\t\tdouble d = distance(points[i], points[j]);\n\t\t\tif (d < min_dist) {\n\t\t\t\tmin_dist = d;\n\t\t\t}\n\t\t}\n\t}\n\treturn min_dist;\n}\n"
    ]
  },
  {
    "problem_type": "geometry",
    "language": "cpp",
    "name": "13_geometry_closest_pair_2d",
    "parallelism_model": "cuda",
    "prompt": "struct Point {\n\tdouble x, y;\n};\n\n__device__ double distanceBetweenPoints(Point const& p1, Point const& p2) {\n\treturn sqrt(pow(p2.x-p1.x, 2) + pow(p2.y-p1.y, 2));\n}\n\n/* Compute the distance between the closest two points in the vector points.\n   Store the result in distance.\n   Use CUDA to compute in parallel. The kernel is launched with at least as many threads as points.\n   Example: \n\n   input: [{2, 3}, {12, 30}, {40, 50}, {5, 1}, {12, 10}, {3, 4}]\n   output: 1.41421\n*/\n__global__ void closestPair(const Point *points, size_t numPoints, double *distance) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n{\n    extern __shared__ Point sharedPoints[];\n    int i = threadIdx.x;\n    int j = threadIdx.y;\n    int gridSize = blockDim.x * blockDim.y;\n    int idx = i * blockDim.y + j;\n\n    // Load points into shared memory\n    if (idx < numPoints) {\n        sharedPoints[idx] = points[idx];\n    }\n    __syncthreads();\n\n    double minDist = INFINITY;\n\n    // Iterate over all unique pairs in the block\n    for (int k = threadIdx.x; k < numPoints; k += blockDim.x) {\n        for (int l = threadIdx.y; l < numPoints; l += blockDim.y) {\n            if (k != l) {\n                double dist = distanceBetweenPoints(points[k], points[l]);\n                if (dist < minDist) {\n                    minDist = dist;\n                }\n            }\n        }\n    }\n\n    // Reduce within the block\n    extern __shared__ double sharedDists[];\n    sharedDists[threadIdx.x] = minDist;\n    __syncthreads();\n\n    for (int s = blockDim.x / 2; s > 0; s /= 2) {\n        if (threadIdx.x < s) {\n            if (sharedDists[threadIdx.x + s] < sharedDists[threadIdx.x]) {\n                sharedDists[threadIdx.x] = sharedDists[threadIdx.x + s];\n            }\n        }\n        __syncthreads();\n    }\n\n    // Write the result from the first thread\n    if (threadIdx.x == 0 && threadIdx.y == 0) {\n        *distance = sharedDists[0];\n    }\n}\n"
    ]
  },
  {
    "problem_type": "geometry",
    "language": "cpp",
    "name": "13_geometry_closest_pair_2d",
    "parallelism_model": "serial",
    "prompt": "struct Point {\n\tdouble x, y;\n};\n\ndouble distance(Point const& p1, Point const& p2) {\n\treturn std::sqrt(std::pow(p2.x-p1.x, 2) + std::pow(p2.y-p1.y, 2));\n}\n\n/* Return the distance between the closest two points in the vector points.\n   Example: \n\n   input: [{2, 3}, {12, 30}, {40, 50}, {5, 1}, {12, 10}, {3, 4}]\n   output: 1.41421\n*/\ndouble closestPair(std::vector<Point> const& points) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n\tdouble min_dist = std::numeric_limits<double>::max();\n\tsize_t n = points.size();\n\t#pragma omp parallel for reduction(min:min_dist)\n\tfor (size_t i = 0; i < n; ++i) {\n\t\t__m512d x1 = _mm512_set1_pd(points[i].x);\n\t\t__m512d y1 = _mm512_set1_pd(points[i].y);\n\t\tfor (size_t j = i + 1; j < n; j += 8) {\n\t\t\t__m512d x2 = _mm512_loadu_pd(&points[j].x);\n\t\t\t__m512d y2 = _mm512_loadu_pd(&points[j].y);\n\t\t\t__m512d dx = _mm512_sub_pd(x2, x1);\n\t\t\t__m512d dy = _mm512_sub_pd(y2, y1);\n\t\t\t__m512d dist_sq = _mm512_fmadd_pd(dx, dx, _mm512_mul_pd(dy, dy));\n\t\t\t__m512d dist = _mm512_sqrt_pd(dist_sq);\n\t\t\tdouble dist_array[8];\n\t\t\t_mm512_storeu_pd(dist_array, dist);\n\t\t\tfor (int k = 0; k < 8 && j + k < n; ++k) {\n\t\t\t\tif (dist_array[k] < min_dist) {\n\t\t\t\t\tmin_dist = dist_array[k];\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn min_dist;\n}\n"
    ]
  },
  {
    "problem_type": "geometry",
    "language": "cpp",
    "name": "11_geometry_convex_hull_perimeter",
    "parallelism_model": "omp",
    "prompt": "#include <omp.h>\n\nstruct Point {\n\tdouble x, y;\n};\n\ndouble distance(Point const& p1, Point const& p2) {\n\treturn std::sqrt(std::pow(p2.x-p1.x, 2) + std::pow(p2.y-p1.y, 2));\n}\n\n/* Return the perimeter of the smallest convex polygon that contains all the points in the vector points.\n   Use OpenMP to compute in parallel.\n   Example:\n\n   input: [{0, 3}, {1, 1}, {2, 2}, {4, 4}, {0, 0}, {1, 2}, {3, 1}, {3, 3}]\n   output: 13.4477\n*/\ndouble convexHullPerimeter(std::vector<Point> const& points) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n\tdouble perimeter = 0.0;\n\t// TODO: Implement convex hull algorithm and calculate perimeter\n\treturn perimeter;\n}\n"
    ]
  },
  {
    "problem_type": "geometry",
    "language": "cpp",
    "name": "11_geometry_convex_hull_perimeter",
    "parallelism_model": "cuda",
    "prompt": "struct Point {\n\tdouble x, y;\n};\n\n__device__ double distance(Point const& p1, Point const& p2) {\n\treturn sqrt(pow(p2.x-p1.x, 2) + pow(p2.y-p1.y, 2));\n}\n\n/* Compute the perimeter of the smallest convex polygon that contains all the points in the vector points.\n   Store the result in perimeter.\n   Use CUDA to compute in parallel. The kernel is launched with at least as many threads as points.\n   Example:\n\n   input: [{0, 3}, {1, 1}, {2, 2}, {4, 4}, {0, 0}, {1, 2}, {3, 1}, {3, 3}]\n   output: 13.4477\n*/\n__global__ void convexHullPerimeter(const Point *points, size_t numPoints, double *perimeter) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n    extern __shared__ Point sharedPoints[];\n    int tid = threadIdx.x;\n    if (tid < numPoints) {\n        sharedPoints[tid] = points[tid];\n    }\n    __syncthreads();\n\n    // Use built-in sort to sort points by x-coordinate, then y-coordinate\n    if (tid == 0) {\n        thrust::sort(thrust::device, sharedPoints, sharedPoints + numPoints, \n            [] __device__ (const Point &a, const Point &b) {\n                return (a.x < b.x) || (a.x == b.x && a.y < b.y);\n            });\n    }\n    __syncthreads();\n\n    // Andrew's monotone chain algorithm to compute convex hull\n    Point *hull = sharedPoints + numPoints - tid; // reverse part of shared memory for hull\n    int n = 0; // length of hull\n\n    // Lower and upper parts\n    for (int i = tid; i < numPoints; i += blockDim.x) {\n        // Lower hull\n        while (n >= 2 && cross(hull[n-2], hull[n-1], points[i]) <= 0) n--;\n        hull[n++] = points[i];\n    }\n    __syncthreads();\n\n    int lowerSize = n;\n    for (int i = numPoints - tid - 1; i >= 0; i -= blockDim.x) {\n        // Upper hull\n        while (n >= 2 && cross(hull[n-2], hull[n-1], points[i]) <= 0) n--;\n        hull[n++] = points[i];\n    }\n    __syncthreads();\n\n    // Remove duplicates\n    if (tid == 0) {\n        hull = sharedPoints + numPoints;\n        n = 0;\n        for (int i = 0; i < numPoints; ++i) {\n            if (i > 0 && hull[i].x == hull[i-1].x && hull[i].y == hull[i-1].y)\n                continue;\n            hull[n++] = hull[i];\n        }\n    }\n    __syncthreads();\n\n    // Compute perimeter\n    double len = 0;\n    if (n >= 2) {\n        for (int i = tid; i < n - 1; i += blockDim.x) {\n            len += distance(hull[i], hull[i+1]);\n        }\n        __syncthreads();\n        if (tid == 0) {\n            *perimeter = len + distance(hull[0], hull[n-1]);\n        }\n    } else {\n        *perimeter = 0;\n    }\n}\n"
    ]
  },
  {
    "problem_type": "geometry",
    "language": "cpp",
    "name": "11_geometry_convex_hull_perimeter",
    "parallelism_model": "serial",
    "prompt": "struct Point {\n\tdouble x, y;\n};\n\ndouble distance(Point const& p1, Point const& p2) {\n\treturn std::sqrt(std::pow(p2.x-p1.x, 2) + std::pow(p2.y-p1.y, 2));\n}\n\n/* Return the perimeter of the smallest convex polygon that contains all the points in the vector points.\n   Example:\n\n   input: [{0, 3}, {1, 1}, {2, 2}, {4, 4}, {0, 0}, {1, 2}, {3, 1}, {3, 3}]\n   output: 13.4477\n*/\ndouble convexHullPerimeter(std::vector<Point> const& points) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n\tdouble perimeter = 0.0;\n\tstd::vector<Point> hull;\n\tint n = points.size();\n\tif (n == 0) return 0;\n\tstd::vector<Point> pts = points;\n\tstd::sort(pts.begin(), pts.end(), [](Point const& a, Point const& b) {\n\t\treturn a.x < b.x || (a.x == b.x && a.y < b.y);\n\t});\n\tint k = 0;\n\thull.resize(2 * n);\n\tfor (int i = 0; i < n; ++i) {\n\t\twhile (k >= 2 && (hull[k-1] - hull[k-2]).x * (pts[i] - hull[k-2]).y - (hull[k-1] - hull[k-2]).y * (pts[i] - hull[k-2]).x <= 0) {\n\t\t\t--k;\n\t\t}\n\t\thull[k++] = pts[i];\n\t}\n\tint t = k + 1;\n\tfor (int i = n - 2; i >= 0; --i) {\n\t\twhile (k >= t && (hull[k-1] - hull[k-2]).x * (pts[i] - hull[k-2]).y - (hull[k-1] - hull[k-2]).y * (pts[i] - hull[k-2]).x <= 0) {\n\t\t\t--k;\n\t\t}\n\t\thull[k++] = pts[i];\n\t}\n\thull.resize(k - 1);\n\tfor (size_t i = 0; i < hull.size(); ++i) {\n\t\tperimeter += distance(hull[i], hull[(i + 1) % hull.size()]);\n\t}\n\treturn perimeter;\n}\n"
    ]
  },
  {
    "problem_type": "geometry",
    "language": "cpp",
    "name": "12_geometry_smallest_triangle",
    "parallelism_model": "omp",
    "prompt": "#include <omp.h>\n\nstruct Point {\n\tdouble x, y;\n};\n\ndouble triangleArea(Point const& A, Point const& B, Point const& C) {\n  return 0.5 * std::abs( A.x*(B.y-C.y) + B.x*(C.y-A.y) + C.x*(A.y-B.y) );\n}\n\n/* Return the area of the smallest triangle that can be formed by any 3 points.\n   Use OpenMP to compute in parallel.\n   Example:\n\n   input: [{0, 10}, {5, 5}, {1,0}, {-1, 1}, {-10, 0}]\n   output: 5.5\n*/\ndouble smallestArea(std::vector<Point> const& points) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n\tdouble minArea = std::numeric_limits<double>::infinity();\n#pragma omp parallel\n\t{\n#pragma omp for schedule(guided)\n\t\tfor (size_t i = 0; i < points.size(); ++i) {\n\t\t\tfor (size_t j = i + 1; j < points.size(); ++j) {\n\t\t\t\tfor (size_t k = j + 1; k < points.size(); ++k) {\n\t\t\t\t\tdouble area = triangleArea(points[i], points[j], points[k]);\n#pragma omp critical\n\t\t\t\t\tif (area < minArea && area > 0) {\n\t\t\t\t\t\tminArea = area;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn minArea;\n}\n"
    ]
  },
  {
    "problem_type": "geometry",
    "language": "cpp",
    "name": "12_geometry_smallest_triangle",
    "parallelism_model": "cuda",
    "prompt": "struct Point {\n\tdouble x, y;\n};\n\n__device__ double triangleArea(Point const& A, Point const& B, Point const& C) {\n  return 0.5 * fabs( A.x*(B.y-C.y) + B.x*(C.y-A.y) + C.x*(A.y-B.y) );\n}\n\n/* Compute the area of the smallest triangle that can be formed by any 3 points.\n   Return the result in area.\n   Use CUDA to compute in parallel. The kernel is launched with at least N threads.\n   Example:\n\n   input: [{0, 10}, {5, 5}, {1,0}, {-1, 1}, {-10, 0}]\n   output: 5.5\n*/\n__global__ void smallestArea(const Point *points, size_t N, double *area) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n  __shared__ double sharedMinArea[256];\n  double minArea = INFINITY;\n\n  int tid = threadIdx.x;\n  int totalThreads = blockDim.x * gridDim.x;\n\n  for (size_t i = 0; i < N; i++) {\n    for (size_t j = i + 1; j < N; j++) {\n      for (size_t k = j + 1; k < N; k += blockDim.x) {\n        size_t idx = k + threadIdx.x;\n        if (idx < N) {\n          double areaVal = triangleArea(points[i], points[j], points[idx]);\n          if (areaVal < minArea) {\n            minArea = areaVal;\n          }\n        }\n      }\n    }\n  }\n\n  sharedMinArea[tid] = minArea;\n  __syncthreads();\n\n  for (int s = blockDim.x / 2; s > 0; s >>= 1) {\n    if (tid < s) {\n      if (sharedMinArea[tid + s] < sharedMinArea[tid]) {\n        sharedMinArea[tid] = sharedMinArea[tid + s];\n      }\n    }\n    __syncthreads();\n  }\n\n  if (tid == 0) {\n    atomicMin(area, sharedMinArea[0]);\n  }\n}\n"
    ]
  },
  {
    "problem_type": "geometry",
    "language": "cpp",
    "name": "12_geometry_smallest_triangle",
    "parallelism_model": "serial",
    "prompt": "struct Point {\n\tdouble x, y;\n};\n\ndouble triangleArea(Point const& A, Point const& B, Point const& C) {\n  return 0.5 * std::abs( A.x*(B.y-C.y) + B.x*(C.y-A.y) + C.x*(A.y-B.y) );\n}\n\n/* Return the area of the smallest triangle that can be formed by any 3 points.\n   Example:\n\n   input: [{0, 10}, {5, 5}, {1,0}, {-1, 1}, {-10, 0}]\n   output: 5.5\n*/\ndouble smallestArea(std::vector<Point> const& points) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\ndouble smallestArea(std::vector<Point> const& points) {\n    double minArea = std::numeric_limits<double>::infinity();\n    size_t n = points.size();\n    for (size_t i = 0; i < n; ++i) {\n        for (size_t j = i + 1; j < n; ++j) {\n            for (size_t k = j + 1; k < n; ++k) {\n                double area = triangleArea(points[i], points[j], points[k]);\n                if (area < minArea) {\n                    minArea = area;\n                }\n            }\n        }\n    }\n    return minArea;\n}\n"
    ]
  },
  {
    "problem_type": "geometry",
    "language": "cpp",
    "name": "14_geometry_closest_pair_1d",
    "parallelism_model": "omp",
    "prompt": "#include <omp.h>\n\ndouble distance(double x1, double x2) {\n\treturn std::abs(x1 - x2);\n}\n\n/* Return the distance between the closest two elements in the vector x.\n   Use OpenMP to compute in parallel.\n   Example: \n\n   input: [7, 3, 9, 12, 31, 1]\n   output: 2\n*/\ndouble closestPair(std::vector<double> const& x) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n\tdouble min_dist = std::numeric_limits<double>::infinity();\n\tint n = x.size();\n\t#pragma omp parallel for schedule(guided) reduction(min:min_dist)\n\tfor (int i = 0; i < n; ++i) {\n\t\tfor (int j = i + 1; j < n; ++j) {\n\t\t\tdouble d = distance(x[i], x[j]);\n\t\t\tif (d < min_dist) {\n\t\t\t\tmin_dist = d;\n\t\t\t}\n\t\t}\n\t}\n\treturn min_dist;\n}\n"
    ]
  },
  {
    "problem_type": "geometry",
    "language": "cpp",
    "name": "14_geometry_closest_pair_1d",
    "parallelism_model": "cuda",
    "prompt": "__device__ double distanceBetweenPoints(double x1, double x2) {\n\treturn fabs(x1 - x2);\n}\n\n/* Compute the distance between the closest two elements in the vector x.\n   Store the result in distance.\n   Use CUDA to compute in parallel. The kernel is launched with at least N threads.\n   Example:\n\n   input: [7, 3, 9, 12, 31, 1]\n   output: 2\n*/\n__global__ void closestPair(const double *x, size_t N, double *distance) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n\t__shared__ double shared_x[1024];\n\tint tid = threadIdx.x;\n\tint i = blockIdx.x * blockDim.x + threadIdx.x;\n\n\tif (i < N) {\n\t\tshared_x[tid] = x[i];\n\t}\n\t__syncthreads();\n\n\tdouble min_dist = INFINITY;\n\tif (i < N) {\n\t\tfor (int j = 0; j < tid; j++) {\n\t\t\tdouble dist = distanceBetweenPoints(shared_x[tid], shared_x[j]);\n\t\t\tif (dist < min_dist) {\n\t\t\t\tmin_dist = dist;\n\t\t\t}\n\t\t}\n\t}\n\t__syncthreads();\n\n\tif (tid == 0) {\n\t\t*distance = min_dist;\n\t}\n}\n"
    ]
  },
  {
    "problem_type": "geometry",
    "language": "cpp",
    "name": "14_geometry_closest_pair_1d",
    "parallelism_model": "serial",
    "prompt": "double distance(double x1, double x2) {\n\treturn std::abs(x1 - x2);\n}\n\n/* Return the distance between the closest two elements in the vector x.\n   Example: \n\n   input: [7, 3, 9, 12, 31, 1]\n   output: 2\n*/\ndouble closestPair(std::vector<double> const& x) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\ndouble closestPair(std::vector<double> const& x) {\n    if (x.size() < 2) return 0.0;\n    double min_dist = distance(x[0], x[1]);\n    for (size_t i = 0; i < x.size(); ++i) {\n        for (size_t j = i + 1; j < x.size(); ++j) {\n            double d = distance(x[i], x[j]);\n            if (d < min_dist) min_dist = d;\n        }\n    }\n    return min_dist;\n}\n"
    ]
  },
  {
    "problem_type": "geometry",
    "language": "cpp",
    "name": "10_geometry_convex_hull",
    "parallelism_model": "omp",
    "prompt": "#include <omp.h>\n\nstruct Point {\n   double x, y;\n};\n\n/* Find the set of points that defined the smallest convex polygon that contains all the points in the vector points. Store the result in `hull`.\n   Use OpenMP to compute in parallel.\n   Example:\n\n   input: [{0, 3}, {1, 1}, {2, 2}, {4, 4}, {0, 0}, {1, 2}, {3, 1}, {3, 3}]\n   output: [{0, 3}, {4, 4}, {3, 1}, {0, 0}]\n*/\nvoid convexHull(std::vector<Point> const& points, std::vector<Point> &hull) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\nvoid convexHull(std::vector<Point> const& points, std::vector<Point> &hull) {\n    if (points.size() <= 3) {\n        hull = points;\n        return;\n    }\n\n    std::vector<Point> sorted_points = points;\n    std::sort(sorted_points.begin(), sorted_points.end(), [](const Point& a, const Point& b) {\n        return a.x < b.x || (a.x == b.x && a.y < b.y);\n    });\n\n    Point p1 = sorted_points.front();\n    Point p2 = sorted_points.back();\n\n    std::vector<Point> left_set, right_set;\n#pragma omp parallel\n    {\n#pragma omp for nowait schedule(guided)\n        for (size_t i = 0; i < sorted_points.size(); ++i) {\n            double cross = (sorted_points[i].x - p1.x) * (p2.y - p1.y) - (sorted_points[i].y - p1.y) * (p2.x - p1.x);\n            if (cross > 0.0) {\n#pragma omp critical\n                left_set.push_back(sorted_points[i]);\n            } else if (cross < 0.0) {\n#pragma omp critical\n                right_set.push_back(sorted_points[i]);\n            }\n        }\n    }\n\n    hull.push_back(p1);\n    hull.push_back(p2);\n\n#pragma omp parallel sections\n    {\n#pragma omp section\n        {\n            std::vector<Point> left_hull;\n            buildHull(left_set, p1, p2, left_hull);\n#pragma omp critical\n            hull.insert(hull.end(), left_hull.begin(), left_hull.end());\n        }\n\n#pragma omp section\n        {\n            std::vector<Point> right_hull;\n            buildHull(right_set, p2, p1, right_hull);\n#pragma omp critical\n            hull.insert(hull.end(), right_hull.begin(), right_hull.end());\n        }\n    }\n\n    std::sort(hull.begin(), hull.end(), [](const Point& a, const Point& b) {\n        return a.x < b.x || (a.x == b.x && a.y < b.y);\n    });\n\n    auto last = std::unique(hull.begin(), hull.end(), [](const Point& a, const Point& b) {\n        return a.x == b.x && a.y == b.y;\n    });\n    hull.erase(last, hull.end());\n}\n\nvoid buildHull(std::vector<Point> const& points, Point const& p1, Point const& p2, std::vector<Point> &hull) {\n    if (points.empty()) return;\n\n    double max_dist = 0.0;\n    Point max_point;\n\n    for (const auto& point : points) {\n        double dist = std::abs((point.x - p1.x) * (p2.y - p1.y) - (point.y - p1.y) * (p2.x - p1.x));\n        if (dist > max_dist) {\n            max_dist = dist;\n            max_point = point;\n        }\n    }\n\n    hull.push_back(max_point);\n\n    std::vector<Point> left_set;\n    for (const auto& point : points) {\n        if (isInsideTriangle(p1, p2, max_point, point)) {\n            left_set.push_back(point);\n        }\n    }\n\n    buildHull(left_set, p1, max_point, hull);\n    buildHull(left_set, max_point, p2, hull);\n}\n\nbool isInsideTriangle(Point const& a, Point const& b, Point const& c, Point const& p) {\n    double area = 0.5 * (-b.x * c.y + a.x * (c.y - b.y) + b.x * a.y - c.x * a.y + (c.x - a.x) * b.y + c.x * p.y);\n    double s = (1.0 / (2.0 * area)) * (a.y * c.x - a.x * c.y + (c.y - a.y) * p.x + (a.x - c.x) * p.y);\n    double t = (1.0 / (2.0 * area)) * (a.x * b.y - a.y * b.x + (a.y - b.y) * p.x + (b.x - a.x) * p.y);\n\n    return s >= 0 && t >= 0 && (s + t) <= 1;\n}\n"
    ]
  },
  {
    "problem_type": "geometry",
    "language": "cpp",
    "name": "10_geometry_convex_hull",
    "parallelism_model": "cuda",
    "prompt": "struct Point {\n   double x, y;\n};\n\n/* Find the set of points that defined the smallest convex polygon that contains all the points in the vector points. Store the result in `hull`.\n   Use CUDA to compute in parallel. The kernel is launched with at least as many threads as points.\n   Example:\n\n   input: [{0, 3}, {1, 1}, {2, 2}, {4, 4}, {0, 0}, {1, 2}, {3, 1}, {3, 3}]\n   output: [{0, 3}, {4, 4}, {3, 1}, {0, 0}]\n*/\n__global__ void convexHull(const Point *points, size_t numPoints, Point *hull, size_t hullSize) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n    extern __shared__ Point sharedPoints[];\n\n    // Copy points to shared memory\n    size_t tid = threadIdx.x;\n    if (tid < numPoints) {\n        sharedPoints[tid] = points[tid];\n    }\n    __syncthreads();\n\n    // Find extreme points (leftmost, rightmost, topmost, bottommost)\n    Point leftmost = sharedPoints[0];\n    Point rightmost = sharedPoints[0];\n    Point topmost = sharedPoints[0];\n    Point bottommost = sharedPoints[0];\n\n    for (size_t i = 1; i < numPoints; ++i) {\n        if (sharedPoints[i].x < leftmost.x || (sharedPoints[i].x == leftmost.x && sharedPoints[i].y < leftmost.y)) {\n            leftmost = sharedPoints[i];\n        }\n        if (sharedPoints[i].x > rightmost.x || (sharedPoints[i].x == rightmost.x && sharedPoints[i].y > rightmost.y)) {\n            rightmost = sharedPoints[i];\n        }\n        if (sharedPoints[i].y > topmost.y || (sharedPoints[i].y == topmost.y && sharedPoints[i].x < topmost.x)) {\n            topmost = sharedPoints[i];\n        }\n        if (sharedPoints[i].y < bottommost.y || (sharedPoints[i].y == bottommost.y && sharedPoints[i].x > bottommost.x)) {\n            bottommost = sharedPoints[i];\n        }\n    }\n\n    // Store results in hull\n    if (tid == 0) {\n        hull[0] = leftmost;\n        hull[1] = rightmost;\n        hull[2] = topmost;\n        hull[3] = bottommost;\n        *reinterpret_cast<size_t*>(hull + 4) = 4; // Store hull size at index 4\n    }\n}\n"
    ]
  },
  {
    "problem_type": "geometry",
    "language": "cpp",
    "name": "10_geometry_convex_hull",
    "parallelism_model": "serial",
    "prompt": "struct Point {\n   double x, y;\n};\n\n/* Find the set of points that defined the smallest convex polygon that contains all the points in the vector points. Store the result in `hull`.\n   Example:\n\n   input: [{0, 3}, {1, 1}, {2, 2}, {4, 4}, {0, 0}, {1, 2}, {3, 1}, {3, 3}]\n   output: [{0, 3}, {4, 4}, {3, 1}, {0, 0}]\n*/\nvoid convexHull(std::vector<Point> const& points, std::vector<Point> &hull) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\nvoid convexHull(std::vector<Point> const& points, std::vector<Point> &hull) {\n    if (points.empty()) return;\n    hull.clear();\n    std::vector<Point> sorted = points;\n    std::sort(sorted.begin(), sorted.end(), [](const Point& a, const Point& b) { return a.x < b.x || (a.x == b.x && a.y < b.y); });\n    int n = 0;\n    for (auto& p : sorted) {\n        while (n >= 2 && (hull[n-1].x - hull[n-2].x)*(p.y - hull[n-2].y) - (hull[n-1].y - hull[n-2].y)*(p.x - hull[n-2].x) <= 0) {\n            hull.pop_back();\n            n--;\n        }\n        hull.push_back(p);\n        n++;\n    }\n    int m = n;\n    for (int i = sorted.size() - 2; i >= 0; i--) {\n        while (n >= m + 1 && (hull[n-1].x - hull[n-2].x)*(sorted[i].y - hull[n-2].y) - (hull[n-1].y - hull[n-2].y)*(sorted[i].x - hull[n-2].x) <= 0) {\n            hull.pop_back();\n            n--;\n        }\n        hull.push_back(sorted[i]);\n        n++;\n    }\n    if (hull.size() > 1) hull.pop_back();\n}\n"
    ]
  },
  {
    "problem_type": "transform",
    "language": "cpp",
    "name": "59_transform_map_function",
    "parallelism_model": "omp",
    "prompt": "#include <omp.h>\n\nbool isPowerOfTwo(int x) {\n\treturn (x > 0) && !(x & (x - 1));\n}\n\n/* Apply the isPowerOfTwo function to every value in x and store the results in mask.\n   Use OpenMP to compute in parallel.\n   Example:\n\n   input: [8, 0, 9, 7, 15, 64, 3]\n   output: [true, false, false, false, false, true, false]\n*/\nvoid mapPowersOfTwo(std::vector<int> const& x, std::vector<bool> &mask) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n#pragma omp parallel for schedule(guided) num_threads(32)\n\tfor (size_t i = 0; i < x.size(); ++i) {\n\t\tmask[i] = isPowerOfTwo(x[i]);\n\t}\n}\n"
    ]
  },
  {
    "problem_type": "transform",
    "language": "cpp",
    "name": "59_transform_map_function",
    "parallelism_model": "cuda",
    "prompt": "__device__ bool isPowerOfTwo(int x) {\n\treturn (x > 0) && !(x & (x - 1));\n}\n\n/* Apply the isPowerOfTwo function to every value in x and store the results in mask.\n   Use CUDA to compute in parallel. The kernel is launched with at least as many threads as elements in x.\n   Example:\n\n   input: [8, 0, 9, 7, 15, 64, 3]\n   output: [true, false, false, false, false, true, false]\n*/\n__global__ void mapPowersOfTwo(const int *x, bool *mask, size_t N) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n    size_t idx = threadIdx.x + blockIdx.x * blockDim.x;\n    if (idx < N) {\n        mask[idx] = isPowerOfTwo(x[idx]);\n    }\n}\n"
    ]
  },
  {
    "problem_type": "transform",
    "language": "cpp",
    "name": "59_transform_map_function",
    "parallelism_model": "serial",
    "prompt": "bool isPowerOfTwo(int x) {\n\treturn (x > 0) && !(x & (x - 1));\n}\n\n/* Apply the isPowerOfTwo function to every value in x and store the results in mask.\n   Example:\n\n   input: [8, 0, 9, 7, 15, 64, 3]\n   output: [true, false, false, false, false, true, false]\n*/\nvoid mapPowersOfTwo(std::vector<int> const& x, std::vector<bool> &mask) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\nvoid mapPowersOfTwo(std::vector<int> const& x, std::vector<bool> &mask) {\n    mask.resize(x.size());\n    #pragma omp simd aligned(x.data():64) aligned(mask.data():64)\n    for (size_t i = 0; i < x.size(); ++i) {\n        mask[i] = (x[i] > 0) && !(x[i] & (x[i] - 1));\n    }\n}\n"
    ]
  },
  {
    "problem_type": "transform",
    "language": "cpp",
    "name": "57_transform_inverse_offset",
    "parallelism_model": "omp",
    "prompt": "#include <omp.h>\n\n/* Replace every element of the vector x with 1-1/x.\n   Use OpenMP to compute in parallel.\n   Example:\n\n   input: [2, 4, 1, 12, -2]\n   output: [0.5, 0.75, 0, 0.91666666, 1.5]\n*/\nvoid oneMinusInverse(std::vector<double> &x) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n#pragma omp parallel for schedule(guided) num_threads(32)\n    for (size_t i = 0; i < x.size(); ++i) {\n        x[i] = 1.0 - (1.0 / x[i]);\n    }\n}\n"
    ]
  },
  {
    "problem_type": "transform",
    "language": "cpp",
    "name": "57_transform_inverse_offset",
    "parallelism_model": "cuda",
    "prompt": "/* Replace every element of the vector x with 1-1/x.\n   Use CUDA to compute in parallel. The kernel is launched with at least as many threads as elements in x.\n   Example:\n\n   input: [2, 4, 1, 12, -2]\n   output: [0.5, 0.75, 0, 0.91666666, 1.5]\n*/\n__global__ void oneMinusInverse(double *x, size_t N) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n    size_t i = blockIdx * blockDim + threadIdx;\n    if (i < N) {\n        double val = x[i];\n        if (val != 0) {\n            x[i] = 1.0 - (1.0 / val);\n        } else {\n            x[i] = 0.0;\n        }\n    }\n}\n"
    ]
  },
  {
    "problem_type": "transform",
    "language": "cpp",
    "name": "57_transform_inverse_offset",
    "parallelism_model": "serial",
    "prompt": "/* Replace every element of the vector x with 1-1/x.\n   Example:\n\n   input: [2, 4, 1, 12, -2]\n   output: [0.5, 0.75, 0, 0.91666666, 1.5]\n*/\nvoid oneMinusInverse(std::vector<double> &x) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n    const size_t size = x.size();\n    const size_t unroll_factor = 4;\n    const size_t aligned_size = size - (size % unroll_factor);\n\n    double* data = x.data();\n\n    for (size_t i = 0; i < aligned_size; i += unroll_factor) {\n        data[i + 0] = 1.0 - 1.0 / data[i + 0];\n        data[i + 1] = 1.0 - 1.0 / data[i + 1];\n        data[i + 2] = 1.0 - 1.0 / data[i + 2];\n        data[i + 3] = 1.0 - 1.0 / data[i + 3];\n    }\n\n    for (size_t i = aligned_size; i < size; ++i) {\n        data[i] = 1.0 - 1.0 / data[i];\n    }\n}\n"
    ]
  },
  {
    "problem_type": "transform",
    "language": "cpp",
    "name": "55_transform_relu",
    "parallelism_model": "omp",
    "prompt": "#include <omp.h>\n\n/* Compute the ReLU function on every element of x. Elements less than zero become zero,\n   while elements greater than zero stay the same.\n   Use OpenMP to compute in parallel.\n   Example:\n\n   input: [-1.8, 24.0, 1.2, 0.0, -5.1, -0.2, 4.5]\n   output: [0, 24.0, 1.2, 0, 0, 0, 4.5]\n*/\nvoid relu(std::vector<double> &x) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n#pragma omp parallel for schedule(guided) num_threads(32)\n    for (size_t i = 0; i < x.size(); ++i) {\n        x[i] = x[i] > 0.0 ? x[i] : 0.0;\n    }\n}\n"
    ]
  },
  {
    "problem_type": "transform",
    "language": "cpp",
    "name": "55_transform_relu",
    "parallelism_model": "cuda",
    "prompt": "/* Compute the ReLU function on every element of x. Elements less than zero become zero,\n   while elements greater than zero stay the same.\n   Use CUDA to compute in parallel. The kernel is launched with at least as many threads as values in x.\n   Example:\n\n   input: [-1.8, 24.0, 1.2, 0.0, -5.1, -0.2, 4.5]\n   output: [0, 24.0, 1.2, 0, 0, 0, 4.5]\n*/\n__global__ void relu(double *x, size_t N) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n    size_t idx = blockIdx.x * blockDim.x + threadIdx.x;\n    if (idx < N) {\n        x[idx] = x[idx] > 0.0 ? x[idx] : 0.0;\n    }\n}\n"
    ]
  },
  {
    "problem_type": "transform",
    "language": "cpp",
    "name": "55_transform_relu",
    "parallelism_model": "serial",
    "prompt": "/* Compute the ReLU function on every element of x. Elements less than zero become zero,\n   while elements greater than zero stay the same.\n   Example:\n\n   input: [-1.8, 24.0, 1.2, 0.0, -5.1, -0.2, 4.5]\n   output: [0, 24.0, 1.2, 0, 0, 0, 4.5]\n*/\nvoid relu(std::vector<double> &x) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n    const size_t size = x.size();\n    double* ptr = x.data();\n\n    size_t i = 0;\n    for (; i + 8 <= size; i += 8, ptr += 8) {\n        __m512d vec = _mm512_load_pd(ptr);\n        __m512d zero = _mm512_setzero_pd();\n        __m512d result = _mm512_max_pd(vec, zero);\n        _mm512_store_pd(ptr, result);\n    }\n\n    for (; i < size; ++i, ++ptr) {\n        *ptr = *ptr > 0.0 ? *ptr : 0.0;\n    }\n}\n"
    ]
  },
  {
    "problem_type": "transform",
    "language": "cpp",
    "name": "56_transform_negate_odds",
    "parallelism_model": "omp",
    "prompt": "#include <omp.h>\n\n/* In the vector x negate the odd values and divide the even values by 2.\n   Use OpenMP to compute in parallel.\n   Example:\n\n   input: [16, 11, 12, 14, 1, 0, 5]\n   output: [8, -11, 6, 7, -1, 0, -5]\n*/\nvoid negateOddsAndHalveEvens(std::vector<int> &x) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n#pragma omp parallel for schedule(guided) num_threads(32)\n    for (size_t i = 0; i < x.size(); ++i) {\n        if (x[i] % 2 == 0) {\n            x[i] /= 2;\n        } else {\n            x[i] = -x[i];\n        }\n    }\n}\n"
    ]
  },
  {
    "problem_type": "transform",
    "language": "cpp",
    "name": "56_transform_negate_odds",
    "parallelism_model": "cuda",
    "prompt": "/* In the vector x negate the odd values and divide the even values by 2.\n   Use CUDA to compute in parallel. The kernel is launched with at least as many threads as values in x.\n   Example:\n\n   input: [16, 11, 12, 14, 1, 0, 5]\n   output: [8, -11, 6, 7, -1, 0, -5]\n*/\n__global__ void negateOddsAndHalveEvens(int *x, size_t N) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n  size_t i = blockIdx.x * blockDim.x + threadIdx.x;\n  if (i < N) {\n    if (x[i] % 2 == 0) {\n      x[i] = x[i] / 2;\n    } else {\n      x[i] = -x[i];\n    }\n  }\n}\n"
    ]
  },
  {
    "problem_type": "transform",
    "language": "cpp",
    "name": "56_transform_negate_odds",
    "parallelism_model": "serial",
    "prompt": "/* In the vector x negate the odd values and divide the even values by 2.\n   Example:\n\n   input: [16, 11, 12, 14, 1, 0, 5]\n   output: [8, -11, 6, 7, -1, 0, -5]\n*/\nvoid negateOddsAndHalveEvens(std::vector<int> &x) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\nvoid negateOddsAndHalveEvens(std::vector<int> &x) {\n    for (size_t i = 0; i < x.size(); ++i) {\n        if (x[i] % 2 == 0) {\n            x[i] /= 2;\n        } else {\n            x[i] = -x[i];\n        }\n    }\n}\n"
    ]
  },
  {
    "problem_type": "transform",
    "language": "cpp",
    "name": "58_transform_squaring",
    "parallelism_model": "omp",
    "prompt": "#include <omp.h>\n\n/* Replace every element of x with the square of its value.\n   Use OpenMP to compute in parallel.\n   Example:\n\n   input: [5, 1, 2, -4, 8]\n   output: [25, 1, 4, 16, 64]\n*/\nvoid squareEach(std::vector<int> &x) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n#pragma omp parallel for schedule(guided) num_threads(32)\n    for (size_t i = 0; i < x.size(); ++i) {\n        x[i] *= x[i];\n    }\n"
    ]
  },
  {
    "problem_type": "transform",
    "language": "cpp",
    "name": "58_transform_squaring",
    "parallelism_model": "cuda",
    "prompt": "/* Replace every element of x with the square of its value.\n   Use CUDA to compute in parallel. The kernel is launched with at least as many threads as values in x.\n   Example:\n\n   input: [5, 1, 2, -4, 8]\n   output: [25, 1, 4, 16, 64]\n*/\n__global__ void squareEach(int *x, size_t N) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n    size_t i = blockIdx.x * blockDim.x + threadIdx.x;\n    if (i < N) {\n        x[i] = x[i] * x[i];\n    }\n}\n"
    ]
  },
  {
    "problem_type": "transform",
    "language": "cpp",
    "name": "58_transform_squaring",
    "parallelism_model": "serial",
    "prompt": "/* Replace every element of x with the square of its value.\n   Example:\n\n   input: [5, 1, 2, -4, 8]\n   output: [25, 1, 4, 16, 64]\n*/\nvoid squareEach(std::vector<int> &x) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\nvoid squareEach(std::vector<int> &x) {\n    const size_t size = x.size();\n    int* data = x.data();\n    for (size_t i = 0; i < size; ++i) {\n        data[i] *= data[i];\n    }\n}\n"
    ]
  },
  {
    "problem_type": "reduce",
    "language": "cpp",
    "name": "26_reduce_product_of_inverses",
    "parallelism_model": "omp",
    "prompt": "#include <omp.h>\n\n/* Return the product of the vector x with every odd indexed element inverted.\n   i.e. x_0 * 1/x_1 * x_2 * 1/x_3 * x_4 ...\n   Use OpenMP to compute product in parallel.\n   Example:\n\n   input: [4, 2, 10, 4, 5]\n   output: 25\n*/\ndouble productWithInverses(std::vector<double> const& x) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\ndouble product = 1.0;\n#pragma omp parallel\n{\n    size_t num_threads = omp_get_num_threads();\n    size_t thread_id = omp_get_thread_num();\n    size_t n = x.size();\n    double local_product = 1.0;\n\n    for (size_t i = thread_id; i < n; i += num_threads) {\n        if (i % 2 == 1) {\n            local_product *= 1.0 / x[i];\n        } else {\n            local_product *= x[i];\n        }\n    }\n\n    #pragma omp critical\n    product *= local_product;\n}\nreturn product;\n"
    ]
  },
  {
    "problem_type": "reduce",
    "language": "cpp",
    "name": "26_reduce_product_of_inverses",
    "parallelism_model": "cuda",
    "prompt": "/* Compute the product of the vector x with every odd indexed element inverted.\n   i.e. x_0 * 1/x_1 * x_2 * 1/x_3 * x_4 ...\n   Store the result in product.\n   Use CUDA to compute product in parallel. The kernel is launched with at least as many threads as values in x.\n   Example:\n\n   input: [4, 2, 10, 4, 5]\n   output: 25\n*/\n__global__ void productWithInverses(const double *x, size_t N, double *product) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n    extern __shared__ double sharedData[];\n    int tid = threadIdx.x;\n    int index = blockIdx.x * blockDim.x + threadIdx.x;\n\n    double localProduct = 1.0;\n\n    while (index < N) {\n        if (index % 2 == 1) {\n            localProduct *= (1.0 / x[index]);\n        } else {\n            localProduct *= x[index];\n        }\n        index += gridDim.x * blockDim.x;\n    }\n\n    sharedData[tid] = localProduct;\n    __syncthreads();\n\n    for (int s = blockDim.x / 2; s > 0; s >>= 1) {\n        if (tid < s) {\n            sharedData[tid] *= sharedData[tid + s];\n        }\n        __syncthreads();\n    }\n\n    if (tid == 0) {\n        atomicMul(product, sharedData[0]);\n    }\n}\n"
    ]
  },
  {
    "problem_type": "reduce",
    "language": "cpp",
    "name": "26_reduce_product_of_inverses",
    "parallelism_model": "serial",
    "prompt": "/* Return the product of the vector x with every odd indexed element inverted.\n   i.e. x_0 * 1/x_1 * x_2 * 1/x_3 * x_4 ...\n   Example:\n\n   input: [4, 2, 10, 4, 5]\n   output: 25\n*/\ndouble productWithInverses(std::vector<double> const& x) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n    double result = 1.0;\n    const size_t size = x.size();\n    for (size_t i = 0; i < size; ++i) {\n        if (i % 2 == 1) {\n            result /= x[i];\n        } else {\n            result *= x[i];\n        }\n    }\n    return result;\n}\n"
    ]
  },
  {
    "problem_type": "reduce",
    "language": "cpp",
    "name": "27_reduce_average",
    "parallelism_model": "omp",
    "prompt": "#include <omp.h>\n\n/* Return the average of the vector x.\n   Use OpenMP to compute in parallel.\n   Examples:\n\t\t\n\t input: [1, 8, 4, 5, 1]\n   output: 3.8\n\n   input: [2, 2, 2, 3]\n   output: 2.25\n*/\ndouble average(std::vector<double> const& x) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\ndouble sum = 0.0;\n#pragma omp parallel for reduction(+:sum) schedule(guided) num_threads(32)\nfor (size_t i = 0; i < x.size(); ++i) {\n    sum += x[i];\n}\nreturn sum / x.size();\n}\n"
    ]
  },
  {
    "problem_type": "reduce",
    "language": "cpp",
    "name": "27_reduce_average",
    "parallelism_model": "cuda",
    "prompt": "/* Compute the average of the vector x. Store the result in average.\n   Use CUDA to compute in parallel. The kernel is launched with at least as many threads as values in x.\n   Examples:\n   \n\t input: [1, 8, 4, 5, 1]\n   output: 3.8\n\n   input: [2, 2, 2, 3]\n   output: 2.25\n*/\n__global__ void average(const double *x, size_t N, double *average) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n    extern __shared__ double sdata[];\n    unsigned int tid = threadIdx.x;\n    unsigned int i = blockIdx.x * blockDim.x + threadIdx.x;\n\n    if (i < N) {\n        sdata[tid] = x[i];\n    } else {\n        sdata[tid] = 0;\n    }\n    __syncthreads();\n\n    for (unsigned int s = blockDim.x / 2; s > 0; s >>= 1) {\n        if (tid < s) {\n            sdata[tid] += sdata[tid + s];\n        }\n        __syncthreads();\n    }\n\n    if (tid == 0) {\n        atomicAdd(average, sdata[0]);\n    }\n}\n"
    ]
  },
  {
    "problem_type": "reduce",
    "language": "cpp",
    "name": "27_reduce_average",
    "parallelism_model": "serial",
    "prompt": "/* Return the average of the vector x.\n   Examples:\n\t\t\n\t input: [1, 8, 4, 5, 1]\n   output: 3.8\n\n   input: [2, 2, 2, 3]\n   output: 2.25\n*/\ndouble average(std::vector<double> const& x) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\ndouble sum = 0.0;\n#pragma omp simd reduction(+:sum)\nfor (size_t i = 0; i < x.size(); ++i) {\n    sum += x[i];\n}\nreturn sum / x.size();\n}\n"
    ]
  },
  {
    "problem_type": "reduce",
    "language": "cpp",
    "name": "28_reduce_smallest_odd_number",
    "parallelism_model": "omp",
    "prompt": "#include <omp.h>\n\n/* Return the value of the smallest odd number in the vector x.\n   Use OpenMP to compute in parallel.\n   Examples:\n\n   input: [7, 9, 5, 2, 8, 16, 4, 1]\n   output: 1\n\n   input: [8, 36, 7, 2, 11]\n   output: 7\n*/\nint smallestOdd(std::vector<int> const& x) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n  int min_odd = INT_MAX;\n  #pragma omp parallel for schedule(guided) reduction(min:min_odd)\n  for (size_t i = 0; i < x.size(); ++i) {\n    if (x[i] % 2 != 0 && x[i] < min_odd) {\n      min_odd = x[i];\n    }\n  }\n  return min_odd;\n}\n"
    ]
  },
  {
    "problem_type": "reduce",
    "language": "cpp",
    "name": "28_reduce_smallest_odd_number",
    "parallelism_model": "cuda",
    "prompt": "/* Find the value of the smallest odd number in the vector x. Store it in smallest.\n   Use CUDA to compute in parallel. The kernel is launched with the same number of threads as elements in x.\n   Examples:\n\n   input: [7, 9, 5, 2, 8, 16, 4, 1]\n   output: 1\n\n   input: [8, 36, 7, 2, 11]\n   output: 7\n*/\n__global__ void smallestOdd(const int *x, size_t N, int *smallest) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n    extern __shared__ int shared_min[];\n    int idx = threadIdx.x + blockIdx.x * blockDim.x;\n\n    // Initialize shared memory\n    if (threadIdx.x == 0) {\n        shared_min[0] = INT_MAX;\n    }\n    __syncthreads();\n\n    // Check if current element is odd and smaller than current smallest\n    if (idx < N && x[idx] % 2 != 0 && x[idx] < shared_min[0]) {\n        shared_min[0] = x[idx];\n    }\n    __syncthreads();\n\n    // Update global smallest value\n    if (threadIdx.x == 0) {\n        atomicMin(smallest, shared_min[0]);\n    }\n}\n"
    ]
  },
  {
    "problem_type": "reduce",
    "language": "cpp",
    "name": "28_reduce_smallest_odd_number",
    "parallelism_model": "serial",
    "prompt": "/* Return the value of the smallest odd number in the vector x.\n   Examples:\n\n   input: [7, 9, 5, 2, 8, 16, 4, 1]\n   output: 1\n\n   input: [8, 36, 7, 2, 11]\n   output: 7\n*/\nint smallestOdd(std::vector<int> const& x) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\nint smallestOdd(std::vector<int> const& x) {\n    int min_odd = -1;\n    for (int num : x) {\n        if (num % 2 != 0) {\n            if (min_odd == -1 || num < min_odd) {\n                min_odd = num;\n            }\n        }\n    }\n    return min_odd;\n}\n"
    ]
  },
  {
    "problem_type": "reduce",
    "language": "cpp",
    "name": "25_reduce_xor",
    "parallelism_model": "omp",
    "prompt": "#include <omp.h>\n\n/* Return the logical XOR reduction of the vector of bools x.\n   Use OpenMP to reduce in parallel.\n   Example:\n\n   input: [false, false, false, true]\n   output: true\n*/\nbool reduceLogicalXOR(std::vector<bool> const& x) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\nbool result = false;\n#pragma omp parallel reduction(^:result) num_threads(32)\n{\n    #pragma omp for schedule(guided)\n    for (size_t i = 0; i < x.size(); ++i) {\n        result ^= x[i];\n    }\n}\nreturn result;\n"
    ]
  },
  {
    "problem_type": "reduce",
    "language": "cpp",
    "name": "25_reduce_xor",
    "parallelism_model": "cuda",
    "prompt": "/* Compute the logical XOR reduction of the vector of bools x. Store the result in output.\n   Use CUDA to reduce in parallel. The kernel is launched with at least as many threads as values in x.\n   Example:\n\n   input: [false, false, false, true]\n   output: true\n*/\n__global__ void reduceLogicalXOR(const bool *x, size_t N, bool *output) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n    extern __shared__ bool s_data[];\n    unsigned int tid = threadIdx.x;\n\n    // Load input into shared memory\n    if (tid < N) {\n        s_data[tid] = x[tid];\n    }\n    __syncthreads();\n\n    // Perform XOR reduction in shared memory\n    for (unsigned int s = 1; s < blockDim.x; s *= 2) {\n        if (tid % (2 * s) == 0 && tid + s < N) {\n            s_data[tid] ^= s_data[tid + s];\n        }\n        __syncthreads();\n    }\n\n    // Write final result to output\n    if (tid == 0) {\n        *output = s_data[0];\n    }\n}\n"
    ]
  },
  {
    "problem_type": "reduce",
    "language": "cpp",
    "name": "25_reduce_xor",
    "parallelism_model": "serial",
    "prompt": "/* Return the logical XOR reduction of the vector of bools x.\n   Example:\n\n   input: [false, false, false, true]\n   output: true\n*/\nbool reduceLogicalXOR(std::vector<bool> const& x) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n    bool result = false;\n    size_t i = 0;\n    size_t size = x.size();\n    \n    // Process vector in chunks of 8 elements using AVX512-like optimization\n    for (; i + 7 < size; i += 8) {\n        bool b0 = x[i + 0];\n        bool b1 = x[i + 1];\n        bool b2 = x[i + 2];\n        bool b3 = x[i + 3];\n        bool b4 = x[i + 4];\n        bool b5 = x[i + 5];\n        bool b6 = x[i + 6];\n        bool b7 = x[i + 7];\n        result ^= b0 ^ b1 ^ b2 ^ b3 ^ b4 ^ b5 ^ b6 ^ b7;\n    }\n\n    // Process remaining elements\n    for (; i < size; ++i) {\n        result ^= x[i];\n    }\n\n    return result;\n}\n"
    ]
  },
  {
    "problem_type": "reduce",
    "language": "cpp",
    "name": "29_reduce_sum_of_min_of_pairs",
    "parallelism_model": "omp",
    "prompt": "#include <omp.h>\n\n/* Return the sum of the minimum value at each index of vectors x and y for all indices.\n   i.e. sum = min(x_0, y_0) + min(x_1, y_1) + min(x_2, y_2) + ...\n   Use OpenMP to sum in parallel.\n   Example:\n\n   input: x=[3, 4, 0, 2, 3], y=[2, 5, 3, 1, 7]\n   output: 10\n*/\ndouble sumOfMinimumElements(std::vector<double> const& x, std::vector<double> const& y) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\ndouble sum = 0.0;\n#pragma omp parallel for reduction(+:sum) schedule(guided) num_threads(32)\nfor (size_t i = 0; i < x.size(); ++i) {\n    sum += std::min(x[i], y[i]);\n}\nreturn sum;\n}\n"
    ]
  },
  {
    "problem_type": "reduce",
    "language": "cpp",
    "name": "29_reduce_sum_of_min_of_pairs",
    "parallelism_model": "cuda",
    "prompt": "/* Compute the sum of the minimum value at each index of vectors x and y for all indices.\n   i.e. sum = min(x_0, y_0) + min(x_1, y_1) + min(x_2, y_2) + ...\n   Store the result in sum.\n   Use CUDA to sum in parallel. The kernel is launched with at least as many threads as values in x.\n   Example:\n\n   input: x=[3, 4, 0, 2, 3], y=[2, 5, 3, 1, 7]\n   output: 10\n*/\n__global__ void sumOfMinimumElements(const double *x, const double *y, size_t N, double *sum) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n    extern __shared__ double sdata[];\n    size_t i = threadIdx.x + blockIdx.x * blockDim.x;\n    size_t tid = threadIdx.x;\n\n    double localSum = 0;\n    while (i < N) {\n        localSum += fmin(x[i], y[i]);\n        i += blockDim.x * gridDim.x;\n    }\n\n    sdata[tid] = localSum;\n    __syncthreads();\n\n    for (size_t s = blockDim.x / 2; s > 0; s >>= 1) {\n        if (tid < s) {\n            sdata[tid] += sdata[tid + s];\n        }\n        __syncthreads();\n    }\n\n    if (tid == 0) {\n        atomicAdd(sum, sdata[0]);\n    }\n}\n"
    ]
  },
  {
    "problem_type": "reduce",
    "language": "cpp",
    "name": "29_reduce_sum_of_min_of_pairs",
    "parallelism_model": "serial",
    "prompt": "/* Return the sum of the minimum value at each index of vectors x and y for all indices.\n   i.e. sum = min(x_0, y_0) + min(x_1, y_1) + min(x_2, y_2) + ...\n   Example:\n\n   input: x=[3, 4, 0, 2, 3], y=[2, 5, 3, 1, 7]\n   output: 10\n*/\ndouble sumOfMinimumElements(std::vector<double> const& x, std::vector<double> const& y) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\ndouble sum = 0.0;\nconst size_t size = x.size();\nfor (size_t i = 0; i < size; ++i) {\n    sum += (x[i] < y[i]) ? x[i] : y[i];\n}\nreturn sum;\n"
    ]
  },
  {
    "problem_type": "dense_la",
    "language": "cpp",
    "name": "00_dense_la_lu_decomp",
    "parallelism_model": "omp",
    "prompt": "#include <omp.h>\n\n/* Factorize the matrix A into A=LU where L is a lower triangular matrix and U is an upper triangular matrix.\n   Store the results for L and U into the original matrix A. \n   A is an NxN matrix stored in row-major.\n   Use OpenMP to compute in parallel.\n   Example:\n\n   input: [[4, 3], [6, 3]]\n   output: [[4, 3], [1.5, -1.5]]\n*/\nvoid luFactorize(std::vector<double> &A, size_t N) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\nvoid luFactorize(std::vector<double> &A, size_t N) {\n    #pragma omp parallel for schedule(dynamic) num_threads(32)\n    for (size_t k = 0; k < N; ++k) {\n        // Compute multipliers for column k\n        #pragma omp simd\n        for (size_t i = k + 1; i < N; ++i) {\n            A[i * N + k] /= A[k * N + k];\n        }\n\n        // Update the trailing submatrix\n        #pragma omp for collapse(2)\n        for (size_t i = k + 1; i < N; ++i) {\n            for (size_t j = k + 1; j < N; ++j) {\n                A[i * N + j] -= A[i * N + k] * A[k * N + j];\n            }\n        }\n    }\n}\n"
    ]
  },
  {
    "problem_type": "dense_la",
    "language": "cpp",
    "name": "00_dense_la_lu_decomp",
    "parallelism_model": "cuda",
    "prompt": "/* Factorize the matrix A into A=LU where L is a lower triangular matrix and U is an upper triangular matrix.\n   Store the results for L and U into the original matrix A. \n   A is an NxN matrix stored in row-major.\n   Use CUDA to compute in parallel. The kernel is launched on an NxN grid of threads.\n   Example:\n\n   input: [[4, 3], [6, 3]]\n   output: [[4, 3], [1.5, -1.5]]\n*/\n__global__ void luFactorize(double *A, size_t N) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n{\n    // Compute the row and column index of the current thread\n    size_t i = blockIdx.y * blockDim.y + threadIdx.y;\n    size_t j = blockIdx.x * blockDim.x + threadIdx.x;\n\n    // Ensure that the thread is within bounds\n    if (i >= N || j >= N) return;\n\n    // For diagonal elements\n    if (i == j) {\n        // Pivot element, compute sum of L_{i,k} * U_{k,i} for k=0 to i-1\n        double sum = 0.0;\n        for (size_t k = 0; k < i; ++k) {\n            sum += A[i * N + k] * A[k * N + i];\n        }\n        A[i * N + i] -= sum;\n    }\n    // Lower triangular part (i > j)\n    else if (i > j) {\n        // Compute L_{i,j}\n        double sum = 0.0;\n        for (size_t k = 0; k < j; ++k) {\n            sum += A[i * N + k] * A[k * N + j];\n        }\n        A[i * N + j] = (A[i * N + j] - sum) / A[j * N + j];\n    }\n    // Upper triangular part (i < j)\n    else {\n        // Compute U_{i,j}\n        double sum = 0.0;\n        for (size_t k = 0; k < i; ++k) {\n            sum += A[i * N + k] * A[k * N + j];\n        }\n        A[i * N + j] -= sum;\n    }\n}\n"
    ]
  },
  {
    "problem_type": "dense_la",
    "language": "cpp",
    "name": "00_dense_la_lu_decomp",
    "parallelism_model": "serial",
    "prompt": "/* Factorize the matrix A into A=LU where L is a lower triangular matrix and U is an upper triangular matrix.\n   Store the results for L and U into the original matrix A. \n   A is an NxN matrix stored in row-major.\n   Example:\n\n   input: [[4, 3], [6, 3]]\n   output: [[4, 3], [1.5, -1.5]]\n*/\nvoid luFactorize(std::vector<double> &A, size_t N) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\nvoid luFactorize(std::vector<double> &A, size_t N) {\n    for (size_t k = 0; k < N; ++k) {\n        double pivot = A[k * N + k];\n        for (size_t i = k + 1; i < N; ++i) {\n            double factor = A[i * N + k] / pivot;\n            A[i * N + k] = factor;\n            for (size_t j = k + 1; j < N; ++j) {\n                A[i * N + j] -= factor * A[k * N + j];\n            }\n        }\n    }\n}\n"
    ]
  },
  {
    "problem_type": "dense_la",
    "language": "cpp",
    "name": "04_dense_la_gemv",
    "parallelism_model": "omp",
    "prompt": "#include <omp.h>\n\n/* Multiply the matrix A by the vector x. Store the results in the vector y.\n   A is an MxN matrix stored in row-major, x has N elements, and y has M elements.\n   Use OpenMP to compute in parallel.\n   Example:\n\n   input: A=[[1, -1, 2], [0, -3, 1]] x=[2, 1, 0]\n   output: y=[1, -3]\n*/\nvoid gemv(std::vector<double> const& A, std::vector<double> const& x, std::vector<double> &y, size_t M, size_t N) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n#pragma omp parallel for schedule(guided) num_threads(32)\n    for (size_t i = 0; i < M; ++i) {\n        double sum = 0.0;\n        for (size_t j = 0; j < N; ++j) {\n            sum += A[i * N + j] * x[j];\n        }\n        y[i] = sum;\n    }\n"
    ]
  },
  {
    "problem_type": "dense_la",
    "language": "cpp",
    "name": "04_dense_la_gemv",
    "parallelism_model": "cuda",
    "prompt": "/* Multiply the matrix A by the vector x. Store the results in the vector y.\n   A is an MxN matrix stored in row-major, x has N elements, and y has M elements.\n   Use CUDA to compute in parallel. The kernel is launched with at least M threads.\n   Example:\n\n   input: A=[[1, -1, 2], [0, -3, 1]] x=[2, 1, 0]\n   output: y=[1, -3]\n*/\n__global__ void gemv(const double *A, const double *x, double *y, size_t M, size_t N) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n    size_t row = blockIdx.x * blockDim.x + threadIdx.x;\n    if (row < M) {\n        double sum = 0.0;\n        for (size_t col = 0; col < N; ++col) {\n            sum += A[row * N + col] * x[col];\n        }\n        y[row] = sum;\n    }\n}\n"
    ]
  },
  {
    "problem_type": "dense_la",
    "language": "cpp",
    "name": "04_dense_la_gemv",
    "parallelism_model": "serial",
    "prompt": "/* Multiply the matrix A by the vector x. Store the results in the vector y.\n   A is an MxN matrix stored in row-major, x has N elements, and y has M elements.\n   Example:\n\n   input: A=[[1, -1, 2], [0, -3, 1]] x=[2, 1, 0]\n   output: y=[1, -3]\n*/\nvoid gemv(std::vector<double> const& A, std::vector<double> const& x, std::vector<double> &y, size_t M, size_t N) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\nvoid gemv(std::vector<double> const& A, std::vector<double> const& x, std::vector<double> &y, size_t M, size_t N) {\n    #pragma omp parallel for\n    for (size_t i = 0; i < M; ++i) {\n        double sum = 0.0;\n        const double* a_ptr = A.data() + i * N;\n        const double* x_ptr = x.data();\n        for (size_t j = 0; j < N; ++j) {\n            sum += *a_ptr++ * *x_ptr++;\n        }\n        y[i] = sum;\n    }\n}\n"
    ]
  },
  {
    "problem_type": "dense_la",
    "language": "cpp",
    "name": "02_dense_la_gemm",
    "parallelism_model": "omp",
    "prompt": "#include <omp.h>\n\n/* Multiply the matrix A by the matrix B. Store the results in the matrix C.\n   A is an MxK matrix, B is a KxN matrix, and C is a MxN matrix. The matrices are stored in row-major.\n   Use OpenMP to compute in parallel.\n   Example:\n\n   input: A=[[1, -1, 2], [0, -2, 1]] B=[[4, 1], [-1, 0], [2, 2]]\n   output: C=[[9, 5], [4, 2]]\n*/\nvoid gemm(std::vector<double> const& A, std::vector<double> const& B, std::vector<double> &C, size_t M, size_t K, size_t N) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n#pragma omp parallel for schedule(guided) num_threads(32)\n    for (size_t i = 0; i < M; ++i) {\n        for (size_t j = 0; j < N; ++j) {\n            double sum = 0.0;\n            for (size_t k = 0; k < K; ++k) {\n                sum += A[i * K + k] * B[k * N + j];\n            }\n            C[i * N + j] = sum;\n        }\n    }\n}\n"
    ]
  },
  {
    "problem_type": "dense_la",
    "language": "cpp",
    "name": "02_dense_la_gemm",
    "parallelism_model": "cuda",
    "prompt": "/* Multiply the matrix A by the matrix B. Store the results in the matrix C.\n   A is an MxK matrix, B is a KxN matrix, and C is a MxN matrix. The matrices are stored in row-major.\n   Use CUDA to compute in parallel. The kernel is launched on an MxN grid of threads.\n   Example:\n\n   input: A=[[1, -1, 2], [0, -2, 1]] B=[[4, 1], [-1, 0], [2, 2]]\n   output: C=[[9, 5], [4, 2]]\n*/\n__global__ void gemm(const double *A, const double *B, double *C, size_t M, size_t K, size_t N) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n    size_t row = blockIdx.y * blockDim.y + threadIdx.y;\n    size_t col = blockIdx.x * blockDim.x + threadIdx.x;\n\n    if (row < M && col < N) {\n        double sum = 0.0;\n        for (size_t i = 0; i < K; ++i) {\n            sum += A[row * K + i] * B[i * N + col];\n        }\n        C[row * N + col] = sum;\n    }\n}\n"
    ]
  },
  {
    "problem_type": "dense_la",
    "language": "cpp",
    "name": "02_dense_la_gemm",
    "parallelism_model": "serial",
    "prompt": "/* Multiply the matrix A by the matrix B. Store the results in the matrix C.\n   A is an MxK matrix, B is a KxN matrix, and C is a MxN matrix. The matrices are stored in row-major.\n   Example:\n\n   input: A=[[1, -1, 2], [0, -2, 1]] B=[[4, 1], [-1, 0], [2, 2]]\n   output: C=[[9, 5], [4, 2]]\n*/\nvoid gemm(std::vector<double> const& A, std::vector<double> const& B, std::vector<double> &C, size_t M, size_t K, size_t N) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n    #pragma omp parallel for collapse(2)\n    for (size_t i = 0; i < M; ++i) {\n        for (size_t j = 0; j < N; ++j) {\n            double sum = 0.0;\n            #pragma omp simd\n            for (size_t k = 0; k < K; ++k) {\n                sum += A[i * K + k] * B[k * N + j];\n            }\n            C[i * N + j] = sum;\n        }\n    }\n}\n"
    ]
  },
  {
    "problem_type": "dense_la",
    "language": "cpp",
    "name": "01_dense_la_solve",
    "parallelism_model": "omp",
    "prompt": "#include <omp.h>\n\n/* Solve the linear system Ax=b for x.\n   A is an NxN matrix in row-major. x and b have N elements.\n   Use OpenMP to compute in parallel.\n   Example:\n   \n   input: A=[[1,4,2], [1,2,3], [2,1,3]] b=[11, 11, 13]\n   output: x=[3, 1, 2]\n*/\nvoid solveLinearSystem(std::vector<double> const& A, std::vector<double> const& b, std::vector<double> &x, size_t N) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n    x.resize(N);\n    std::vector<double> y(N);\n\n    #pragma omp parallel\n    {\n        #pragma omp for schedule(dynamic) nowait\n        for (size_t i = 0; i < N; ++i) {\n            y[i] = b[i];\n            for (size_t j = 0; j < i; ++j) {\n                y[i] -= A[i * N + j] * x[j];\n            }\n        }\n\n        #pragma omp for schedule(dynamic) nowait\n        for (size_t i = N - 1; i < N; --i) {\n            double sum = 0.0;\n            for (size_t j = i + 1; j < N; ++j) {\n                sum += A[i * N + j] * x[j];\n            }\n            x[i] = (y[i] - sum) / A[i * N + i];\n        }\n    }\n}\n"
    ]
  },
  {
    "problem_type": "dense_la",
    "language": "cpp",
    "name": "01_dense_la_solve",
    "parallelism_model": "cuda",
    "prompt": "/* Solve the linear system Ax=b for x.\n   A is an NxN matrix in row-major. x and b have N elements.\n   Use CUDA to compute in parallel. The kernel is launched on an NxN grid of threads.\n   Example:\n   \n   input: A=[[1,4,2], [1,2,3], [2,1,3]] b=[11, 11, 13]\n   output: x=[3, 1, 2]\n*/\n__global__ void solveLinearSystem(const double *A, const double *b, double *x, size_t N) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n    extern __shared__ double shared_data[];\n    double *A_shared = shared_data;\n    double *b_shared = shared_data + N * N;\n\n    size_t row = blockIdx.x;\n    size_t col = threadIdx.x;\n\n    if (col < N) {\n        A_shared[row * N + col] = A[row * N + col];\n        b_shared[row] = b[row];\n    }\n    __syncthreads();\n\n    if (row < N && col < N) {\n        double pivot = A_shared[row * N + row];\n        if (fabs(pivot) > 1e-9) {\n            for (size_t i = 0; i < N; ++i) {\n                if (i != row) {\n                    double factor = A_shared[i * N + row] / pivot;\n                    for (size_t j = 0; j < N; ++j) {\n                        A_shared[i * N + j] -= factor * A_shared[row * N + j];\n                    }\n                    b_shared[i] -= factor * b_shared[row];\n                }\n            }\n        }\n    }\n    __syncthreads();\n\n    if (row < N && col == 0) {\n        x[row] = b_shared[row] / A_shared[row * N + row];\n    }\n}\n"
    ]
  },
  {
    "problem_type": "dense_la",
    "language": "cpp",
    "name": "01_dense_la_solve",
    "parallelism_model": "serial",
    "prompt": "/* Solve the linear system Ax=b for x.\n   A is an NxN matrix in row-major. x and b have N elements.\n   Example:\n   \n   input: A=[[1,4,2], [1,2,3], [2,1,3]] b=[11, 11, 13]\n   output: x=[3, 1, 2]\n*/\nvoid solveLinearSystem(std::vector<double> const& A, std::vector<double> const& b, std::vector<double> &x, size_t N) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\nvoid solveLinearSystem(std::vector<double> const& A, std::vector<double> const& b, std::vector<double> &x, size_t N) {\n    x.resize(N);\n    std::vector<double> mat(N * N);\n    std::copy(A.begin(), A.end(), mat.begin());\n    std::copy(b.begin(), b.end(), x.begin());\n    std::vector<int> ipiv(N);\n    int info;\n    dgesv_(&N, &N, mat.data(), &N, ipiv.data(), x.data(), &N, &info);\n}\n"
    ]
  },
  {
    "problem_type": "dense_la",
    "language": "cpp",
    "name": "03_dense_la_axpy",
    "parallelism_model": "omp",
    "prompt": "#include <omp.h>\n\n/* Compute z = alpha*x+y where x and y are vectors. Store the result in z.\n   Use OpenMP to compute in parallel.\n   Example:\n   \n   input: x=[1, -5, 2, 9] y=[0, 4, 1, -1] alpha=2\n   output: z=[2, -6, 5, 17]\n*/\nvoid axpy(double alpha, std::vector<double> const& x, std::vector<double> const& y, std::vector<double> &z) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n#pragma omp parallel for schedule(guided) num_threads(32)\n    for (size_t i = 0; i < z.size(); ++i) {\n        z[i] = alpha * x[i] + y[i];\n    }\n"
    ]
  },
  {
    "problem_type": "dense_la",
    "language": "cpp",
    "name": "03_dense_la_axpy",
    "parallelism_model": "cuda",
    "prompt": "/* Compute z = alpha*x+y where x and y are vectors. Store the result in z.\n   Use CUDA to compute in parallel. The kernel is launched with at least as many threads as values in x.\n   Example:\n   \n   input: x=[1, -5, 2, 9] y=[0, 4, 1, -1] alpha=2\n   output: z=[2, -6, 5, 17]\n*/\n__global__ void axpy(double alpha, const double *x, const double *y, double *z, size_t N) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n    size_t i = threadIdx.x + blockIdx.x * blockDim.x;\n    if (i < N) {\n        z[i] = alpha * x[i] + y[i];\n    }\n}\n"
    ]
  },
  {
    "problem_type": "dense_la",
    "language": "cpp",
    "name": "03_dense_la_axpy",
    "parallelism_model": "serial",
    "prompt": "/* Compute z = alpha*x+y where x and y are vectors. Store the result in z.\n   Example:\n   \n   input: x=[1, -5, 2, 9] y=[0, 4, 1, -1] alpha=2\n   output: z=[2, -6, 5, 17]\n*/\nvoid axpy(double alpha, std::vector<double> const& x, std::vector<double> const& y, std::vector<double> &z) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\nvoid axpy(double alpha, std::vector<double> const& x, std::vector<double> const& y, std::vector<double> &z) {\n    #pragma omp simd\n    for (size_t i = 0; i < x.size(); ++i) {\n        z[i] = alpha * x[i] + y[i];\n    }\n}\n"
    ]
  },
  {
    "problem_type": "sort",
    "language": "cpp",
    "name": "41_sort_k-th_smallest_element",
    "parallelism_model": "omp",
    "prompt": "#include <omp.h>\n\n/* Find the k-th smallest element of the vector x.\n   Use OpenMP to compute in parallel.\n   Example:\n   \n   input: x=[1, 7, 6, 0, 2, 2, 10, 6], k=4\n   output: 6\n*/\nint findKthSmallest(std::vector<int> const& x, int k) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n    std::vector<int> copy = x;\n    #pragma omp parallel\n    {\n        #pragma omp single\n        {\n            #pragma omp taskgroup\n            {\n                #pragma omp task untied\n                std::sort(copy.begin(), copy.end());\n            }\n        }\n    }\n    return copy[k - 1];\n}\n"
    ]
  },
  {
    "problem_type": "sort",
    "language": "cpp",
    "name": "41_sort_k-th_smallest_element",
    "parallelism_model": "cuda",
    "prompt": "/* Find the k-th smallest element of the vector x.\n   Use CUDA to compute in parallel. The kernel is launched with at least as many threads as values in x.\n   Example:\n   \n   input: x=[1, 7, 6, 0, 2, 2, 10, 6], k=4\n   output: 6\n*/\n__global__ void findKthSmallest(const int *x, size_t N, int k, int *kthSmallest) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n    extern __shared__ int s_data[];\n    int tid = threadIdx.x;\n    int *heap = s_data;\n\n    // Initialize shared memory with input data\n    if (tid < N) {\n        heap[tid] = x[tid];\n    }\n    __syncthreads();\n\n    // Build a max-heap of size k\n    if (tid == 0) {\n        std::make_heap(heap, heap + k);\n\n        // Process remaining elements\n        for (size_t i = k; i < N; ++i) {\n            if (x[i] < heap[0]) {\n                std::pop_heap(heap, heap + k);\n                heap[k - 1] = x[i];\n                std::push_heap(heap, heap + k);\n            }\n        }\n\n        // The root of the heap is the k-th smallest element\n        *kthSmallest = heap[0];\n    }\n}\n"
    ]
  },
  {
    "problem_type": "sort",
    "language": "cpp",
    "name": "41_sort_k-th_smallest_element",
    "parallelism_model": "serial",
    "prompt": "/* Find the k-th smallest element of the vector x.\n   Example:\n   \n   input: x=[1, 7, 6, 0, 2, 2, 10, 6], k=4\n   output: 6\n*/\nint findKthSmallest(std::vector<int> const& x, int k) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\nint findKthSmallest(std::vector<int> const& x, int k) {\n    std::vector<int> copy = x;\n    std::nth_element(copy.begin(), copy.begin() + k - 1, copy.end());\n    return copy[k - 1];\n}\n"
    ]
  },
  {
    "problem_type": "sort",
    "language": "cpp",
    "name": "43_sort_sort_an_array_of_structs_by_key",
    "parallelism_model": "omp",
    "prompt": "#include <omp.h>\n\nstruct Result {\n   int startTime, duration;\n   float value;\n};\n\n/* Sort vector of Result structs by start time in ascending order.\n   Use OpenMP to sort in parallel.\n   Example:\n   \n   input: [{startTime=8, duration=4, value=-1.22}, {startTime=2, duration=10, value=1.0}, {startTime=10, duration=3, value=0.0}]\n   output: [{startTime=2, duration=10, value=1.0}, {startTime=8, duration=4, value=-1.22}, {startTime=10, duration=3, value=0.0}]\n*/\nvoid sortByStartTime(std::vector<Result> &results) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\nvoid sortByStartTime(std::vector<Result> &results) {\n    #pragma omp parallel\n    {\n        #pragma omp single\n        {\n            #pragma omp taskgroup\n            {\n                #pragma omp task untied\n                std::sort(results.begin(), results.end(), [](const Result &a, const Result &b) {\n                    return a.startTime < b.startTime;\n                });\n            }\n        }\n    }\n}\n"
    ]
  },
  {
    "problem_type": "sort",
    "language": "cpp",
    "name": "43_sort_sort_an_array_of_structs_by_key",
    "parallelism_model": "cuda",
    "prompt": "struct Result {\n   int startTime, duration;\n   float value;\n};\n\n/* Sort vector of Result structs by start time in ascending order.\n   Use CUDA to sort in parallel. The kernel is launched with at least as many threads as there are elements.\n   Example:\n   \n   input: [{startTime=8, duration=4, value=-1.22}, {startTime=2, duration=10, value=1.0}, {startTime=10, duration=3, value=0.0}]\n   output: [{startTime=2, duration=10, value=1.0}, {startTime=8, duration=4, value=-1.22}, {startTime=10, duration=3, value=0.0}]\n*/\n__global__ void sortByStartTime(Result *results, size_t N) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n  extern __shared__ Result sharedResults[];\n  int i = threadIdx.x;\n  if (i < N) {\n    sharedResults[i] = results[i];\n  }\n  __syncthreads();\n\n  for (int j = 1; j < N; j *= 2) {\n    if (i < N - j) {\n      Result a = sharedResults[i];\n      Result b = sharedResults[i + j];\n      if (a.startTime > b.startTime) {\n        sharedResults[i] = b;\n        sharedResults[i + j] = a;\n      }\n    }\n    __syncthreads();\n  }\n\n  if (i < N) {\n    results[i] = sharedResults[i];\n  }\n}\n"
    ]
  },
  {
    "problem_type": "sort",
    "language": "cpp",
    "name": "43_sort_sort_an_array_of_structs_by_key",
    "parallelism_model": "serial",
    "prompt": "struct Result {\n   int startTime, duration;\n   float value;\n};\n\n/* Sort vector of Result structs by start time in ascending order.\n   Example:\n   \n   input: [{startTime=8, duration=4, value=-1.22}, {startTime=2, duration=10, value=1.0}, {startTime=10, duration=3, value=0.0}]\n   output: [{startTime=2, duration=10, value=1.0}, {startTime=8, duration=4, value=-1.22}, {startTime=10, duration=3, value=0.0}]\n*/\nvoid sortByStartTime(std::vector<Result> &results) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\nvoid sortByStartTime(std::vector<Result> &results) {\n    std::sort(results.begin(), results.end(), [](const Result &a, const Result &b) {\n        return a.startTime < b.startTime;\n    });\n}\n"
    ]
  },
  {
    "problem_type": "sort",
    "language": "cpp",
    "name": "44_sort_sort_non-zero_elements",
    "parallelism_model": "omp",
    "prompt": "#include <omp.h>\n\n/* Sort the vector x in ascending order ignoring elements with value 0.\n   Leave zero valued elements in-place. \n\t Use OpenMP to sort x in parallel. \n   Example:\n\n   input: [8, 4, 0, 9, 8, 0, 1, -1, 7]\n   output: [-1, 1, 0, 4, 7, 0, 8, 8, 9]\n*/\nvoid sortIgnoreZero(std::vector<int> &x) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\nvoid sortIgnoreZero(std::vector<int> &x) {\n    std::vector<int> nonZero;\n    std::vector<int> zeroIndices;\n\n    #pragma omp parallel for\n    for (size_t i = 0; i < x.size(); ++i) {\n        if (x[i] != 0) {\n            #pragma omp critical\n            nonZero.push_back(x[i]);\n        } else {\n            #pragma omp critical\n            zeroIndices.push_back(i);\n        }\n    }\n\n    std::sort(std::execution::par, nonZero.begin(), nonZero.end());\n\n    std::vector<int> result(x.size());\n    size_t nzIndex = 0;\n    for (size_t i = 0; i < x.size(); ++i) {\n        if (std::find(zeroIndices.begin(), zeroIndices.end(), i) != zeroIndices.end()) {\n            result[i] = 0;\n        } else {\n            result[i] = nonZero[nzIndex++];\n        }\n    }\n\n    x = result;\n}\n"
    ]
  },
  {
    "problem_type": "sort",
    "language": "cpp",
    "name": "44_sort_sort_non-zero_elements",
    "parallelism_model": "cuda",
    "prompt": "/* Sort the array x in ascending order ignoring elements with value 0.\n   Leave zero valued elements in-place. \n\t Use CUDA to compute in parallel. The kernel will be launched with 1 thread per element.\n   Example:\n\n   input: [8, 4, 0, 9, 8, 0, 1, -1, 7]\n   output: [-1, 1, 0, 4, 7, 0, 8, 8, 9]\n*/\n__global__ void sortIgnoreZero(int *x, size_t N) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n    extern __shared__ int s_data[];\n    int idx = threadIdx.x + blockIdx.x * blockDim.x;\n    if (idx < N) {\n        s_data[threadIdx.x] = (x[idx] != 0) ? x[idx] : INT_MAX;\n    }\n    __syncthreads();\n    for (int stride = 1; stride < blockDim.x; stride *= 2) {\n        int val = s_data[threadIdx.x];\n        if (threadIdx.x >= stride) {\n            int neighbor = s_data[threadIdx.x - stride];\n            if (neighbor > val) {\n                s_data[threadIdx.x] = val;\n                s_data[threadIdx.x - stride] = neighbor;\n            }\n        }\n        __syncthreads();\n    }\n    if (idx < N && x[idx] != 0) {\n        x[idx] = s_data[threadIdx.x];\n    }\n}\n"
    ]
  },
  {
    "problem_type": "sort",
    "language": "cpp",
    "name": "44_sort_sort_non-zero_elements",
    "parallelism_model": "serial",
    "prompt": "/* Sort the vector x in ascending order ignoring elements with value 0.\n   Leave zero valued elements in-place.\n   Example:\n\n\t input: [8, 4, 0, 9, 8, 0, 1, -1, 7]\n   output: [-1, 1, 0, 4, 7, 0, 8, 8, 9]\n*/\nvoid sortIgnoreZero(std::vector<int> &x) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\nvoid sortIgnoreZero(std::vector<int> &x) {\n    std::vector<int> nonZero;\n    for (int val : x) {\n        if (val != 0) {\n            nonZero.push_back(val);\n        }\n    }\n    std::sort(nonZero.begin(), nonZero.end());\n    size_t nzIdx = 0;\n    for (size_t i = 0; i < x.size(); ++i) {\n        if (x[i] != 0) {\n            x[i] = nonZero[nzIdx++];\n        }\n    }\n}\n"
    ]
  },
  {
    "problem_type": "sort",
    "language": "cpp",
    "name": "40_sort_sort_an_array_of_complex_numbers_by_magnitude",
    "parallelism_model": "omp",
    "prompt": "#include <omp.h>\n\n/* Sort the vector x of complex numbers by their magnitude in ascending order.\n   Use OpenMP to sort in parallel.\n   Example:\n   \n   input: [3.0-1.0i, 4.5+2.1i, 0.0-1.0i, 1.0-0.0i, 0.5+0.5i]\n   output: [0.5+0.5i, 0.0-1.0i, 1.0-0.0i, 3.0-1.0i, 4.5+2.1i]\n*/\nvoid sortComplexByMagnitude(std::vector<std::complex<double>> &x) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\nvoid sortComplexByMagnitude(std::vector<std::complex<double>> &x) {\n    #pragma omp parallel\n    {\n        #pragma omp single\n        {\n            #pragma omp taskloop grainsize(1024)\n            for (size_t i = 0; i < x.size(); ++i) {\n                // No operation needed here; the actual sorting is done by the library\n            }\n        }\n    }\n    std::sort(std::execution::par, x.begin(), x.end(), [](const std::complex<double> &a, const std::complex<double> &b) {\n        return std::abs(a) < std::abs(b);\n    });\n}\n"
    ]
  },
  {
    "problem_type": "sort",
    "language": "cpp",
    "name": "40_sort_sort_an_array_of_complex_numbers_by_magnitude",
    "parallelism_model": "cuda",
    "prompt": "/* Sort the vector x of complex numbers by their magnitude in ascending order.\n   Use CUDA to sort in parallel. The kernel is launched with at least as many threads as elements in x.\n   Example:\n   \n   input: [3.0-1.0i, 4.5+2.1i, 0.0-1.0i, 1.0-0.0i, 0.5+0.5i]\n   output: [0.5+0.5i, 0.0-1.0i, 1.0-0.0i, 3.0-1.0i, 4.5+2.1i]\n*/\n__global__ void sortComplexByMagnitude(cuDoubleComplex *x, size_t N) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n    extern __shared__ cuDoubleComplex shared[];\n    size_t tid = threadIdx.x;\n    size_t i = tid;\n\n    // Load elements into shared memory\n    if (i < N) {\n        shared[i] = x[i];\n    }\n    __syncthreads();\n\n    // Bitonic sort\n    for (size_t j = 1; j < N; j <<= 1) {\n        for (size_t k = j; k > 0; k >>= 1) {\n            size_t ix0 = i ^ 0;\n            size_t ix1 = i ^ k;\n            if (ix0 < N && ix1 < N) {\n                cuDoubleComplex a = shared[ix0];\n                cuDoubleComplex b = shared[ix1];\n                double magA = cuCabs(a);\n                double magB = cuCabs(b);\n                if (( (i & (2 * k)) == 0 ) ? (magA > magB) : (magA < magB)) {\n                    shared[ix0] = b;\n                    shared[ix1] = a;\n                }\n            }\n            __syncthreads();\n        }\n    }\n\n    // Write result back to global memory\n    if (i < N) {\n        x[i] = shared[i];\n    }\n}\n"
    ]
  },
  {
    "problem_type": "sort",
    "language": "cpp",
    "name": "40_sort_sort_an_array_of_complex_numbers_by_magnitude",
    "parallelism_model": "serial",
    "prompt": "/* Sort the vector x of complex numbers by their magnitude in ascending order.\n   Example:\n   \n   input: [3.0-1.0i, 4.5+2.1i, 0.0-1.0i, 1.0-0.0i, 0.5+0.5i]\n   output: [0.5+0.5i, 0.0-1.0i, 1.0-0.0i, 3.0-1.0i, 4.5+2.1i]\n*/\nvoid sortComplexByMagnitude(std::vector<std::complex<double>> &x) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n    std::sort(x.begin(), x.end(), [](const std::complex<double> &a, const std::complex<double> &b) {\n        return std::abs(a) < std::abs(b);\n    });\n}\n"
    ]
  },
  {
    "problem_type": "sort",
    "language": "cpp",
    "name": "42_sort_sorted_ranks",
    "parallelism_model": "omp",
    "prompt": "#include <omp.h>\n\n/* For each value in the vector x compute its index in the sorted vector.\n   Store the results in `ranks`.\n   Use OpenMP to compute in parallel.\n   Examples:\n\n   input: [3.1, 2.8, 9.1, 0.4, 3.14]\n   output: [2, 1, 4, 0, 3]\n \n   input: [100, 7.6, 16.1, 18, 7.6]\n   output: [4, 0, 1, 2, 3]\n*/\nvoid ranks(std::vector<float> const& x, std::vector<size_t> &ranks) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n{\n    const size_t n = x.size();\n    ranks.resize(n);\n    std::vector<size_t> indices(n);\n    for (size_t i = 0; i < n; ++i) {\n        indices[i] = i;\n    }\n\n    // Sort the indices based on the corresponding values in x\n    std::sort(indices.begin(), indices.end(), [&](size_t a, size_t b) {\n        return x[a] < x[b];\n    });\n\n    // Assign ranks using parallelization\n    #pragma omp parallel for schedule(dynamic) num_threads(32)\n    for (size_t i = 0; i < n; ++i) {\n        ranks[indices[i]] = i;\n    }\n}\n"
    ]
  },
  {
    "problem_type": "sort",
    "language": "cpp",
    "name": "42_sort_sorted_ranks",
    "parallelism_model": "cuda",
    "prompt": "/* For each value in the vector x compute its index in the sorted vector.\n   Store the results in `ranks`.\n   Use CUDA to compute in parallel. The kernel will be launched with at least as many threads as elements in x.\n   Examples:\n\n   input: [3.1, 2.8, 9.1, 0.4, 3.14]\n   output: [2, 1, 4, 0, 3]\n \n   input: [100, 7.6, 16.1, 18, 7.6]\n   output: [4, 0, 1, 2, 3]\n*/\n__global__ void ranks(const float *x, size_t *ranks, size_t N) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n  extern __shared__ float shared_x[];\n  size_t tid = threadIdx.x + blockIdx.x * blockDim.x;\n  if (tid < N) {\n    shared_x[tid] = x[tid];\n  }\n  __syncthreads();\n\n  if (tid < N) {\n    size_t rank = 0;\n    for (size_t i = 0; i < N; ++i) {\n      if (shared_x[i] < shared_x[tid]) {\n        ++rank;\n      }\n    }\n    ranks[tid] = rank;\n  }\n}\n"
    ]
  },
  {
    "problem_type": "sort",
    "language": "cpp",
    "name": "42_sort_sorted_ranks",
    "parallelism_model": "serial",
    "prompt": "/* For each value in the vector x compute its index in the sorted vector.\n   Store the results in `ranks`.\n   Examples:\n\n   input: [3.1, 2.8, 9.1, 0.4, 3.14]\n   output: [2, 1, 4, 0, 3]\n \n   input: [100, 7.6, 16.1, 18, 7.6]\n   output: [4, 0, 1, 2, 3]\n*/\nvoid ranks(std::vector<float> const& x, std::vector<size_t> &ranks) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n    const size_t n = x.size();\n    ranks.resize(n);\n    std::vector<size_t> indices(n);\n    for (size_t i = 0; i < n; ++i) {\n        indices[i] = i;\n    }\n    std::sort(indices.begin(), indices.end(), [&](size_t a, size_t b) {\n        return x[a] < x[b];\n    });\n    for (size_t i = 0; i < n; ++i) {\n        ranks[indices[i]] = i;\n    }\n}\n"
    ]
  },
  {
    "problem_type": "sparse_la",
    "language": "cpp",
    "name": "46_sparse_la_spmm",
    "parallelism_model": "omp",
    "prompt": "#include <omp.h>\n\nstruct COOElement {\n   size_t row, column;\n   double value;\n};\n\n/* Compute the matrix multiplication Y=AX. A is a sparse MxK matrix in COO format.\n   X is a sparse KxN matrix in COO format. Y is a dense MxN matrix in row-major.\n   Use OpenMP to compute in parallel.\n   Example:\n\n   input: A=[{0,0,-2}, {0,1,1}, {1,1,-1}] X=[{0,1,2}, {1,0,-1}]\n   output: Y=[{-1,-4}, {1,0}]\n*/\nvoid spmm(std::vector<COOElement> const& A, std::vector<COOElement> const& X, std::vector<double> &Y, size_t M, size_t K, size_t N) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n#pragma omp parallel for schedule(guided) num_threads(32)\nfor (size_t i = 0; i < M; ++i) {\n    for (size_t j = 0; j < N; ++j) {\n        double sum = 0.0;\n        for (auto const& a : A) {\n            if (a.row == i) {\n                for (auto const& x : X) {\n                    if (x.column == j && x.row == a.column) {\n                        sum += a.value * x.value;\n                    }\n                }\n            }\n        }\n        Y[i * N + j] = sum;\n    }\n}\n"
    ]
  },
  {
    "problem_type": "sparse_la",
    "language": "cpp",
    "name": "46_sparse_la_spmm",
    "parallelism_model": "cuda",
    "prompt": "struct COOElement {\n   size_t row, column;\n   double value;\n};\n\n/* Compute the matrix multiplication Y=AX. A is a sparse MxK matrix in COO format with sizeA elements.\n   X is a sparse KxN matrix in COO format with sizeX elements. Y is a dense MxN matrix in row-major.\n   Use CUDA to compute in parallel. The kernel is launched with at least sizeA threads.\n   Example:\n\n   input: A=[{0,0,-2}, {0,1,1}, {1,1,-1}] X=[{0,1,2}, {1,0,-1}]\n   output: Y=[{-1,-4}, {1,0}]\n*/\n__global__ void spmm(const COOElement *A, size_t sizeA, const COOElement *X, size_t sizeX, double *Y, size_t M, size_t K, size_t N) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n   size_t idx = blockIdx.x * blockDim.x + threadIdx.x;\n   if (idx >= sizeA) return;\n\n   COOElement a = A[idx];\n   for (size_t i = 0; i < sizeX; ++i) {\n       COOElement x = X[i];\n       if (a.column == x.row) {\n           size_t y_row = a.row;\n           size_t y_col = x.column;\n           double product = a.value * x.value;\n           atomicAdd(Y + y_row * N + y_col, product);\n       }\n   }\n}\n"
    ]
  },
  {
    "problem_type": "sparse_la",
    "language": "cpp",
    "name": "46_sparse_la_spmm",
    "parallelism_model": "serial",
    "prompt": "struct COOElement {\n   size_t row, column;\n   double value;\n};\n\n/* Compute the matrix multiplication Y=AX. A is a sparse MxK matrix in COO format.\n   X is a sparse KxN matrix in COO format. Y is a dense MxN matrix in row-major.\n   Example:\n\n   input: A=[{0,0,-2}, {0,1,1}, {1,1,-1}] X=[{0,1,2}, {1,0,-1}]\n   output: Y=[{-1,-4}, {1,0}]\n*/\nvoid spmm(std::vector<COOElement> const& A, std::vector<COOElement> const& X, std::vector<double> &Y, size_t M, size_t K, size_t N) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n   #pragma omp parallel for\n   for (size_t i = 0; i < M; ++i) {\n       for (size_t j = 0; j < N; ++j) {\n           Y[i * N + j] = 0.0;\n       }\n   }\n\n   #pragma omp parallel for\n   for (size_t a_idx = 0; a_idx < A.size(); ++a_idx) {\n       COOElement const& a = A[a_idx];\n       size_t row_a = a.row;\n       size_t col_a = a.column;\n       double val_a = a.value;\n\n       for (size_t x_idx = 0; x_idx < X.size(); ++x_idx) {\n           COOElement const& x = X[x_idx];\n           size_t row_x = x.row;\n           size_t col_x = x.column;\n           double val_x = x.value;\n\n           if (col_a == row_x) {\n               Y[row_a * N + col_x] += val_a * val_x;\n           }\n       }\n   }\n}\n"
    ]
  },
  {
    "problem_type": "sparse_la",
    "language": "cpp",
    "name": "47_sparse_la_spmv",
    "parallelism_model": "omp",
    "prompt": "#include <omp.h>\n\nstruct COOElement {\n   size_t row, column;\n   double value;\n};\n\n/* Compute y = alpha*A*x + beta*y where alpha and beta are scalars, x and y are vectors,\n   and A is a sparse matrix stored in COO format.\n   A has dimensions MxN, x has N values, and y has M values.\n   Use OpenMP to parallelize.\n   Example:\n\n   input: alpha=0.5 beta=1.0 A=[{0,1,3}, {1,0,-1}] x=[-4, 2] y=[-1,1]\n   output: y=[2, 3]\n*/\nvoid spmv(double alpha, std::vector<COOElement> const& A, std::vector<double> const& x, double beta, std::vector<double> &y, size_t M, size_t N) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n   if (beta != 1.0) {\n      #pragma omp parallel for simd schedule(guided)\n      for (size_t i = 0; i < M; ++i) {\n         y[i] *= beta;\n      }\n   }\n\n   #pragma omp parallel\n   {\n      std::vector<double> local_y(M, 0.0);\n      #pragma omp for schedule(guided)\n      for (size_t i = 0; i < A.size(); ++i) {\n         local_y[A[i].row] += alpha * A[i].value * x[A[i].column];\n      }\n\n      #pragma omp critical\n      {\n         for (size_t i = 0; i < M; ++i) {\n            y[i] += local_y[i];\n         }\n      }\n   }\n}\n"
    ]
  },
  {
    "problem_type": "sparse_la",
    "language": "cpp",
    "name": "47_sparse_la_spmv",
    "parallelism_model": "cuda",
    "prompt": "struct COOElement {\n   size_t row, column;\n   double value;\n};\n\n/* Compute y = alpha*A*x + beta*y where alpha and beta are scalars, x and y are vectors,\n   and A is a sparse matrix stored in COO format with sizeA elements.\n   A has dimensions MxN, x has N values, and y has M values.\n   Use CUDA to parallelize. The kernel will be launched with at least sizeA threads.\n   Example:\n\n   input: alpha=0.5 beta=1.0 A=[{0,1,3}, {1,0,-1}] x=[-4, 2] y=[-1,1]\n   output: y=[2, 3]\n*/\n__global__ void spmv(double alpha, const COOElement *A, size_t sizeA, const double *x, double beta, double *y, size_t M, size_t N) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n   size_t idx = blockIdx.x * blockDim.x + threadIdx.x;\n   if (idx < sizeA) {\n      COOElement element = A[idx];\n      size_t row = element.row;\n      size_t column = element.column;\n      double val = alpha * element.value * x[column];\n      atomicAdd(&y[row], val);\n   }\n}\n"
    ]
  },
  {
    "problem_type": "sparse_la",
    "language": "cpp",
    "name": "47_sparse_la_spmv",
    "parallelism_model": "serial",
    "prompt": "struct COOElement {\n   size_t row, column;\n   double value;\n};\n\n/* Compute y = alpha*A*x + beta*y where alpha and beta are scalars, x and y are vectors,\n   and A is a sparse matrix stored in COO format.\n   A has dimensions MxN, x has N values, and y has M values.\n   Example:\n\n   input: alpha=0.5 beta=1.0 A=[{0,1,3}, {1,0,-1}] x=[-4, 2] y=[-1,1]\n   output: y=[2, 3]\n*/\nvoid spmv(double alpha, std::vector<COOElement> const& A, std::vector<double> const& x, double beta, std::vector<double> &y, size_t M, size_t N) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n   if (beta != 1.0) {\n      for (size_t i = 0; i < M; ++i) {\n         y[i] *= beta;\n      }\n   }\n   if (alpha == 0.0) return;\n   for (const auto& elem : A) {\n      y[elem.row] += alpha * elem.value * x[elem.column];\n   }\n}\n"
    ]
  },
  {
    "problem_type": "sparse_la",
    "language": "cpp",
    "name": "48_sparse_la_sparse_axpy",
    "parallelism_model": "omp",
    "prompt": "#include <omp.h>\n\nstruct Element {\n\tsize_t index;\n  double value;\n};\n\n/* Compute z = alpha*x+y where x and y are sparse vectors. Store the result in the dense vector z.\n   Use OpenMP to compute in parallel.\n   Example:\n   \n   input: x=[{5, 12}, {8, 3}, {12, -1}], y=[{3, 1}, {5, -2}, {7, 1}, {8, -3}], alpha=1\n   output: z=[0, 0, 0, 1, 0, 10, 0, 1, 0, 0, 0, 0, -1]\n*/\nvoid sparseAxpy(double alpha, std::vector<Element> const& x, std::vector<Element> const& y, std::vector<double> &z) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n#pragma omp parallel\n{\n    #pragma omp for schedule(guided)\n    for (size_t i = 0; i < x.size(); ++i) {\n        size_t idx = x[i].index;\n        #pragma omp atomic\n        z[idx] += alpha * x[i].value;\n    }\n\n    #pragma omp for schedule(guided)\n    for (size_t i = 0; i < y.size(); ++i) {\n        size_t idx = y[i].index;\n        #pragma omp atomic\n        z[idx] += y[i].value;\n    }\n}\n"
    ]
  },
  {
    "problem_type": "sparse_la",
    "language": "cpp",
    "name": "48_sparse_la_sparse_axpy",
    "parallelism_model": "cuda",
    "prompt": "struct Element {\n\tsize_t index;\n  double value;\n};\n\n/* Compute z = alpha*x+y where x and y are sparse vectors of size Nx and Ny. Store the result in the dense vector z.\n   Use CUDA to compute in parallel. The kernel is launched with at least as many threads as values in x or y.\n   Example:\n   \n   input: x=[{5, 12}, {8, 3}, {12, -1}], y=[{3, 1}, {5, -2}, {7, 1}, {8, -3}], alpha=1\n   output: z=[0, 0, 0, 1, 0, 10, 0, 1, 0, 0, 0, 0, -1]\n*/\n__global__ void sparseAxpy(double alpha, const Element *x, const Element *y, double *z, size_t Nx, size_t Ny, size_t N) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n  size_t i = blockIdx.x * blockDim.x + threadIdx.x;\n  if (i < Nx) {\n    size_t idx = x[i].index;\n    if (idx < N) {\n      z[idx] += alpha * x[i].value;\n    }\n  }\n  if (i < Ny) {\n    size_t idx = y[i].index;\n    if (idx < N) {\n      z[idx] += y[i].value;\n    }\n  }\n}\n"
    ]
  },
  {
    "problem_type": "sparse_la",
    "language": "cpp",
    "name": "48_sparse_la_sparse_axpy",
    "parallelism_model": "serial",
    "prompt": "struct Element {\n\tsize_t index;\n  double value;\n};\n\n/* Compute z = alpha*x+y where x and y are sparse vectors. Store the result in the dense vector z.\n   Example:\n   \n   input: x=[{5, 12}, {8, 3}, {12, -1}], y=[{3, 1}, {5, -2}, {7, 1}, {8, -3}], alpha=1\n   output: z=[0, 0, 0, 1, 0, 10, 0, 1, 0, 0, 0, 0, -1]\n*/\nvoid sparseAxpy(double alpha, std::vector<Element> const& x, std::vector<Element> const& y, std::vector<double> &z) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n  size_t nx = x.size();\n  size_t ny = y.size();\n  size_t ix = 0;\n  size_t iy = 0;\n\n  while (ix < nx && iy < ny) {\n    size_t jx = x[ix].index;\n    size_t jy = y[iy].index;\n    if (jx == jy) {\n      z[jx] += alpha * x[ix].value + y[iy].value;\n      ++ix;\n      ++iy;\n    } else if (jx < jy) {\n      z[jx] += alpha * x[ix].value;\n      ++ix;\n    } else {\n      z[jy] += y[iy].value;\n      ++iy;\n    }\n  }\n\n  while (ix < nx) {\n    size_t jx = x[ix].index;\n    z[jx] += alpha * x[ix].value;\n    ++ix;\n  }\n\n  while (iy < ny) {\n    size_t jy = y[iy].index;\n    z[jy] += y[iy].value;\n    ++iy;\n  }\n}\n"
    ]
  },
  {
    "problem_type": "sparse_la",
    "language": "cpp",
    "name": "45_sparse_la_sparse_solve",
    "parallelism_model": "omp",
    "prompt": "#include <omp.h>\n\nstruct COOElement {\n   size_t row, column;\n   double value;\n};\n\n/* Solve the sparse linear system Ax=b for x.\n   A is a sparse NxN matrix in COO format. x and b are dense vectors with N elements.\n   Use OpenMP to compute in parallel.\n   Example:\n   \n   input: A=[{0,0,1}, {0,1,1}, {1,1,-2}] b=[1,4]\n   output: x=[3,-2]\n*/\nvoid solveLinearSystem(std::vector<COOElement> const& A, std::vector<double> const& b, std::vector<double> &x, size_t N) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n#pragma omp parallel\n{\n    size_t num_threads = omp_get_num_threads();\n    size_t thread_id = omp_get_thread_num();\n\n    // Partition the system for each thread\n    size_t chunk_size = N / num_threads;\n    size_t start = thread_id * chunk_size;\n    size_t end = (thread_id == num_threads - 1) ? N : start + chunk_size;\n\n    // Local accumulation of matrix rows\n    std::vector<std::vector<double>> local_A(num_threads, std::vector<double>(N, 0.0));\n    std::vector<std::vector<double>> local_b(num_threads, std::vector<double>(N, 0.0));\n\n    // Distribute the COO elements among threads\n    #pragma omp for schedule(static)\n    for (size_t i = 0; i < A.size(); ++i) {\n        size_t row = A[i].row;\n        size_t column = A[i].column;\n        double val = A[i].value;\n        #pragma omp critical\n        {\n            local_A[row][column] += val;\n        }\n    }\n\n    // Combine local matrices into global\n    std::vector<std::vector<double>> global_A(N, std::vector<double>(N, 0.0));\n    std::vector<double> global_b(N, 0.0);\n    #pragma omp for schedule(static)\n    for (size_t row = 0; row < N; ++row) {\n        for (size_t thread = 0; thread < num_threads; ++thread) {\n            for (size_t col = 0; col < N; ++col) {\n                global_A[row][col] += local_A[thread][col];\n            }\n            global_b[row] += local_b[thread][row];\n        }\n    }\n\n    // Solve the system using Gaussian elimination or LU decomposition\n    #pragma omp single\n    {\n        // Perform Gaussian elimination on global_A and global_b\n        for (size_t i = 0; i < N; ++i) {\n            // Normalize the pivot row\n            double pivot = global_A[i][i];\n            if (pivot != 0.0) {\n                for (size_t j = i; j < N; ++j) {\n                    global_A[i][j] /= pivot;\n                }\n                global_b[i] /= pivot;\n            }\n\n            // Eliminate other rows\n            for (size_t k = 0; k < N; ++k) {\n                if (k != i && global_A[k][i] != 0.0) {\n                    double factor = global_A[k][i];\n                    for (size_t j = i; j < N; ++j) {\n                        global_A[k][j] -= factor * global_A[i][j];\n                    }\n                    global_b[k] -= factor * global_b[i];\n                }\n            }\n        }\n\n        // Back-substitution to get x\n        x.resize(N);\n        for (size_t i = N - 1; i < N; --i) {\n            double sum = 0.0;\n            for (size_t j = i + 1; j < N; ++j) {\n                sum += global_A[i][j] * x[j];\n            }\n            x[i] = global_b[i] - sum;\n        }\n    }\n}\n"
    ]
  },
  {
    "problem_type": "sparse_la",
    "language": "cpp",
    "name": "45_sparse_la_sparse_solve",
    "parallelism_model": "cuda",
    "prompt": "struct COOElement {\n   size_t row, column;\n   double value;\n};\n\n/* Solve the sparse linear system Ax=b for x.\n   A is a sparse NxN matrix in COO format with sizeA elements. x and b are dense vectors with N elements.\n   Use CUDA to compute in parallel. The kernel is launched with at least sizeA threads.\n   Example:\n   \n   input: A=[{0,0,1}, {0,1,1}, {1,1,-2}] b=[1,4]\n   output: x=[3,-2]\n*/\n__global__ void solveLinearSystem(const COOElement *A, size_t sizeA, const double *b, double *x, size_t N) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n{\n    extern __shared__ double shared_A[];\n    size_t tid = threadIdx.x + blockIdx.x * blockDim.x;\n    size_t stride = blockDim.x * gridDim.x;\n\n    for (size_t i = tid; i < N; i += stride) {\n        double sum = 0.0;\n        for (size_t j = 0; j < sizeA; j++) {\n            if (A[j].row == i) {\n                sum += A[j].value * x[A[j].column];\n            }\n        }\n        x[i] = (b[i] - sum) / 1.0; // Assuming diagonal dominance or preconditioning\n    }\n}\n"
    ]
  },
  {
    "problem_type": "sparse_la",
    "language": "cpp",
    "name": "45_sparse_la_sparse_solve",
    "parallelism_model": "serial",
    "prompt": "struct COOElement {\n   size_t row, column;\n   double value;\n};\n\n/* Solve the sparse linear system Ax=b for x.\n   A is a sparse NxN matrix in COO format. x and b are dense vectors with N elements.\n   Example:\n   \n   input: A=[{0,0,1}, {0,1,1}, {1,1,-2}] b=[1,4]\n   output: x=[3,-2]\n*/\nvoid solveLinearSystem(std::vector<COOElement> const& A, std::vector<double> const& b, std::vector<double> &x, size_t N) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\nvoid solveLinearSystem(std::vector<COOElement> const& A, std::vector<double> const& b, std::vector<double> &x, size_t N) {\n    std::vector<std::vector<std::pair<size_t, double>>> rowEntries(N);\n    for (const auto& elem : A) {\n        rowEntries[elem.row].emplace_back(elem.column, elem.value);\n    }\n    x.resize(N);\n    for (size_t i = 0; i < N; ++i) {\n        double sum = 0.0;\n        for (const auto& entry : rowEntries[i]) {\n            if (entry.first != i) {\n                sum += entry.second * x[entry.first];\n            }\n        }\n        x[i] = (b[i] - sum) / rowEntries[i].back().second;\n    }\n}\n"
    ]
  },
  {
    "problem_type": "sparse_la",
    "language": "cpp",
    "name": "49_sparse_la_sparse_lu_decomp",
    "parallelism_model": "omp",
    "prompt": "#include <omp.h>\n\nstruct COOElement {\n   size_t row, column;\n   double value;\n};\n\n/* Factorize the sparse matrix A into A=LU where L is a lower triangular matrix and U is an upper triangular matrix.\n   A is a sparse NxN matrix stored in COO format.\n   Use OpenMP to compute in parallel.\n   Example:\n\n   input: A=[{0,0,4}, {0,1,3}, {1,0,6}, {1,1,3}]\n   output: L=[{0,0,1},{1,0,1.5}, {1,1,1}] U=[{0,0,4}, {0,1,3}, {1,1,-1.5}]\n*/\nvoid luFactorize(std::vector<COOElement> const& A, std::vector<double> &L, std::vector<double> &U, size_t N) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\nvoid luFactorize(std::vector<COOElement> const& A, std::vector<double> &L, std::vector<double> &U, size_t N) {\n    std::vector<std::vector<double>> Lmat(N, std::vector<double>(N, 0.0));\n    std::vector<std::vector<double>> Umat(N, std::vector<double>(N, 0.0));\n\n    #pragma omp parallel for schedule(dynamic) num_threads(32)\n    for (size_t i = 0; i < N; ++i) {\n        Lmat[i][i] = 1.0;\n    }\n\n    for (size_t k = 0; k < N; ++k) {\n        #pragma omp parallel for schedule(dynamic) num_threads(32)\n        for (size_t j = k; j < N; ++j) {\n            double sum = 0.0;\n            for (size_t m = 0; m < k; ++m) {\n                sum += Lmat[k][m] * Umat[m][j];\n            }\n            Umat[k][j] = A[k * N + j].value - sum;\n        }\n\n        #pragma omp parallel for schedule(dynamic) num_threads(32)\n        for (size_t i = k + 1; i < N; ++i) {\n            double sum = 0.0;\n            for (size_t m = 0; m < k; ++m) {\n                sum += Lmat[i][m] * Umat[m][k];\n            }\n            Lmat[i][k] = (A[i * N + k].value - sum) / Umat[k][k];\n        }\n    }\n\n    #pragma omp parallel for schedule(dynamic) num_threads(32)\n    for (size_t i = 0; i < N; ++i) {\n        for (size_t j = 0; j <= i; ++j) {\n            L.push_back(Lmat[i][j]);\n        }\n    }\n\n    #pragma omp parallel for schedule(dynamic) num_threads(32)\n    for (size_t i = 0; i < N; ++i) {\n        for (size_t j = i; j < N; ++j) {\n            U.push_back(Umat[i][j]);\n        }\n    }\n}\n"
    ]
  },
  {
    "problem_type": "sparse_la",
    "language": "cpp",
    "name": "49_sparse_la_sparse_lu_decomp",
    "parallelism_model": "cuda",
    "prompt": "struct COOElement {\n   size_t row, column;\n   double value;\n};\n\n/* Factorize the sparse matrix A into A=LU where L is a lower triangular matrix and U is an upper triangular matrix.\n   A is a sparse NxN matrix stored in COO format with sizeA elements.\n   Use CUDA to compute in parallel. The kernel is launched with at least sizeA threads.\n   Example:\n\n   input: A=[{0,0,4}, {0,1,3}, {1,0,6}, {1,1,3}]\n   output: L=[{0,0,1},{1,0,1.5}, {1,1,1}] U=[{0,0,4}, {0,1,3}, {1,1,-1.5}]\n*/\n__global__ void luFactorize(const COOElement *A, size_t sizeA, double *L, double *U, size_t N) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n   size_t idx = threadIdx.x + blockIdx.x * blockDim.x;\n   if (idx >= sizeA) return;\n\n   COOElement element = A[idx];\n   size_t row = element.row;\n   size_t col = element.column;\n   double value = element.value;\n\n   if (row == col) {\n       atomicAdd(&U[row * N + col], value);\n   } else if (row > col) {\n       double sum = 0.0;\n       for (size_t k = 0; k < col; ++k) {\n           sum += L[row * N + k] * U[k * N + col];\n       }\n       double lValue = (value - sum) / U[col * N + col];\n       atomicAdd(&L[row * N + col], lValue);\n   } else {\n       double sum = 0.0;\n       for (size_t k = 0; k < row; ++k) {\n           sum += L[row * N + k] * U[k * N + col];\n       }\n       double uValue = value - sum;\n       atomicAdd(&U[row * N + col], uValue);\n   }\n}\n"
    ]
  },
  {
    "problem_type": "sparse_la",
    "language": "cpp",
    "name": "49_sparse_la_sparse_lu_decomp",
    "parallelism_model": "serial",
    "prompt": "struct COOElement {\n   size_t row, column;\n   double value;\n};\n\n/* Factorize the sparse matrix A into A=LU where L is a lower triangular matrix and U is an upper triangular matrix.\n   A is a sparse NxN matrix stored in COO format.\n   Example:\n\n   input: A=[{0,0,4}, {0,1,3}, {1,0,6}, {1,1,3}]\n   output: L=[{0,0,1},{1,0,1.5}, {1,1,1}] U=[{0,0,4}, {0,1,3}, {1,1,-1.5}]\n*/\nvoid luFactorize(std::vector<COOElement> const& A, std::vector<double> &L, std::vector<double> &U, size_t N) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\nvoid luFactorize(std::vector<COOElement> const& A, std::vector<double> &L, std::vector<double> &U, size_t N) {\n    std::vector<std::vector<double>> Lmat(N, std::vector<double>(N, 0.0));\n    std::vector<std::vector<double>> Umat(N, std::vector<double>(N, 0.0));\n\n    for (auto const& elem : A) {\n        Umat[elem.row][elem.column] = elem.value;\n    }\n\n    for (size_t i = 0; i < N; ++i) {\n        Lmat[i][i] = 1.0;\n    }\n\n    for (size_t i = 0; i < N; ++i) {\n        for (size_t k = i; k < N; ++k) {\n            double sum = 0.0;\n            for (size_t j = 0; j < i; ++j) {\n                sum += Lmat[i][j] * Umat[j][k];\n            }\n            Umat[i][k] -= sum;\n        }\n\n        for (size_t k = i + 1; k < N; ++k) {\n            double sum = 0.0;\n            for (size_t j = 0; j < i; ++j) {\n                sum += Lmat[k][j] * Umat[j][i];\n            }\n            Lmat[k][i] = (Umat[k][i] - sum) / Umat[i][i];\n        }\n    }\n\n    L.clear();\n    U.clear();\n    L.resize(N * N, 0.0);\n    U.resize(N * N, 0.0);\n\n    for (size_t i = 0; i < N; ++i) {\n        for (size_t j = 0; j <= i; ++j) {\n            L[i * N + j] = Lmat[i][j];\n        }\n        for (size_t j = i; j < N; ++j) {\n            U[i * N + j] = Umat[i][j];\n        }\n    }\n}\n"
    ]
  },
  {
    "problem_type": "stencil",
    "language": "cpp",
    "name": "50_stencil_xor_kernel",
    "parallelism_model": "omp",
    "prompt": "#include <omp.h>\n\n/* Set every cell's value to 1 if it has exactly one neighbor that's a 1. Otherwise set it to 0.\n   Note that we only consider neighbors and not input_{i,j} when computing output_{i,j}.\n   input and output are NxN grids of ints in row-major.\n   Use OpenMP to compute in parallel.\n   Example:\n\n   input: [[0, 1, 1, 0],\n           [1, 0, 0, 0],\n           [0, 0, 0, 0],\n           [0, 1, 0, 0]\n   output: [[0, 0, 1, 1],\n            [1, 0, 0, 1],\n            [0, 0, 1, 0],\n            [1, 0, 1, 0]]\n*/\nvoid cellsXOR(std::vector<int> const& input, std::vector<int> &output, size_t N) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n#pragma omp parallel for schedule(guided) num_threads(32)\n    for (size_t i = 0; i < N; ++i) {\n        for (size_t j = 0; j < N; ++j) {\n            int count = 0;\n            for (size_t dx = -1; dx <= 1; ++dx) {\n                for (size_t dy = -1; dy <= 1; ++dy) {\n                    if (dx == 0 && dy == 0) continue;\n                    size_t x = i + dx;\n                    size_t y = j + dy;\n                    if (x < N && y < N) {\n                        count += input[x * N + y];\n                    }\n                }\n            }\n            output[i * N + j] = (count == 1) ? 1 : 0;\n        }\n    }\n}\n"
    ]
  },
  {
    "problem_type": "stencil",
    "language": "cpp",
    "name": "50_stencil_xor_kernel",
    "parallelism_model": "cuda",
    "prompt": "/* Set every cell's value to 1 if it has exactly one neighbor that's a 1. Otherwise set it to 0.\n   Note that we only consider neighbors and not input_{i,j} when computing output_{i,j}.\n   input and output are NxN grids of ints in row-major.\n   Use CUDA to compute in parallel. The kernel is launched on an NxN grid of threads.\n   Example:\n\n   input: [[0, 1, 1, 0],\n           [1, 0, 0, 0],\n           [0, 0, 0, 0],\n           [0, 1, 0, 0]\n   output: [[0, 0, 1, 1],\n            [1, 0, 0, 1],\n            [0, 0, 1, 0],\n            [1, 0, 1, 0]]\n*/\n__global__ void cellsXOR(const int *input, int *output, size_t N) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n    int i = blockIdx.y * blockDim.y + threadIdx.y;\n    int j = blockIdx.x * blockDim.x + threadIdx.x;\n\n    if (i >= N || j >= N) return;\n\n    int count = 0;\n    for (int dx = -1; dx <= 1; ++dx) {\n        for (int dy = -1; dy <= 1; ++dy) {\n            if (dx == 0 && dy == 0) continue;\n            int ni = i + dx;\n            int nj = j + dy;\n            if (ni >= 0 && ni < N && nj >= 0 && nj < N) {\n                count += input[ni * N + nj];\n            }\n        }\n    }\n\n    output[i * N + j] = (count == 1) ? 1 : 0;\n}\n"
    ]
  },
  {
    "problem_type": "stencil",
    "language": "cpp",
    "name": "50_stencil_xor_kernel",
    "parallelism_model": "serial",
    "prompt": "/* Set every cell's value to 1 if it has exactly one neighbor that's a 1. Otherwise set it to 0.\n   Note that we only consider neighbors and not input_{i,j} when computing output_{i,j}.\n   input and output are NxN grids of ints in row-major.\n   Example:\n\n   input: [[0, 1, 1, 0],\n           [1, 0, 0, 0],\n           [0, 0, 0, 0],\n           [0, 1, 0, 0]\n   output: [[0, 0, 1, 1],\n            [1, 0, 0, 1],\n            [0, 0, 1, 0],\n            [1, 0, 1, 0]]\n*/\nvoid cellsXOR(std::vector<int> const& input, std::vector<int> &output, size_t N) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\nvoid cellsXOR(std::vector<int> const& input, std::vector<int> &output, size_t N) {\n    output.resize(N * N);\n    for (size_t i = 0; i < N; ++i) {\n        for (size_t j = 0; j < N; ++j) {\n            int count = 0;\n            for (int dx = -1; dx <= 1; ++dx) {\n                for (int dy = -1; dy <= 1; ++dy) {\n                    if (dx == 0 && dy == 0) continue;\n                    size_t x = i + dx;\n                    size_t y = j + dy;\n                    if (x < N && y < N) {\n                        count += input[x * N + y];\n                    }\n                }\n            }\n            output[i * N + j] = (count == 1) ? 1 : 0;\n        }\n    }\n}\n"
    ]
  },
  {
    "problem_type": "stencil",
    "language": "cpp",
    "name": "51_stencil_edge_kernel",
    "parallelism_model": "omp",
    "prompt": "#include <omp.h>\n\nconst int edgeKernel[3][3] = {{-1, -1, -1}, {-1, 8, -1}, {-1, -1, -1}};\n\n/* Convolve the edge kernel with a grayscale image. Each pixel will be replaced with\n   the dot product of itself and its neighbors with the edge kernel.\n   Use a value of 0 for pixels outside the image's boundaries and clip outputs between 0 and 255.\n   imageIn and imageOut are NxN grayscale images stored in row-major.\n   Store the output of the computation in imageOut.\n   Use OpenMP to compute in parallel.\n   Example:\n\n   input: [[112, 118, 141, 152],\n           [93, 101, 119, 203],\n           [45, 17, 16, 232],\n           [82, 31, 49, 101]]\n   output: [[255, 255, 255, 255],\n            [255, 147, 0, 255],\n            [36, 0, 0, 255],\n            [255, 39, 0, 255]]\n*/\nvoid convolveKernel(std::vector<int> const& imageIn, std::vector<int> &imageOut, size_t N) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n    #pragma omp parallel for schedule(guided) num_threads(32)\n    for (size_t i = 0; i < N; ++i) {\n        for (size_t j = 0; j < N; ++j) {\n            int sum = 0;\n            for (int k = -1; k <= 1; ++k) {\n                for (int l = -1; l <= 1; ++l) {\n                    size_t row = i + k;\n                    size_t col = j + l;\n                    int pixel = 0;\n                    if (row < N && col < N) {\n                        pixel = imageIn[row * N + col];\n                    }\n                    sum += pixel * edgeKernel[k + 1][l + 1];\n                }\n            }\n            imageOut[i * N + j] = std::max(0, std::min(255, sum));\n        }\n    }\n}\n"
    ]
  },
  {
    "problem_type": "stencil",
    "language": "cpp",
    "name": "51_stencil_edge_kernel",
    "parallelism_model": "cuda",
    "prompt": "__constant__ int edgeKernel[3][3] = {{-1, -1, -1}, {-1, 8, -1}, {-1, -1, -1}};\n\n/* Convolve the edge kernel with a grayscale image. Each pixel will be replaced with\n   the dot product of itself and its neighbors with the edge kernel.\n   Use a value of 0 for pixels outside the image's boundaries and clip outputs between 0 and 255.\n   imageIn and imageOut are NxN grayscale images stored in row-major.\n   Store the output of the computation in imageOut.\n   Use CUDA to compute in parallel. The kernel is launched on an NxN grid of threads.\n   Example:\n\n   input: [[112, 118, 141, 152],\n           [93, 101, 119, 203],\n           [45, 17, 16, 232],\n           [82, 31, 49, 101]]\n   output: [[255, 255, 255, 255],\n            [255, 147, 0, 255],\n            [36, 0, 0, 255],\n            [255, 39, 0, 255]]\n*/\n__global__ void convolveKernel(const int *imageIn, int *imageOut, size_t N) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n    int row = blockIdx.y;\n    int col = blockIdx.x;\n    int sum = 0;\n\n    for (int kr = -1; kr <= 1; ++kr) {\n        for (int kc = -1; kc <= 1; ++kc) {\n            int r = row + kr;\n            int c = col + kc;\n            int val = 0;\n            if (r >= 0 && r < N && c >= 0 && c < N) {\n                val = imageIn[r * N + c];\n            }\n            sum += val * edgeKernel[kr + 1][kc + 1];\n        }\n    }\n\n    int output = max(0, min(255, sum));\n    imageOut[row * N + col] = output;\n}\n"
    ]
  },
  {
    "problem_type": "stencil",
    "language": "cpp",
    "name": "51_stencil_edge_kernel",
    "parallelism_model": "serial",
    "prompt": "const int edgeKernel[3][3] = {{-1, -1, -1}, {-1, 8, -1}, {-1, -1, -1}};\n\n/* Convolve the edge kernel with a grayscale image. Each pixel will be replaced with\n   the dot product of itself and its neighbors with the edge kernel.\n   Use a value of 0 for pixels outside the image's boundaries and clip outputs between 0 and 255.\n   imageIn and imageOut are NxN grayscale images stored in row-major.\n   Store the output of the computation in imageOut.\n   Example:\n\n   input: [[112, 118, 141, 152],\n           [93, 101, 119, 203],\n           [45, 17, 16, 232],\n           [82, 31, 49, 101]]\n   output: [[255, 255, 255, 255],\n            [255, 147, 0, 255],\n            [36, 0, 0, 255],\n            [255, 39, 0, 255]]\n*/\nvoid convolveKernel(std::vector<int> const& imageIn, std::vector<int> &imageOut, size_t N) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\nvoid convolveKernel(std::vector<int> const& imageIn, std::vector<int> &imageOut, size_t N) {\n    imageOut.resize(N * N);\n    const int kernel[3][3] = {{-1, -1, -1}, {-1, 8, -1}, {-1, -1, -1}};\n    for (size_t y = 0; y < N; ++y) {\n        for (size_t x = 0; x < N; ++x) {\n            int sum = 0;\n            for (int ky = -1; ky <= 1; ++ky) {\n                for (int kx = -1; kx <= 1; ++kx) {\n                    int nx = static_cast<int>(x) + kx;\n                    int ny = static_cast<int>(y) + ky;\n                    if (nx >= 0 && nx < static_cast<int>(N) && ny >= 0 && ny < static_cast<int>(N)) {\n                        sum += imageIn[ny * N + nx] * kernel[ky + 1][kx + 1];\n                    }\n                }\n            }\n            imageOut[y * N + x] = std::max(0, std::min(255, sum));\n        }\n    }\n}\n"
    ]
  },
  {
    "problem_type": "stencil",
    "language": "cpp",
    "name": "53_stencil_2d_jacobi_5-point_stencil",
    "parallelism_model": "omp",
    "prompt": "#include <omp.h>\n\n/* Compute one iteration of a 5-point 2D jacobi stencil on `input`. Store the results in `output`.\n   Each element of `input` will be averaged with its four neighbors and stored in the corresponding element of `output`.\n   i.e. output_{i,j} = (input_{i,j-1} + input_{i,j+1} + input_{i-1,j} + input_{i+1,j} + input_{i,j})/5\n   Replace with 0 when reading past the boundaries of `input`.\n   `input` and `output` are NxN grids stored in row-major.\n   Use OpenMP to compute in parallel.\n   Example:\n\n   input: [[3, 4, 1], [0, 1, 7], [5, 3, 2]]\n   output: [[1.4, 1.8, 2.4],[1.8, 3, 2.2], [1.6, 2.2, 2.4]]\n*/\nvoid jacobi2D(std::vector<double> const& input, std::vector<double> &output, size_t N) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n#pragma omp parallel for schedule(guided) num_threads(32)\n    for (size_t i = 0; i < N; ++i) {\n        for (size_t j = 0; j < N; ++j) {\n            double sum = 0.0;\n            int count = 0;\n\n            // Current cell\n            sum += input[i * N + j];\n            count += 1;\n\n            // Top neighbor\n            if (i > 0) {\n                sum += input[(i - 1) * N + j];\n                count += 1;\n            }\n\n            // Bottom neighbor\n            if (i < N - 1) {\n                sum += input[(i + 1) * N + j];\n                count += 1;\n            }\n\n            // Left neighbor\n            if (j > 0) {\n                sum += input[i * N + (j - 1)];\n                count += 1;\n            }\n\n            // Right neighbor\n            if (j < N - 1) {\n                sum += input[i * N + (j + 1)];\n                count += 1;\n            }\n\n            output[i * N + j] = sum / count;\n        }\n    }\n}\n"
    ]
  },
  {
    "problem_type": "stencil",
    "language": "cpp",
    "name": "53_stencil_2d_jacobi_5-point_stencil",
    "parallelism_model": "cuda",
    "prompt": "/* Compute one iteration of a 5-point 2D jacobi stencil on `input`. Store the results in `output`.\n   Each element of `input` will be averaged with its four neighbors and stored in the corresponding element of `output`.\n   i.e. output_{i,j} = (input_{i,j-1} + input_{i,j+1} + input_{i-1,j} + input_{i+1,j} + input_{i,j})/5\n   Replace with 0 when reading past the boundaries of `input`.\n   `input` and `output` are NxN grids stored in row-major.\n   Use CUDA to compute in parallel. The kernel is launched on an NxN grid of threads.\n   Example:\n\n   input: [[3, 4, 1], [0, 1, 7], [5, 3, 2]]\n   output: [[1.4, 1.8, 2.4],[1.8, 3, 2.2], [1.6, 2.2, 2.4]]\n*/\n__global__ void jacobi2D(const double *input, double *output, size_t N) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n{\n    int i = blockIdx.x * blockDim.x + threadIdx.x;\n    int j = blockIdx.y * blockDim.y + threadIdx.y;\n\n    if (i >= N || j >= N) return;\n\n    double sum = 0.0;\n    int count = 0;\n\n    // Check top neighbor\n    if (j > 0) {\n        sum += input[(i) * N + (j - 1)];\n        count++;\n    } else {\n        sum += 0;\n        count++;\n    }\n\n    // Check bottom neighbor\n    if (j < N - 1) {\n        sum += input[(i) * N + (j + 1)];\n        count++;\n    } else {\n        sum += 0;\n        count++;\n    }\n\n    // Check left neighbor\n    if (i > 0) {\n        sum += input[(i - 1) * N + j];\n        count++;\n    } else {\n        sum += 0;\n        count++;\n    }\n\n    // Check right neighbor\n    if (i < N - 1) {\n        sum += input[(i + 1) * N + j];\n        count++;\n    } else {\n        sum += 0;\n        count++;\n    }\n\n    // Current cell\n    sum += input[i * N + j];\n    count++;\n\n    output[i * N + j] = sum / count;\n}\n"
    ]
  },
  {
    "problem_type": "stencil",
    "language": "cpp",
    "name": "53_stencil_2d_jacobi_5-point_stencil",
    "parallelism_model": "serial",
    "prompt": "/* Compute one iteration of a 5-point 2D jacobi stencil on `input`. Store the results in `output`.\n   Each element of `input` will be averaged with its four neighbors and stored in the corresponding element of `output`.\n   i.e. output_{i,j} = (input_{i,j-1} + input_{i,j+1} + input_{i-1,j} + input_{i+1,j} + input_{i,j})/5\n   Replace with 0 when reading past the boundaries of `input`.\n   `input` and `output` are NxN grids stored in row-major.\n   Example:\n\n   input: [[3, 4, 1], [0, 1, 7], [5, 3, 2]]\n   output: [[1.4, 1.8, 2.4],[1.8, 3, 2.2], [1.6, 2.2, 2.4]]\n*/\nvoid jacobi2D(std::vector<double> const& input, std::vector<double> &output, size_t N) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\nvoid jacobi2D(std::vector<double> const& input, std::vector<double> &output, size_t N) {\n    #pragma omp parallel for\n    for (size_t i = 0; i < N; ++i) {\n        for (size_t j = 0; j < N; j += 8) {\n            __m512d sum = _mm512_setzero_pd();\n            __m512d weights = _mm512_set1_pd(1.0 / 5.0);\n            for (int dx = -1; dx <= 1; dx += 2) {\n                for (int dy = -1; dy <= 1; dy += 2) {\n                    if (dx == 0 || dy == 0) {\n                        __m512d val = _mm512_set1_pd(0.0);\n                        if (i + dx < N && j + dy < N && i + dx >= 0 && j + dy >= 0) {\n                            val = _mm512_loadu_pd(&input[(i + dx) * N + j + dy]);\n                        }\n                        sum = _mm512_add_pd(sum, val);\n                    }\n                }\n            }\n            __m512d center = _mm512_loadu_pd(&input[i * N + j]);\n            sum = _mm512_add_pd(sum, center);\n            sum = _mm512_mul_pd(sum, weights);\n            _mm512_storeu_pd(&output[i * N + j], sum);\n        }\n    }\n}\n"
    ]
  },
  {
    "problem_type": "stencil",
    "language": "cpp",
    "name": "52_stencil_1d_jacobi_3-point_stencil",
    "parallelism_model": "omp",
    "prompt": "#include <omp.h>\n\n/* Compute one iteration of a 3-point 1D jacobi stencil on `input`. Store the results in `output`.\n   Each element of `input` will be averaged with its two neighbors and stored in the corresponding element of `output`.\n   i.e. output[i] = (input[i-1]+input[i]+input[i+1])/3\n   Replace with 0 when reading past the boundaries of `input`.\n   Use OpenMP to compute in parallel.\n   Example:\n\n   input: [9, -6, -1, 2, 3]\n   output: [1, 2/3, -5/3, 4/3, 5/3]\n*/\nvoid jacobi1D(std::vector<double> const& input, std::vector<double> &output) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n#pragma omp parallel for schedule(guided) num_threads(32)\n    for (size_t i = 0; i < input.size(); ++i) {\n        double left = (i > 0) ? input[i - 1] : 0.0;\n        double right = (i < input.size() - 1) ? input[i + 1] : 0.0;\n        output[i] = (left + input[i] + right) / 3.0;\n    }\n}\n"
    ]
  },
  {
    "problem_type": "stencil",
    "language": "cpp",
    "name": "52_stencil_1d_jacobi_3-point_stencil",
    "parallelism_model": "cuda",
    "prompt": "/* Compute one iteration of a 3-point 1D jacobi stencil on `input`. Store the results in `output`.\n   Each element of `input` will be averaged with its two neighbors and stored in the corresponding element of `output`.\n   i.e. output[i] = (input[i-1]+input[i]+input[i+1])/3\n   Replace with 0 when reading past the boundaries of `input`.\n   Use CUDA to compute in parallel. The kernel is launched with at least N threads.\n   Example:\n\n   input: [9, -6, -1, 2, 3]\n   output: [1, 2/3, -5/3, 4/3, 5/3]\n*/\n__global__ void jacobi1D(const double *input, double *output, size_t N) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n    size_t i = threadIdx.x + blockIdx.x * blockDim.x;\n    if (i < N) {\n        double left = (i > 0) ? input[i - 1] : 0;\n        double center = input[i];\n        double right = (i < N - 1) ? input[i + 1] : 0;\n        output[i] = (left + center + right) / 3.0;\n    }\n}\n"
    ]
  },
  {
    "problem_type": "stencil",
    "language": "cpp",
    "name": "52_stencil_1d_jacobi_3-point_stencil",
    "parallelism_model": "serial",
    "prompt": "/* Compute one iteration of a 3-point 1D jacobi stencil on `input`. Store the results in `output`.\n   Each element of `input` will be averaged with its two neighbors and stored in the corresponding element of `output`.\n   i.e. output[i] = (input[i-1]+input[i]+input[i+1])/3\n   Replace with 0 when reading past the boundaries of `input`.\n   Example:\n\n   input: [9, -6, -1, 2, 3]\n   output: [1, 2/3, -5/3, 4/3, 5/3]\n*/\nvoid jacobi1D(std::vector<double> const& input, std::vector<double> &output) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n    const size_t size = input.size();\n    output.resize(size);\n\n    if (size == 0) return;\n\n    // Vectorized computation using AVX512\n    size_t i = 0;\n    for (; i + 16 <= size; i += 16) {\n        __m512d in0 = _mm512_loadu_pd(&input[i]);\n        __m512d in1 = _mm512_loadu_pd(&input[i + 1]);\n        __m512d in_prev = (i == 0) ? _mm512_setzero_pd() : _mm512_loadu_pd(&input[i - 1]);\n        __m512d sum = _mm512_add_pd(_mm512_add_pd(in_prev, in0), in1);\n        __m512d avg = _mm512_div_pd(sum, _mm512_set1_pd(3.0));\n        _mm512_storeu_pd(&output[i], avg);\n    }\n\n    // Handle remaining elements with scalar code\n    for (; i < size; ++i) {\n        double left = (i > 0) ? input[i - 1] : 0.0;\n        double curr = input[i];\n        double right = (i < size - 1) ? input[i + 1] : 0.0;\n        output[i] = (left + curr + right) / 3.0;\n    }\n}\n"
    ]
  },
  {
    "problem_type": "stencil",
    "language": "cpp",
    "name": "54_stencil_game_of_life",
    "parallelism_model": "omp",
    "prompt": "#include <omp.h>\n\n/* Simulate one generation of Game of Life on `input`. Store the results in `output`.\n   A cell is 1 if it is alive and 0 if it is dead.\n   If a live cell has fewer than 2 live neighbors then it dies.\n   If a live cell has 2 or 3 live neighbors then it lives on.\n   If a live cell has more than 3 live neighbords then it dies.\n   If a cell is dead and has exactly 3 live neighbors then it becomes alive.\n   `input` and `output` are NxN grids stored in row-major.\n   Use OpenMP to compute in parallel.\n   Example:\n\n   input:  [[0, 0, 0, 0, 0],\n\t\t\t\t\t  [0, 1, 0, 0, 0],\n            [0, 1, 1, 0, 0],\n            [0, 0, 1, 1, 0],\n            [0, 1, 0, 0, 0]]\n   output: [[0, 0, 0, 0, 0],\n\t\t\t\t\t  [0, 1, 1, 0, 0],\n            [0, 1, 0, 1, 0],\n            [0, 0, 0, 1, 0],\n            [0, 0, 1, 0, 0]]\n*/\nvoid gameOfLife(std::vector<int> const& input, std::vector<int> &output, size_t N) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n#pragma omp parallel for schedule(guided) num_threads(32)\n    for (size_t i = 0; i < N; ++i) {\n        for (size_t j = 0; j < N; ++j) {\n            int liveNeighbors = 0;\n            for (int dx = -1; dx <= 1; ++dx) {\n                for (int dy = -1; dy <= 1; ++dy) {\n                    if (dx == 0 && dy == 0) continue;\n                    size_t x = i + dx;\n                    size_t y = j + dy;\n                    if (x < N && y < N) {\n                        liveNeighbors += input[x * N + y];\n                    }\n                }\n            }\n            int cell = input[i * N + j];\n            if (cell == 1) {\n                if (liveNeighbors < 2 || liveNeighbors > 3) {\n                    output[i * N + j] = 0;\n                } else {\n                    output[i * N + j] = 1;\n                }\n            } else {\n                if (liveNeighbors == 3) {\n                    output[i * N + j] = 1;\n                } else {\n                    output[i * N + j] = 0;\n                }\n            }\n        }\n    }\n}\n"
    ]
  },
  {
    "problem_type": "stencil",
    "language": "cpp",
    "name": "54_stencil_game_of_life",
    "parallelism_model": "cuda",
    "prompt": "/* Simulate one generation of Game of Life on `input`. Store the results in `output`.\n   A cell is 1 if it is alive and 0 if it is dead.\n   If a live cell has fewer than 2 live neighbors then it dies.\n   If a live cell has 2 or 3 live neighbors then it lives on.\n   If a live cell has more than 3 live neighbords then it dies.\n   If a cell is dead and has exactly 3 live neighbors then it becomes alive.\n   `input` and `output` are NxN grids stored in row-major.\n   Use CUDA to compute in parallel. The kernel is launched on an NxN grid of threads.\n   Example:\n\n   input:  [[0, 0, 0, 0, 0],\n\t\t\t\t\t  [0, 1, 0, 0, 0],\n            [0, 1, 1, 0, 0],\n            [0, 0, 1, 1, 0],\n            [0, 1, 0, 0, 0]]\n   output: [[0, 0, 0, 0, 0],\n\t\t\t\t\t  [0, 1, 1, 0, 0],\n            [0, 1, 0, 1, 0],\n            [0, 0, 0, 1, 0],\n            [0, 0, 1, 0, 0]]\n*/\n__global__ void gameOfLife(const int *input, int *output, size_t N) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n  int row = blockIdx.y * blockDim.y + threadIdx.y;\n  int col = blockIdx.x * blockDim.x + threadIdx.x;\n\n  if (row >= N || col >= N) return;\n\n  int liveNeighbors = 0;\n  for (int i = -1; i <= 1; ++i) {\n    for (int j = -1; j <= 1; ++j) {\n      if (i == 0 && j == 0) continue;\n      int r = row + i;\n      int c = col + j;\n      if (r >= 0 && r < N && c >= 0 && c < N) {\n        liveNeighbors += input[r * N + c];\n      }\n    }\n  }\n\n  int cell = input[row * N + col];\n  if (cell == 1) {\n    if (liveNeighbors < 2) {\n      output[row * N + col] = 0;\n    } else if (liveNeighbors == 2 || liveNeighbors == 3) {\n      output[row * N + col] = 1;\n    } else {\n      output[row * N + col] = 0;\n    }\n  } else {\n    if (liveNeighbors == 3) {\n      output[row * N + col] = 1;\n    } else {\n      output[row * N + col] = 0;\n    }\n  }\n}\n"
    ]
  },
  {
    "problem_type": "stencil",
    "language": "cpp",
    "name": "54_stencil_game_of_life",
    "parallelism_model": "serial",
    "prompt": "/* Simulate one generation of Game of Life on `input`. Store the results in `output`.\n   A cell is 1 if it is alive and 0 if it is dead.\n   If a live cell has fewer than 2 live neighbors then it dies.\n   If a live cell has 2 or 3 live neighbors then it lives on.\n   If a live cell has more than 3 live neighbords then it dies.\n   If a cell is dead and has exactly 3 live neighbors then it becomes alive.\n   `input` and `output` are NxN grids stored in row-major.\n   Example:\n\n   input:  [[0, 0, 0, 0, 0],\n\t\t\t\t\t  [0, 1, 0, 0, 0],\n            [0, 1, 1, 0, 0],\n            [0, 0, 1, 1, 0],\n            [0, 1, 0, 0, 0]]\n   output: [[0, 0, 0, 0, 0],\n\t\t\t\t\t  [0, 1, 1, 0, 0],\n            [0, 1, 0, 1, 0],\n            [0, 0, 0, 1, 0],\n            [0, 0, 1, 0, 0]]\n*/\nvoid gameOfLife(std::vector<int> const& input, std::vector<int> &output, size_t N) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\nvoid gameOfLife(std::vector<int> const& input, std::vector<int> &output, size_t N) {\n    output.resize(N * N);\n    for (size_t i = 0; i < N; ++i) {\n        for (size_t j = 0; j < N; ++j) {\n            int liveNeighbors = 0;\n            for (int dx = -1; dx <= 1; ++dx) {\n                for (int dy = -1; dy <= 1; ++dy) {\n                    if (dx == 0 && dy == 0) continue;\n                    size_t x = i + dx;\n                    size_t y = j + dy;\n                    if (x < N && y < N) {\n                        liveNeighbors += input[x * N + y];\n                    }\n                }\n            }\n            int cell = input[i * N + j];\n            if (cell == 1) {\n                if (liveNeighbors < 2) {\n                    output[i * N + j] = 0;\n                } else if (liveNeighbors == 2 || liveNeighbors == 3) {\n                    output[i * N + j] = 1;\n                } else {\n                    output[i * N + j] = 0;\n                }\n            } else {\n                if (liveNeighbors == 3) {\n                    output[i * N + j] = 1;\n                } else {\n                    output[i * N + j] = 0;\n                }\n            }\n        }\n    }\n}\n"
    ]
  },
  {
    "problem_type": "histogram",
    "language": "cpp",
    "name": "20_histogram_pixel_histogram",
    "parallelism_model": "omp",
    "prompt": "#include <omp.h>\n\n/* Count the number of pixels in image with each grayscale intensity.\n   The vector `image` is a grayscale image with values 0-255.\n   Store the results in `bins`.\n   Use OpenMP to count in parallel.\n   Example:\n   \n   input: image=[2, 116, 201, 11, 92, 92, 201, 4, 2]\n   output: [0, 0, 2, 0, 1, ...]\n*/\n void pixelCounts(std::vector<int> const& image, std::array<size_t, 256> &bins) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n#pragma omp parallel\n{\n    std::array<size_t, 256> local_bins = {0};\n    #pragma omp for schedule(guided)\n    for (size_t i = 0; i < image.size(); ++i) {\n        int val = image[i];\n        if (val >= 0 && val <= 255) {\n            local_bins[val]++;\n        }\n    }\n    #pragma omp critical\n    {\n        for (size_t j = 0; j < 256; ++j) {\n            bins[j] += local_bins[j];\n        }\n    }\n}\n"
    ]
  },
  {
    "problem_type": "histogram",
    "language": "cpp",
    "name": "20_histogram_pixel_histogram",
    "parallelism_model": "cuda",
    "prompt": "/* Count the number of pixels in image with each grayscale intensity.\n   The vector `image` is a grayscale image with values 0-255.\n   Store the results in `bins`.\n   Use CUDA to count in parallel. The kernel is launched with at least N threads.\n   Example:\n   \n   input: image=[2, 116, 201, 11, 92, 92, 201, 4, 2]\n   output: [0, 0, 2, 0, 1, ...]\n*/\n__global__ void pixelCounts(const int *image, size_t N, size_t bins[256]) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n    extern __shared__ size_t shared_bins[];\n    int tid = threadIdx.x;\n    int bid = blockIdx.x;\n    int num_threads = blockDim.x * gridDim.x;\n\n    // Initialize shared memory bins\n    for (int i = tid; i < 256; i += num_threads) {\n        shared_bins[i] = 0;\n    }\n    __syncthreads();\n\n    // Process image pixels\n    for (int i = bid * num_threads + tid; i < N; i += num_threads * gridDim.x) {\n        atomicAdd(&shared_bins[image[i]], 1);\n    }\n    __syncthreads();\n\n    // Write results back to global memory\n    for (int i = tid; i < 256; i += num_threads) {\n        atomicAdd(&bins[i], shared_bins[i]);\n    }\n}\n"
    ]
  },
  {
    "problem_type": "histogram",
    "language": "cpp",
    "name": "20_histogram_pixel_histogram",
    "parallelism_model": "serial",
    "prompt": "/* Count the number of pixels in image with each grayscale intensity.\n   The vector `image` is a grayscale image with values 0-255.\n   Store the results in `bins`.\n   Example:\n   \n   input: image=[2, 116, 201, 11, 92, 92, 201, 4, 2]\n   output: [0, 0, 2, 0, 1, ...]\n*/\n void pixelCounts(std::vector<int> const& image, std::array<size_t, 256> &bins) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n    bins.fill(0);\n    for (size_t i = 0; i < image.size(); ++i) {\n        int pixel = image[i];\n        if (pixel >= 0 && pixel <= 255) {\n            bins[pixel]++;\n        }\n    }\n}\n"
    ]
  },
  {
    "problem_type": "histogram",
    "language": "cpp",
    "name": "24_histogram_count_quartile",
    "parallelism_model": "omp",
    "prompt": "#include <omp.h>\n\n/* Count the number of doubles in the vector x that have a fractional part \n   in [0, 0.25), [0.25, 0.5), [0.5, 0.75), and [0.75, 1). Store the counts in `bins`.\n   Use OpenMP to compute in parallel.\n   Examples:\n\n   input: [7.8, 4.2, 9.1, 7.6, 0.27, 1.5, 3.8]\n   output: [2, 1, 2, 2]\n\n   input: [1.9, 0.2, 0.6, 10.1, 7.4]\n   output: [2, 1, 1, 1]\n*/\nvoid countQuartiles(std::vector<double> const& x, std::array<size_t, 4> &bins) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\nvoid countQuartiles(std::vector<double> const& x, std::array<size_t, 4> &bins) {\n    bins.fill(0);\n    #pragma omp parallel\n    {\n        std::array<size_t, 4> local_bins = {0, 0, 0, 0};\n        #pragma omp for schedule(guided)\n        for (size_t i = 0; i < x.size(); ++i) {\n            double frac = x[i] - std::floor(x[i]);\n            if (frac >= 0.0 && frac < 0.25) ++local_bins[0];\n            else if (frac >= 0.25 && frac < 0.5) ++local_bins[1];\n            else if (frac >= 0.5 && frac < 0.75) ++local_bins[2];\n            else if (frac >= 0.75 && frac < 1.0) ++local_bins[3];\n        }\n        #pragma omp critical\n        {\n            for (size_t j = 0; j < 4; ++j) {\n                bins[j] += local_bins[j];\n            }\n        }\n    }\n}\n"
    ]
  },
  {
    "problem_type": "histogram",
    "language": "cpp",
    "name": "24_histogram_count_quartile",
    "parallelism_model": "cuda",
    "prompt": "/* Count the number of doubles in the vector x that have a fractional part \n   in [0, 0.25), [0.25, 0.5), [0.5, 0.75), and [0.75, 1). Store the counts in `bins`.\n   Use CUDA to compute in parallel. The kernel is launched with at least N threads.\n   Examples:\n\n   input: [7.8, 4.2, 9.1, 7.6, 0.27, 1.5, 3.8]\n   output: [2, 1, 2, 2]\n\n   input: [1.9, 0.2, 0.6, 10.1, 7.4]\n   output: [2, 1, 1, 1]\n*/\n__global__ void countQuartiles(const double *x, size_t N, size_t bins[4]) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n    size_t i = blockIdx.x * blockDim.x + threadIdx.x;\n    if (i < N) {\n        double intPart;\n        double frac = modf(x[i], &intPart);\n        if (frac >= 0.0 && frac < 0.25) atomicAdd(&bins[0], 1);\n        else if (frac >= 0.25 && frac < 0.5) atomicAdd(&bins[1], 1);\n        else if (frac >= 0.5 && frac < 0.75) atomicAdd(&bins[2], 1);\n        else if (frac >= 0.75 && frac < 1.0) atomicAdd(&bins[3], 1);\n    }\n}\n"
    ]
  },
  {
    "problem_type": "histogram",
    "language": "cpp",
    "name": "24_histogram_count_quartile",
    "parallelism_model": "serial",
    "prompt": "/* Count the number of doubles in the vector x that have a fractional part \n   in [0, 0.25), [0.25, 0.5), [0.5, 0.75), and [0.75, 1). Store the counts in `bins`.\n   Examples:\n\n   input: [7.8, 4.2, 9.1, 7.6, 0.27, 1.5, 3.8]\n   output: [2, 1, 2, 2]\n\n   input: [1.9, 0.2, 0.6, 10.1, 7.4]\n   output: [2, 1, 1, 1]\n*/\nvoid countQuartiles(std::vector<double> const& x, std::array<size_t, 4> &bins) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\nvoid countQuartiles(std::vector<double> const& x, std::array<size_t, 4> &bins) {\n    bins.fill(0);\n    for (size_t i = 0; i < x.size(); ++i) {\n        double frac = x[i] - std::floor(x[i]);\n        if (frac < 0.25) ++bins[0];\n        else if (frac < 0.5) ++bins[1];\n        else if (frac < 0.75) ++bins[2];\n        else ++bins[3];\n    }\n}\n"
    ]
  },
  {
    "problem_type": "histogram",
    "language": "cpp",
    "name": "22_histogram_count_quadrants",
    "parallelism_model": "omp",
    "prompt": "#include <omp.h>\n\nstruct Point {\n   double x, y;\n};\n\n/* Count the number of cartesian points in each quadrant. The vector points contains a list of `Point` objects.\n   Store the counts in `bins`.\n   Use OpenMP to count in parallel.\n   Example:\n\n   input: [{x=1.5, y=0.1}, {x=-3, y=1.1}, {x=5, y=9}, {x=1.5, y=-1}, {x=3, y=-7}, {x=0.1, y=2}]\n   output: [3, 1, 0, 2]\n*/\nvoid countQuadrants(std::vector<Point> const& points, std::array<size_t, 4> &bins) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\nvoid countQuadrants(std::vector<Point> const& points, std::array<size_t, 4> &bins) {\n    bins = {0, 0, 0, 0};\n    size_t local_bins[4] = {0, 0, 0, 0};\n\n    #pragma omp parallel num_threads(32) shared(points, bins) default(none) private(local_bins)\n    {\n        #pragma omp for schedule(guided)\n        for (size_t i = 0; i < points.size(); ++i) {\n            double x = points[i].x;\n            double y = points[i].y;\n            if (x > 0 && y > 0) ++local_bins[0];\n            else if (x < 0 && y > 0) ++local_bins[1];\n            else if (x < 0 && y < 0) ++local_bins[2];\n            else if (x > 0 && y < 0) ++local_bins[3];\n        }\n\n        #pragma omp critical\n        {\n            for (int j = 0; j < 4; ++j) {\n                bins[j] += local_bins[j];\n            }\n        }\n    }\n}\n"
    ]
  },
  {
    "problem_type": "histogram",
    "language": "cpp",
    "name": "22_histogram_count_quadrants",
    "parallelism_model": "cuda",
    "prompt": "struct Point {\n   double x, y;\n};\n\n/* Count the number of cartesian points in each quadrant. The vector points contains a list of `Point` objects.\n   Store the counts in `bins`.\n   Use CUDA to count in parallel. The kernel is launched with at least N threads.\n   Example:\n\n   input: [{x=1.5, y=0.1}, {x=-3, y=1.1}, {x=5, y=9}, {x=1.5, y=-1}, {x=3, y=-7}, {x=0.1, y=2}]\n   output: [3, 1, 0, 2]\n*/\n__global__ void countQuadrants(const Point *points, size_t N, size_t bins[4]) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n    unsigned int idx = threadIdx.x + blockIdx.x * blockDim.x;\n    __shared__ size_t s_bins[4];\n    if (threadIdx.x == 0) {\n        s_bins[0] = s_bins[1] = s_bins[2] = s_bins[3] = 0;\n    }\n    __syncthreads();\n\n    if (idx < N) {\n        Point p = points[idx];\n        if (p.x > 0 && p.y > 0) atomicAdd(&s_bins[0], 1);\n        else if (p.x < 0 && p.y > 0) atomicAdd(&s_bins[1], 1);\n        else if (p.x < 0 && p.y < 0) atomicAdd(&s_bins[2], 1);\n        else if (p.x > 0 && p.y < 0) atomicAdd(&s_bins[3], 1);\n    }\n    __syncthreads();\n\n    if (threadIdx.x == 0) {\n        atomicAdd(&bins[0], s_bins[0]);\n        atomicAdd(&bins[1], s_bins[1]);\n        atomicAdd(&bins[2], s_bins[2]);\n        atomicAdd(&bins[3], s_bins[3]);\n    }\n}\n"
    ]
  },
  {
    "problem_type": "histogram",
    "language": "cpp",
    "name": "22_histogram_count_quadrants",
    "parallelism_model": "serial",
    "prompt": "struct Point {\n   double x, y;\n};\n\n/* Count the number of cartesian points in each quadrant. The vector points contains a list of `Point` objects.\n   Store the counts in `bins`.\n   Example:\n\n   input: [{x=1.5, y=0.1}, {x=-3, y=1.1}, {x=5, y=9}, {x=1.5, y=-1}, {x=3, y=-7}, {x=0.1, y=2}]\n   output: [3, 1, 0, 2]\n*/\nvoid countQuadrants(std::vector<Point> const& points, std::array<size_t, 4> &bins) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n    bins.fill(0);\n    const size_t size = points.size();\n    const Point* data = points.data();\n\n    for (size_t i = 0; i < size; ++i) {\n        const Point& p = data[i];\n        bool x_positive = p.x > 0.0;\n        bool y_positive = p.y > 0.0;\n        if (x_positive && y_positive) ++bins[0];\n        else if (!x_positive && y_positive) ++bins[1];\n        else if (!x_positive && !y_positive) ++bins[2];\n        else if (x_positive && !y_positive) ++bins[3];\n    }\n}\n"
    ]
  },
  {
    "problem_type": "histogram",
    "language": "cpp",
    "name": "23_histogram_first_letter_counts",
    "parallelism_model": "omp",
    "prompt": "#include <omp.h>\n\n/* For each letter in the alphabet, count the number of strings in the vector s that start with that letter.\n   Assume all strings are in lower case. Store the output in `bins` array.\n   Use OpenMP to compute in parallel.\n   Example:\n\n   input: [\"dog\", \"cat\", \"xray\", \"cow\", \"code\", \"type\", \"flower\"]\n   output: [0, 0, 3, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0]\n*/\nvoid firstLetterCounts(std::vector<std::string> const& s, std::array<size_t, 26> &bins) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n#pragma omp parallel\n{\n    std::array<size_t, 26> local_bins = {0};\n    #pragma omp for schedule(guided)\n    for (size_t i = 0; i < s.size(); ++i) {\n        if (!s[i].empty()) {\n            char c = s[i][0];\n            if (c >= 'a' && c <= 'z') {\n                local_bins[c - 'a']++;\n            }\n        }\n    }\n    #pragma omp critical\n    {\n        for (int i = 0; i < 26; ++i) {\n            bins[i] += local_bins[i];\n        }\n    }\n}\n"
    ]
  },
  {
    "problem_type": "histogram",
    "language": "cpp",
    "name": "23_histogram_first_letter_counts",
    "parallelism_model": "cuda",
    "prompt": "/* For each letter in the alphabet, count the number of strings in the vector s that start with that letter.\n   Assume all strings are in lower case. Store the output in `bins` array.\n   Use CUDA to compute in parallel. The kernel is launched with at least N threads.\n   Example:\n\n   input: [\"dog\", \"cat\", \"xray\", \"cow\", \"code\", \"type\", \"flower\"]\n   output: [0, 0, 3, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0]\n*/\n__global__ void firstLetterCounts(const char **s, size_t N, size_t bins[26]) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n    unsigned int idx = blockIdx.x * blockDim.x + threadIdx.x;\n    if (idx < N) {\n        char first_char = s[idx][0];\n        if (first_char >= 'a' && first_char <= 'z') {\n            atomicAdd(&bins[first_char - 'a'], 1);\n        }\n    }\n}\n"
    ]
  },
  {
    "problem_type": "histogram",
    "language": "cpp",
    "name": "23_histogram_first_letter_counts",
    "parallelism_model": "serial",
    "prompt": "/* For each letter in the alphabet, count the number of strings in the vector s that start with that letter.\n   Assume all strings are in lower case. Store the output in `bins` array.\n   Example:\n\n   input: [\"dog\", \"cat\", \"xray\", \"cow\", \"code\", \"type\", \"flower\"]\n   output: [0, 0, 3, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0]\n*/\nvoid firstLetterCounts(std::vector<std::string> const& s, std::array<size_t, 26> &bins) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\nvoid firstLetterCounts(std::vector<std::string> const& s, std::array<size_t, 26> &bins) {\n    #pragma omp simd aligned(s.data():64)\n    for (size_t i = 0; i < s.size(); ++i) {\n        const char c = s[i][0];\n        if (c >= 'a' && c <= 'z') {\n            #pragma omp atomic\n            bins[c - 'a'] += 1;\n        }\n    }\n}\n"
    ]
  },
  {
    "problem_type": "histogram",
    "language": "cpp",
    "name": "21_histogram_bin_0-100",
    "parallelism_model": "omp",
    "prompt": "#include <omp.h>\n\n/* Vector x contains values between 0 and 100, inclusive. Count the number of\n   values in [0,10), [10, 20), [20, 30), ... and store the counts in `bins`.\n   Use OpenMP to compute in parallel.\n   Example:\n\n   input: [7, 32, 95, 12, 39, 32, 11, 71, 70, 66]\n   output: [1, 2, 0, 3, 0, 0, 1, 2, 0, 1]\n*/\nvoid binsBy10Count(std::vector<double> const& x, std::array<size_t, 10> &bins) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n#pragma omp parallel\n{\n    std::array<size_t, 10> local_bins = {0};\n    #pragma omp for schedule(guided)\n    for (size_t i = 0; i < x.size(); ++i) {\n        int bin_index = static_cast<int>(x[i]) / 10;\n        if (bin_index < 10) {\n            local_bins[bin_index]++;\n        }\n    }\n    #pragma omp critical\n    {\n        for (size_t j = 0; j < 10; ++j) {\n            bins[j] += local_bins[j];\n        }\n    }\n}\n"
    ]
  },
  {
    "problem_type": "histogram",
    "language": "cpp",
    "name": "21_histogram_bin_0-100",
    "parallelism_model": "cuda",
    "prompt": "/* Vector x contains values between 0 and 100, inclusive. Count the number of\n   values in [0,10), [10, 20), [20, 30), ... and store the counts in `bins`.\n   Use CUDA to compute in parallel. The kernel is initialized with at least as many threads as values in x.\n   Example:\n\n   input: [7, 32, 95, 12, 39, 32, 11, 71, 70, 66]\n   output: [1, 2, 0, 3, 0, 0, 1, 2, 0, 1]\n*/\n__global__ void binsBy10Count(const double *x, size_t N, size_t bins[10]) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n    extern __shared__ size_t shared_bins[];\n    int tid = threadIdx.x;\n\n    // Initialize shared memory bins\n    if (tid < 10) {\n        shared_bins[tid] = 0;\n    }\n    __syncthreads();\n\n    // Process each element assigned to this thread\n    size_t i = blockIdx.x * blockDim.x + tid;\n    if (i < N) {\n        double val = x[i];\n        if (val < 100.0) {\n            int bin = static_cast<int>(val) / 10;\n            atomicAdd(&shared_bins[bin], 1);\n        }\n    }\n    __syncthreads();\n\n    // Write results back to global memory\n    if (tid < 10) {\n        atomicAdd(&bins[tid], shared_bins[tid]);\n    }\n}\n"
    ]
  },
  {
    "problem_type": "histogram",
    "language": "cpp",
    "name": "21_histogram_bin_0-100",
    "parallelism_model": "serial",
    "prompt": "/* Vector x contains values between 0 and 100, inclusive. Count the number of\n   values in [0,10), [10, 20), [20, 30), ... and store the counts in `bins`.\n   Example:\n\n   input: [7, 32, 95, 12, 39, 32, 11, 71, 70, 66]\n   output: [1, 2, 0, 3, 0, 0, 1, 2, 0, 1]\n*/\nvoid binsBy10Count(std::vector<double> const& x, std::array<size_t, 10> &bins) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\nvoid binsBy10Count(std::vector<double> const& x, std::array<size_t, 10> &bins) {\n    for (auto& bin : bins) bin = 0;\n    for (double val : x) {\n        if (val < 100.0) {\n            size_t binIndex = static_cast<size_t>(val) / 10;\n            ++bins[binIndex];\n        }\n    }\n}\n"
    ]
  },
  {
    "problem_type": "search",
    "language": "cpp",
    "name": "39_search_xor_contains",
    "parallelism_model": "omp",
    "prompt": "#include <omp.h>\n\n/* Return true if `val` is only in one of vectors x or y.\n   Return false if it is in both or neither.\n   Use OpenMP to search in parallel.\n   Examples:\n\n   input: x=[1,8,4,3,2], y=[3,4,4,1,1,7], val=7\n   output: true\n\n   input: x=[1,8,4,3,2], y=[3,4,4,1,1,7], val=1\n   output: false\n*/\nbool xorContains(std::vector<int> const& x, std::vector<int> const& y, int val) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\nbool inX = false;\nbool inY = false;\n\n#pragma omp parallel sections\n{\n    #pragma omp section\n    {\n        #pragma omp parallel for simd reduction(||:inX) schedule(guided)\n        for (size_t i = 0; i < x.size(); ++i) {\n            inX |= (x[i] == val);\n        }\n    }\n\n    #pragma omp section\n    {\n        #pragma omp parallel for simd reduction(||:inY) schedule(guided)\n        for (size_t i = 0; i < y.size(); ++i) {\n            inY |= (y[i] == val);\n        }\n    }\n}\n\nreturn inX != inY;\n"
    ]
  },
  {
    "problem_type": "search",
    "language": "cpp",
    "name": "39_search_xor_contains",
    "parallelism_model": "cuda",
    "prompt": "/* Set `found` to true if `val` is only in one of vectors x or y.\n   Set it to false if it is in both or neither.\n   Use CUDA to search in parallel. The kernel is launched with at least N threads.\n   Examples:\n\n   input: x=[1,8,4,3,2], y=[3,4,4,1,1,7], val=7\n   output: true\n\n   input: x=[1,8,4,3,2], y=[3,4,4,1,1,7], val=1\n   output: false\n*/\n__global__ void xorContains(const int *x, const int *y, size_t N, int val, bool *found) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n    __shared__ bool xFound[256];\n    __shared__ bool yFound[256];\n    int tid = threadIdx.x;\n    xFound[tid] = false;\n    yFound[tid] = false;\n    __syncthreads();\n\n    if (tid < N) {\n        if (x[tid] == val) xFound[tid] = true;\n        if (y[tid] == val) yFound[tid] = true;\n    }\n    __syncthreads();\n\n    for (int i = 128; i > 0; i >>= 1) {\n        if (tid < i) {\n            xFound[tid] |= xFound[tid + i];\n            yFound[tid] |= yFound[tid + i];\n        }\n        __syncthreads();\n    }\n\n    if (tid == 0) {\n        *found = (xFound[0] ^ yFound[0]);\n    }\n}\n"
    ]
  },
  {
    "problem_type": "search",
    "language": "cpp",
    "name": "39_search_xor_contains",
    "parallelism_model": "serial",
    "prompt": "/* Return true if `val` is only in one of vectors x or y.\n   Return false if it is in both or neither.\n   Examples:\n\n   input: x=[1,8,4,3,2], y=[3,4,4,1,1,7], val=7\n   output: true\n\n   input: x=[1,8,4,3,2], y=[3,4,4,1,1,7], val=1\n   output: false\n*/\nbool xorContains(std::vector<int> const& x, std::vector<int> const& y, int val) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\nbool xorContains(std::vector<int> const& x, std::vector<int> const& y, int val) {\n    bool inX = false;\n    bool inY = false;\n    for (int num : x) {\n        if (num == val) {\n            inX = true;\n            break;\n        }\n    }\n    for (int num : y) {\n        if (num == val) {\n            inY = true;\n            break;\n        }\n    }\n    return inX != inY;\n}\n"
    ]
  },
  {
    "problem_type": "search",
    "language": "cpp",
    "name": "37_search_find_the_closest_number_to_pi",
    "parallelism_model": "omp",
    "prompt": "#include <omp.h>\n\n/* Return the index of the value in the vector x that is closest to the math constant PI.\n   Use M_PI for the value of PI.\n   Use OpenMP to search in parallel.\n   Example:\n\n   input: [9.18, 3.05, 7.24, 11.3, -166.49, 2.1]\n   output: 1\n*/\nsize_t findClosestToPi(std::vector<double> const& x) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n    size_t closestIndex = 0;\n    double minDiff = std::abs(x[0] - M_PI);\n    #pragma omp parallel\n    {\n        #pragma omp for schedule(guided)\n        for (size_t i = 1; i < x.size(); ++i) {\n            double diff = std::abs(x[i] - M_PI);\n            if (diff < minDiff) {\n                #pragma omp critical\n                {\n                    if (diff < minDiff) {\n                        minDiff = diff;\n                        closestIndex = i;\n                    }\n                }\n            }\n        }\n    }\n    return closestIndex;\n}\n"
    ]
  },
  {
    "problem_type": "search",
    "language": "cpp",
    "name": "37_search_find_the_closest_number_to_pi",
    "parallelism_model": "cuda",
    "prompt": "/* Find the index of the value in the vector x that is closest to the math constant PI. Store the index in closestToPiIndex.\n   Use M_PI for the value of PI.\n   Use CUDA to search in parallel. The kernel is launched with at least N threads.\n   Example:\n\n   input: [9.18, 3.05, 7.24, 11.3, -166.49, 2.1]\n   output: 1\n*/\n__global__ void findClosestToPi(const double *x, size_t N, size_t *closestToPiIndex) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n    extern __shared__ double sharedDiffs[];\n    extern __shared__ size_t sharedIndices[];\n\n    size_t tid = threadIdx.x;\n    size_t i = blockIdx.x * blockDim.x + threadIdx.x;\n\n    if (i < N) {\n        double diff = fabs(x[i] - M_PI);\n        sharedDiffs[tid] = diff;\n        sharedIndices[tid] = i;\n    } else {\n        sharedDiffs[tid] = INFINITY;\n        sharedIndices[tid] = -1;\n    }\n\n    __syncthreads();\n\n    for (size_t s = blockDim.x / 2; s > 0; s >>= 1) {\n        if (tid < s) {\n            if (sharedDiffs[tid] > sharedDiffs[tid + s]) {\n                sharedDiffs[tid] = sharedDiffs[tid + s];\n                sharedIndices[tid] = sharedIndices[tid + s];\n            }\n        }\n        __syncthreads();\n    }\n\n    if (tid == 0) {\n        atomicMinIndex(closestToPiIndex, sharedIndices[0], sharedDiffs[0]);\n    }\n}\n"
    ]
  },
  {
    "problem_type": "search",
    "language": "cpp",
    "name": "37_search_find_the_closest_number_to_pi",
    "parallelism_model": "serial",
    "prompt": "/* Return the index of the value in the vector x that is closest to the math constant PI.\n   Use M_PI for the value of PI.\n   Example:\n\n   input: [9.18, 3.05, 7.24, 11.3, -166.49, 2.1]\n   output: 1\n*/\nsize_t findClosestToPi(std::vector<double> const& x) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\nsize_t findClosestToPi(std::vector<double> const& x) {\n    size_t closestIndex = 0;\n    double minDiff = std::abs(x[0] - M_PI);\n    for (size_t i = 1; i < x.size(); ++i) {\n        double diff = std::abs(x[i] - M_PI);\n        if (diff < minDiff) {\n            minDiff = diff;\n            closestIndex = i;\n        }\n    }\n    return closestIndex;\n}\n"
    ]
  },
  {
    "problem_type": "search",
    "language": "cpp",
    "name": "38_search_find_the_first_even_number",
    "parallelism_model": "omp",
    "prompt": "#include <omp.h>\n\n/* Return the index of the first even number in the vector x.\n   Use OpenMP to parallelize the search.\n   Examples:\n\n   input: [7, 3, 9, 5, 5, 7, 2, 9, 12, 11]\n   output: 6\n\n   input: [3, 8, 9, 9, 3, 4, 8, 6]\n   output: 1\n*/\nsize_t findFirstEven(std::vector<int> const& x) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n    size_t result = x.size();\n    #pragma omp parallel for schedule(dynamic) shared(result)\n    for (size_t i = 0; i < x.size(); ++i) {\n        if (x[i] % 2 == 0) {\n            #pragma omp critical\n            {\n                if (i < result) {\n                    result = i;\n                }\n            }\n        }\n    }\n    return result;\n}\n"
    ]
  },
  {
    "problem_type": "search",
    "language": "cpp",
    "name": "38_search_find_the_first_even_number",
    "parallelism_model": "cuda",
    "prompt": "/* Find the index of the first even number in the vector x. Store it in firstEvenIndex.\n   Use CUDA to parallelize the search. The kernel is launched with at least as many threads as values in x.\n   Examples:\n\n   input: [7, 3, 9, 5, 5, 7, 2, 9, 12, 11]\n   output: 6\n\n   input: [3, 8, 9, 9, 3, 4, 8, 6]\n   output: 1\n*/\n__global__ void findFirstEven(const int *x, size_t N, size_t *firstEvenIndex) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n    extern __shared__ size_t sharedMin[];\n\n    size_t tid = threadIdx.x + blockIdx.x * blockDim.x;\n    size_t minIndex = N; // Initialize to invalid index\n\n    if (tid < N) {\n        if (x[tid] % 2 == 0) {\n            minIndex = tid;\n        }\n    }\n\n    sharedMin[threadIdx.x] = minIndex;\n    __syncthreads();\n\n    // Perform parallel reduction to find the minimum index\n    for (size_t s = blockDim.x / 2; s > 0; s >>= 1) {\n        if (threadIdx.x < s) {\n            if (sharedMin[threadIdx.x + s] < sharedMin[threadIdx.x]) {\n                sharedMin[threadIdx.x] = sharedMin[threadIdx.x + s];\n            }\n        }\n        __syncthreads();\n    }\n\n    if (threadIdx.x == 0) {\n        if (sharedMin[0] < *firstEvenIndex) {\n            *firstEvenIndex = sharedMin[0];\n        }\n    }\n}\n"
    ]
  },
  {
    "problem_type": "search",
    "language": "cpp",
    "name": "38_search_find_the_first_even_number",
    "parallelism_model": "serial",
    "prompt": "/* Return the index of the first even number in the vector x.\n   Examples:\n\n   input: [7, 3, 9, 5, 5, 7, 2, 9, 12, 11]\n   output: 6\n\n   input: [3, 8, 9, 9, 3, 4, 8, 6]\n   output: 1\n*/\nsize_t findFirstEven(std::vector<int> const& x) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n  for (size_t i = 0; i < x.size(); ++i) {\n    if ((x[i] & 1) == 0) {\n      return i;\n    }\n  }\n  return x.size();\n}\n"
    ]
  },
  {
    "problem_type": "search",
    "language": "cpp",
    "name": "35_search_search_for_last_struct_by_key",
    "parallelism_model": "omp",
    "prompt": "#include <omp.h>\n\nstruct Book {\n   std::string title;\n   int pages;\n};\n\n/* Return the index of the last Book item in the vector books where Book.pages is less than 100.\n   Use OpenMP to search in parallel.\n\t Example:\n\n   input: [{title=\"Green Eggs and Ham\", pages=72}, {title=\"gulliver's travels\", pages=362}, {title=\"Stories of Your Life\", pages=54}, {title=\"Hamilton\", pages=818}]\n   output: 2\n*/\nsize_t findLastShortBook(std::vector<Book> const& books) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\nsize_t findLastShortBook(std::vector<Book> const& books) {\n    size_t lastIndex = -1;\n    int n = books.size();\n    #pragma omp parallel\n    {\n        size_t localIndex = -1;\n        #pragma omp for schedule(guided)\n        for (int i = 0; i < n; ++i) {\n            if (books[i].pages < 100) {\n                localIndex = i;\n            }\n        }\n        #pragma omp critical\n        {\n            if (localIndex > lastIndex) {\n                lastIndex = localIndex;\n            }\n        }\n    }\n    return lastIndex;\n}\n"
    ]
  },
  {
    "problem_type": "search",
    "language": "cpp",
    "name": "35_search_search_for_last_struct_by_key",
    "parallelism_model": "cuda",
    "prompt": "struct Book {\n   const char* title;\n   int pages;\n};\n\n/* Find the index of the last Book item in the vector books where Book.pages is less than 100.\n   Store the result in lastShortBookIndex.\n   Use CUDA to search in parallel. The kernel is launched with one thread for every book element.\n\t Example:\n\n   input: [{title=\"Green Eggs and Ham\", pages=72}, {title=\"gulliver's travels\", pages=362}, {title=\"Stories of Your Life\", pages=54}, {title=\"Hamilton\", pages=818}]\n   output: 2\n*/\n__global__ void findLastShortBook(const Book *books, size_t N, size_t *lastShortBookIndex) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n   extern __shared__ size_t sharedIndices[];\n\n   size_t idx = blockIdx.x * blockDim.x + threadIdx.x;\n   size_t localIdx = threadIdx.x;\n   size_t groupSize = blockDim.x;\n\n   if (idx < N) {\n      sharedIndices[localIdx] = (books[idx].pages < 100) ? idx : -1;\n   } else {\n      sharedIndices[localIdx] = -1;\n   }\n\n   __syncthreads();\n\n   for (size_t stride = groupSize / 2; stride > 0; stride >>= 1) {\n      if (localIdx < stride) {\n         size_t left = sharedIndices[localIdx];\n         size_t right = sharedIndices[localIdx + stride];\n         sharedIndices[localIdx] = (right > left) ? right : left;\n      }\n      __syncthreads();\n   }\n\n   if (localIdx == 0) {\n      size_t globalMax = sharedIndices[0];\n      atomicMax((long long int *)lastShortBookIndex, (long long int)globalMax);\n   }\n}\n"
    ]
  },
  {
    "problem_type": "search",
    "language": "cpp",
    "name": "35_search_search_for_last_struct_by_key",
    "parallelism_model": "serial",
    "prompt": "struct Book {\n   std::string title;\n   int pages;\n};\n\n/* Return the index of the last Book item in the vector books where Book.pages is less than 100.\n\t Example:\n\n   input: [{title=\"Green Eggs and Ham\", pages=72}, {title=\"gulliver's travels\", pages=362}, {title=\"Stories of Your Life\", pages=54}, {title=\"Hamilton\", pages=818}]\n   output: 2\n*/\nsize_t findLastShortBook(std::vector<Book> const& books) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\nsize_t findLastShortBook(std::vector<Book> const& books) {\n    size_t index = -1;\n    for (size_t i = 0; i < books.size(); ++i) {\n        if (books[i].pages < 100) {\n            index = i;\n        }\n    }\n    return index;\n}\n"
    ]
  },
  {
    "problem_type": "search",
    "language": "cpp",
    "name": "36_search_check_if_array_contains_value",
    "parallelism_model": "omp",
    "prompt": "#include <omp.h>\n\n/* Return true if the vector x contains the value `target`. Return false otherwise.\n   Use OpenMP to search in parallel.\n   Examples:\n\n   input: x=[1, 8, 2, 6, 4, 6], target=3\n   output: false\n   \n   input: x=[1, 8, 2, 6, 4, 6], target=8\n   output: true\n*/\nbool contains(std::vector<int> const& x, int target) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n    bool found = false;\n    #pragma omp parallel for shared(found) schedule(guided) num_threads(32)\n    for (size_t i = 0; i < x.size(); ++i) {\n        if (x[i] == target) {\n            #pragma omp atomic write\n            found = true;\n        }\n    }\n    return found;\n}\n"
    ]
  },
  {
    "problem_type": "search",
    "language": "cpp",
    "name": "36_search_check_if_array_contains_value",
    "parallelism_model": "cuda",
    "prompt": "/* Set `found` to true if the vector x contains the value `target`. Set it to false otherwise.\n   Use CUDA to search in parallel. The kernel is launched with at least N threads.\n   Examples:\n\n   input: x=[1, 8, 2, 6, 4, 6], target=3\n   output: false\n   \n   input: x=[1, 8, 2, 6, 4, 6], target=8\n   output: true\n*/\n__global__ void contains(const int *x, size_t N, int target, bool *found) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n    extern __shared__ bool s_found[];\n    int tid = threadIdx.x;\n    s_found[tid] = false;\n    __syncthreads();\n\n    size_t i = blockIdx.x * blockDim.x + threadIdx.x;\n    if (i < N && x[i] == target) {\n        s_found[tid] = true;\n    }\n    __syncthreads();\n\n    for (int s = blockDim.x / 2; s > 0; s >>= 1) {\n        if (threadIdx.x < s) {\n            s_found[threadIdx.x] |= s_found[threadIdx.x + s];\n        }\n        __syncthreads();\n    }\n\n    if (threadIdx.x == 0) {\n        atomicOr(found, s_found[0]);\n    }\n}\n"
    ]
  },
  {
    "problem_type": "search",
    "language": "cpp",
    "name": "36_search_check_if_array_contains_value",
    "parallelism_model": "serial",
    "prompt": "/* Return true if the vector x contains the value `target`. Return false otherwise.\n   Examples:\n\n   input: x=[1, 8, 2, 6, 4, 6], target=3\n   output: false\n   \n   input: x=[1, 8, 2, 6, 4, 6], target=8\n   output: true\n*/\nbool contains(std::vector<int> const& x, int target) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n    for (int i = 0; i < x.size(); ++i) {\n        if (x[i] == target) {\n            return true;\n        }\n    }\n    return false;\n}\n"
    ]
  },
  {
    "problem_type": "fft",
    "language": "cpp",
    "name": "05_fft_inverse_fft",
    "parallelism_model": "omp",
    "prompt": "#include <omp.h>\n\n/* forward declare fft. computes fourier transform in-place */\nvoid fft(std::vector<std::complex<double>> &x);\n\n/* Compute the inverse fourier transform of x in-place.\n   Use OpenMP to compute in parallel.\n   Example:\n   \n   input: [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n   output: [{0.5,0}, {0.125,0.301777}, {0,-0}, {0.125,0.0517767}, {0,-0}, {0.125,-0.0517767}, {0,-0}, {0.125,-0.301777}]\n*/\nvoid ifft(std::vector<std::complex<double>> &x) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\nvoid ifft(std::vector<std::complex<double>> &x) {\n    #pragma omp parallel\n    {\n        #pragma omp for schedule(guided)\n        for (size_t i = 0; i < x.size(); ++i) {\n            x[i] = std::conj(x[i]);\n        }\n    }\n    fft(x);\n    #pragma omp parallel\n    {\n        #pragma omp for schedule(guided)\n        for (size_t i = 0; i < x.size(); ++i) {\n            x[i] = std::conj(x[i]) / static_cast<double>(x.size());\n        }\n    }\n}\n"
    ]
  },
  {
    "problem_type": "fft",
    "language": "cpp",
    "name": "05_fft_inverse_fft",
    "parallelism_model": "cuda",
    "prompt": "/* Compute the inverse fourier transform of x in-place.\n   Use CUDA to compute in parallel. The kernel is launched with at least N threads.\n   Example:\n   \n   input: [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n   output: [{0.5,0}, {0.125,0.301777}, {0,-0}, {0.125,0.0517767}, {0,-0}, {0.125,-0.0517767}, {0,-0}, {0.125,-0.301777}]\n*/\n__global__ void ifft(cuDoubleComplex *x, size_t N) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n    extern __shared__ cuDoubleComplex shared[];\n    size_t tid = threadIdx.x;\n    size_t i = tid;\n    while (i < N) {\n        shared[i] = x[i];\n        i += blockDim.x;\n    }\n    __syncthreads();\n\n    for (size_t s = 1; s < N; s *= 2) {\n        size_t m = 1 << s;\n        size_t mh = m >> 1;\n        for (size_t k = tid; k < N; k += blockDim.x) {\n            if ((k & (m - 1)) < mh) {\n                cuDoubleComplex t = cuCmul(shared[k + mh], cuComplexExp(cuDoubleComplex{0.0, 2.0 * M_PI * (double)(k & (mh - 1)) / (double)m}));\n                shared[k + mh] = cuCsub(shared[k], t);\n                shared[k] = cuCadd(shared[k], t);\n            }\n        }\n        __syncthreads();\n    }\n\n    size_t rev = tid;\n    rev = ((rev & 0x55555555) << 1) | ((rev & 0xAAAAAAA) >> 1);\n    rev = ((rev & 0x33333333) << 2) | ((rev & 0xCCCCCCC) >> 2);\n    rev = ((rev & 0x0F0F0F0F) << 4) | ((rev & 0xF0F0F0F0) >> 4);\n    rev = ((rev & 0x00FF00FF) << 8) | ((rev & 0xFF00FF00) >> 8);\n    rev = ((rev & 0x0000FFFF) << 16) | ((rev & 0xFFFF0000) >> 16);\n    rev >>= (32 - log2(N));\n    if (rev < N) {\n        x[rev] = cuCdiv(shared[tid], cuDoubleComplex{(double)N, 0.0});\n    }\n}\n"
    ]
  },
  {
    "problem_type": "fft",
    "language": "cpp",
    "name": "05_fft_inverse_fft",
    "parallelism_model": "serial",
    "prompt": "/* forward declare fft. computes fourier transform in-place */\nvoid fft(std::vector<std::complex<double>> &x);\n\n/* Compute the inverse fourier transform of x in-place.\n   Example:\n   \n   input: [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n   output: [{0.5,0}, {0.125,0.301777}, {0,-0}, {0.125,0.0517767}, {0,-0}, {0.125,-0.0517767}, {0,-0}, {0.125,-0.301777}]\n*/\nvoid ifft(std::vector<std::complex<double>> &x) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\nvoid ifft(std::vector<std::complex<double>> &x) {\n    const size_t n = x.size();\n    for (size_t i = 0; i < n; ++i) {\n        x[i] = std::conj(x[i]);\n    }\n    fft(x);\n    for (size_t i = 0; i < n; ++i) {\n        x[i] = std::conj(x[i]) / static_cast<double>(n);\n    }\n}\n"
    ]
  },
  {
    "problem_type": "fft",
    "language": "cpp",
    "name": "08_fft_split_fft",
    "parallelism_model": "omp",
    "prompt": "#include <omp.h>\n\n/* Compute the fourier transform of x. Store real part of results in r and imaginary in i.\n   Use OpenMP to compute in parallel.\n   Example:\n\n   input: [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n   output: r: [4, 1, 0, 1, 0, 1, 0, 1] i: [0, -2.41421, 0, -0.414214, 0, 0.414214, 0, 2.41421]\n*/\nvoid fft(std::vector<std::complex<double>> const& x, std::vector<double> &r, std::vector<double> &i) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\nvoid fft(std::vector<std::complex<double>> const& x, std::vector<double> &r, std::vector<double> &i) {\n    const size_t N = x.size();\n    r.resize(N);\n    i.resize(N);\n\n    #pragma omp parallel for schedule(guided) num_threads(32)\n    for (size_t k = 0; k < N; ++k) {\n        std::complex<double> sum(0.0, 0.0);\n        for (size_t n = 0; n < N; ++n) {\n            double angle = -2.0 * M_PI * static_cast<double>(k * n) / static_cast<double>(N);\n            sum += x[n] * std::complex<double>(cos(angle), sin(angle));\n        }\n        r[k] = sum.real();\n        i[k] = sum.imag();\n    }\n}\n"
    ]
  },
  {
    "problem_type": "fft",
    "language": "cpp",
    "name": "08_fft_split_fft",
    "parallelism_model": "cuda",
    "prompt": "/* Compute the fourier transform of x. Store real part of results in r and imaginary in i.\n   Use CUDA to compute in parallel. The kernel is launched with at least N threads.\n   Example:\n\n   input: [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n   output: r: [4, 1, 0, 1, 0, 1, 0, 1] i: [0, -2.41421, 0, -0.414214, 0, 0.414214, 0, 2.41421]\n*/\n__global__ void fft(const cuDoubleComplex *x, double *r, double *i, size_t N) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n    unsigned int tid = threadIdx.x + blockIdx.x * blockDim.x;\n    if (tid >= N) return;\n\n    cuDoubleComplex result = make_cuDoubleComplex(0.0, 0.0);\n    for (size_t k = 0; k < N; ++k) {\n        double angle = -2.0 * M_PI * tid * k / N;\n        cuDoubleComplex exp_val = make_cuDoubleComplex(cos(angle), sin(angle));\n        result = cuCadd(result, cuCmul(exp_val, x[k]));\n    }\n\n    r[tid] = cuCreal(result)\n    i[tid] = cuCimag(result)\n}\n"
    ]
  },
  {
    "problem_type": "fft",
    "language": "cpp",
    "name": "08_fft_split_fft",
    "parallelism_model": "serial",
    "prompt": "/* Compute the fourier transform of x. Store real part of results in r and imaginary in i.\n   Example:\n\n   input: [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n   output: r: [4, 1, 0, 1, 0, 1, 0, 1] i: [0, -2.41421, 0, -0.414214, 0, 0.414214, 0, 2.41421]\n*/\nvoid fft(std::vector<std::complex<double>> const& x, std::vector<double> &r, std::vector<double> &i) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n    const size_t N = x.size();\n    r.resize(N);\n    i.resize(N);\n\n    std::vector<std::complex<double>> X(N);\n    for (size_t k = 0; k < N; ++k) {\n        double sum_real = 0.0;\n        double sum_imag = 0.0;\n        for (size_t n = 0; n < N; ++n) {\n            double angle = 2 * M_PI * k * n / N;\n            sum_real += x[n].real() * std::cos(angle) + x[n].imag() * std::sin(angle);\n            sum_imag += x[n].real() * std::sin(angle) - x[n].imag() * std::cos(angle);\n        }\n        X[k] = std::complex<double>(sum_real, sum_imag);\n    }\n\n    for (size_t k = 0; k < N; ++k) {\n        r[k] = X[k].real();\n        i[k] = X[k].imag();\n    }\n}\n"
    ]
  },
  {
    "problem_type": "fft",
    "language": "cpp",
    "name": "07_fft_fft_conjugate",
    "parallelism_model": "omp",
    "prompt": "#include <omp.h>\n\n/* Compute the fourier transform of x in-place. Return the imaginary conjugate of each value.\n   Use OpenMP to compute in parallel.\n   Example:\n\n   input: [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n   output: [{4,0}, {1,-2.41421}, {0,0}, {1,-0.414214}, {0,0}, {1,0.414214}, {0,0}, {1,2.41421}]\n*/\nvoid fftConjugate(std::vector<std::complex<double>> &x) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n    const size_t N = x.size();\n    if (N <= 1) return;\n\n    // Bit-reversal permutation\n    #pragma omp parallel\n    {\n        #pragma omp for\n        for (size_t i = 0; i < N; ++i) {\n            size_t j = 0;\n            for (size_t bit = 1; bit < N; bit <<= 1) {\n                j = (j << 1) | (i & 1);\n                i &= ~1;\n                i >>= 1;\n            }\n            if (j > i) std::swap(x[i], x[j]);\n        }\n    }\n\n    // Danielson-Lanczos lemma\n    for (size_t m = 2; m <= N; m <<= 1) {\n        size_t mh = m >> 1;\n        std::complex<double> w(std::cos(M_PI / mh), -std::sin(M_PI / mh));\n        #pragma omp parallel\n        {\n            std::complex<double> wp(1, 0);\n            #pragma omp for collapse(2)\n            for (size_t i = 0; i < N; i += m) {\n                for (size_t j = 0; j < mh; ++j) {\n                    std::complex<double> u = x[i + j];\n                    std::complex<double> t = wp * x[i + j + mh];\n                    x[i + j] = u + t;\n                    x[i + j + mh] = u - t;\n                }\n                wp *= w;\n            }\n        }\n    }\n\n    // Compute the imaginary conjugate of each value\n    #pragma omp parallel for\n    for (size_t i = 0; i < N; ++i) {\n        x[i] = std::conj(x[i]);\n    }\n}\n"
    ]
  },
  {
    "problem_type": "fft",
    "language": "cpp",
    "name": "07_fft_fft_conjugate",
    "parallelism_model": "cuda",
    "prompt": "/* Compute the fourier transform of x in-place. Return the imaginary conjugate of each value.\n   Use CUDA to compute in parallel. The kernel is launched with at least N threads.\n   Example:\n\n   input: [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n   output: [{4,0}, {1,-2.41421}, {0,0}, {1,-0.414214}, {0,0}, {1,0.414214}, {0,0}, {1,2.41421}]\n*/\n__global__ void fftConjugate(cuDoubleComplex *x, size_t N) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n    unsigned int i = threadIdx.x + blockIdx.x * blockDim.x;\n    if (i < N) {\n        cuDoubleComplex val = x[i];\n        x[i] = make_cuDoubleComplex(cuCreal(val), -cuCimag(val));\n    }\n}\n"
    ]
  },
  {
    "problem_type": "fft",
    "language": "cpp",
    "name": "07_fft_fft_conjugate",
    "parallelism_model": "serial",
    "prompt": "/* Compute the fourier transform of x in-place. Return the imaginary conjugate of each value.\n   Example:\n\n   input: [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n   output: [{4,0}, {1,-2.41421}, {0,0}, {1,-0.414214}, {0,0}, {1,0.414214}, {0,0}, {1,2.41421}]\n*/\nvoid fftConjugate(std::vector<std::complex<double>> &x) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\nvoid fftConjugate(std::vector<std::complex<double>> &x) {\n    const size_t N = x.size();\n    if (N <= 1) return;\n\n    std::vector<std::complex<double>> even(N / 2), odd(N / 2);\n    for (size_t k = 0; k < N / 2; ++k) {\n        even[k] = x[2 * k];\n        odd[k] = x[2 * k + 1];\n    }\n\n    fftConjugate(even);\n    fftConjugate(odd);\n\n    for (size_t k = 0; k < N / 2; ++k) {\n        const double theta = -2 * M_PI * k / N;\n        std::complex<double> w = std::complex<double>(cos(theta), sin(theta)) * odd[k];\n        x[k] = even[k] + w;\n        x[k + N / 2] = even[k] - w;\n    }\n}\n"
    ]
  },
  {
    "problem_type": "fft",
    "language": "cpp",
    "name": "09_fft_fft_out_of_place",
    "parallelism_model": "omp",
    "prompt": "#include <omp.h>\n\n/* Compute the fourier transform of x. Store the result in output.\n   Use OpenMP to compute in parallel.\n   Example:\n\n   input: [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n   output: [{4,0}, {1,-2.42421}, {0,0}, {1,-0.414214}, {0,0}, {1,0.414214}, {0,0}, {1,2.41421}]\n*/\nvoid fft(std::vector<std::complex<double>> const& x, std::vector<std::complex<double>> &output) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n    const size_t N = x.size();\n    const double TWOPI = 6.283185307179586;\n\n    output.resize(N);\n\n    #pragma omp parallel\n    {\n        size_t thread_id = omp_get_thread_num();\n        size_t num_threads = omp_get_num_threads();\n        size_t chunk_size = N / num_threads;\n        size_t start = thread_id * chunk_size;\n        size_t end = (thread_id == num_threads - 1) ? N : start + chunk_size;\n\n        for (size_t k = start; k < end; ++k) {\n            std::complex<double> sum(0.0, 0.0);\n            for (size_t n = 0; n < N; ++n) {\n                double real = std::cos(TWOPI * k * n / N);\n                double imag = -std::sin(TWOPI * k * n / N);\n                sum += x[n] * std::complex<double>(real, imag);\n            }\n            output[k] = sum;\n        }\n    }\n}\n"
    ]
  },
  {
    "problem_type": "fft",
    "language": "cpp",
    "name": "09_fft_fft_out_of_place",
    "parallelism_model": "cuda",
    "prompt": "/* Compute the fourier transform of x. Store the result in output.\n   Use CUDA to compute in parallel. The kernel is launched with at least N threads.\n   Example:\n\n   input: [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n   output: [{4,0}, {1,-2.42421}, {0,0}, {1,-0.414214}, {0,0}, {1,0.414214}, {0,0}, {1,2.41421}]\n*/\n__global__ void fft(const cuDoubleComplex *x, cuDoubleComplex *output, size_t N) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n    unsigned int tid = threadIdx.x + blockIdx.x * blockDim.x;\n    if (tid >= N) return;\n\n    double angle = -2.0 * M_PI * tid / N;\n    cuDoubleComplex w = make_cuDoubleComplex(cos(angle), sin(angle));\n    cuDoubleComplex result = make_cuDoubleComplex(0.0, 0.0);\n\n    for (size_t k = 0; k < N; ++k) {\n        double angle_k = 2.0 * M_PI * k * tid / N;\n        cuDoubleComplex exp_term = make_cuDoubleComplex(cos(angle_k), sin(angle_k));\n        result = cuCadd(result, cuCmul(exp_term, x[k]));\n    }\n\n    output[tid] = result;\n}\n"
    ]
  },
  {
    "problem_type": "fft",
    "language": "cpp",
    "name": "09_fft_fft_out_of_place",
    "parallelism_model": "serial",
    "prompt": "/* Compute the fourier transform of x. Store the result in output.\n   Example:\n\n   input: [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n   output: [{4,0}, {1,-2.42421}, {0,0}, {1,-0.414214}, {0,0}, {1,0.414214}, {0,0}, {1,2.41421}]\n*/\nvoid fft(std::vector<std::complex<double>> const& x, std::vector<std::complex<double>> &output) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n    const size_t N = x.size();\n    if (N <= 1) {\n        output = std::vector<std::complex<double>>(x);\n        return;\n    }\n\n    std::vector<std::complex<double>> even(N / 2), odd(N / 2);\n    for (size_t k = 0; k < N / 2; ++k) {\n        even[k] = x[2 * k];\n        odd[k] = x[2 * k + 1];\n    }\n\n    std::vector<std::complex<double>> even_fft(N / 2), odd_fft(N / 2);\n    fft(even, even_fft);\n    fft(odd, odd_fft);\n\n    output.resize(N);\n    for (size_t k = 0; k < N / 2; ++k) {\n        std::complex<double> const t = std::polar(1.0, -2 * M_PI * k / N) * odd_fft[k];\n        output[k] = even_fft[k] + t;\n        output[k + N / 2] = even_fft[k] - t;\n    }\n}\n"
    ]
  },
  {
    "problem_type": "fft",
    "language": "cpp",
    "name": "06_fft_dft",
    "parallelism_model": "omp",
    "prompt": "#include <omp.h>\n\n/* Compute the discrete fourier transform of x. Store the result in output.\n   Use OpenMP to compute in parallel.\n   Example:\n\n   input: [1, 4, 9, 16]\n   output: [30+0i, -8-12i, -10-0i, -8+12i]\n*/\nvoid dft(std::vector<double> const& x, std::vector<std::complex<double>> &output) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\nvoid dft(std::vector<double> const& x, std::vector<std::complex<double>> &output) {\n    int N = x.size();\n    #pragma omp parallel for schedule(guided) num_threads(32)\n    for (int k = 0; k < N; ++k) {\n        std::complex<double> sum(0, 0);\n        for (int n = 0; n < N; ++n) {\n            double real = std::cos(2 * M_PI * k * n / N);\n            double imag = -std::sin(2 * M_PI * k * n / N);\n            sum += x[n] * std::complex<double>(real, imag);\n        }\n        output[k] = sum;\n    }\n}\n"
    ]
  },
  {
    "problem_type": "fft",
    "language": "cpp",
    "name": "06_fft_dft",
    "parallelism_model": "cuda",
    "prompt": "/* Compute the discrete fourier transform of x. Store the result in output.\n   Use CUDA to compute in parallel. The kernel is launched with at least N threads.\n   Example:\n\n   input: [1, 4, 9, 16]\n   output: [30+0i, -8-12i, -10-0i, -8+12i]\n*/\n__global__ void dft(const double *x, cuDoubleComplex *output, size_t N) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n    size_t k = blockIdx.x * blockDim.x + threadIdx.x;\n    if (k >= N) return;\n\n    cuDoubleComplex result = make_cuDoubleComplex(0.0, 0.0);\n    double angle = -2.0 * M_PI * k / N;\n\n    for (size_t n = 0; n < N; ++n) {\n        double real = x[n] * cos(angle * n);\n        double imag = x[n] * sin(angle * n);\n        result = cuCadd(result, make_cuDoubleComplex(real, imag));\n    }\n\n    output[k] = result;\n}\n"
    ]
  },
  {
    "problem_type": "fft",
    "language": "cpp",
    "name": "06_fft_dft",
    "parallelism_model": "serial",
    "prompt": "/* Compute the discrete fourier transform of x. Store the result in output.\n   Example:\n\n   input: [1, 4, 9, 16]\n   output: [30+0i, -8-12i, -10-0i, -8+12i]\n*/\nvoid dft(std::vector<double> const& x, std::vector<std::complex<double>> &output) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\nvoid dft(std::vector<double> const& x, std::vector<std::complex<double>> &output) {\n    size_t N = x.size();\n    output.resize(N);\n    #pragma omp parallel for\n    for (size_t k = 0; k < N; ++k) {\n        std::complex<double> sum(0.0, 0.0);\n        double real_part = 0.0, imag_part = 0.0;\n        double theta = -2.0 * M_PI * k / N;\n        double cos_theta = std::cos(theta);\n        double sin_theta = std::sin(theta);\n        double twiddle_real = 1.0;\n        double twiddle_imag = 0.0;\n        for (size_t n = 0; n < N; ++n) {\n            real_part += x[n] * twiddle_real;\n            imag_part += x[n] * twiddle_imag;\n            double next_twiddle_real = twiddle_real * cos_theta - twiddle_imag * sin_theta;\n            twiddle_imag = twiddle_real * sin_theta + twiddle_imag * cos_theta;\n            twiddle_real = next_twiddle_real;\n        }\n        output[k] = std::complex<double>(real_part, imag_part);\n    }\n}\n"
    ]
  },
  {
    "problem_type": "scan",
    "language": "cpp",
    "name": "33_scan_reverse_prefix_sum",
    "parallelism_model": "omp",
    "prompt": "#include <omp.h>\n\n/* Compute the reverse prefix sum of the vector x into output.\n   Use OpenMP to compute in parallel.\n   Examples:\n   \n   input: [1, 7, 4, 6, 6, 2]\n   output: [2, 8, 14, 18, 25, 26]\n\n   input: [3, 3, 7, 1, -2]\n   output: [-2, -1, 6, 9, 12]\n*/\nvoid reversePrefixSum(std::vector<int> const& x, std::vector<int> &output) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n    int n = x.size();\n    output.resize(n);\n    if (n == 0) return;\n\n    // Initialize the last element of output\n    output[n - 1] = x[n - 1];\n\n    // Parallel reverse prefix sum using OpenMP\n    #pragma omp parallel shared(output, x) num_threads(32)\n    {\n        #pragma omp for schedule(guided) nowait\n        for (int i = n - 2; i >= 0; --i) {\n            output[i] = output[i + 1] + x[i];\n        }\n    }\n}\n"
    ]
  },
  {
    "problem_type": "scan",
    "language": "cpp",
    "name": "33_scan_reverse_prefix_sum",
    "parallelism_model": "cuda",
    "prompt": "/* Compute the reverse prefix sum of the vector x into output.\n   Use CUDA to compute in parallel. The kernel is launched with at least as many threads as values in x.\n   Examples:\n   \n   input: [1, 7, 4, 6, 6, 2]\n   output: [2, 8, 14, 18, 25, 26]\n\n   input: [3, 3, 7, 1, -2]\n   output: [-2, -1, 6, 9, 12]\n*/\n__global__ void reversePrefixSum(const int *x, int *output, size_t N) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n    extern __shared__ int s_data[];\n    unsigned int tid = threadIdx.x;\n    unsigned int i = blockIdx.x * blockDim.x + threadIdx.x;\n\n    // Load data into shared memory, reversing the order within each block\n    if (i < N) {\n        s_data[tid] = x[N - 1 - i];\n    }\n    __syncthreads();\n\n    // Perform inclusive prefix sum on shared memory\n    for (unsigned int s = 1; s <= blockDim.x; s *= 2) {\n        if (tid >= s) {\n            s_data[tid] += s_data[tid - s];\n        }\n        __syncthreads();\n    }\n\n    // Write the result in reverse order\n    if (i < N) {\n        output[i] = s_data[tid];\n    }\n}\n"
    ]
  },
  {
    "problem_type": "scan",
    "language": "cpp",
    "name": "33_scan_reverse_prefix_sum",
    "parallelism_model": "serial",
    "prompt": "/* Compute the reverse prefix sum of the vector x into output.\n   Examples:\n   \n   input: [1, 7, 4, 6, 6, 2]\n   output: [2, 8, 14, 18, 25, 26]\n\n   input: [3, 3, 7, 1, -2]\n   output: [-2, -1, 6, 9, 12]\n*/\nvoid reversePrefixSum(std::vector<int> const& x, std::vector<int> &output) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\nvoid reversePrefixSum(std::vector<int> const& x, std::vector<int> &output) {\n    int n = x.size();\n    output.resize(n);\n    int sum = 0;\n    for (int i = n - 1; i >= 0; --i) {\n        sum += x[i];\n        output[i] = sum;\n    }\n}\n"
    ]
  },
  {
    "problem_type": "scan",
    "language": "cpp",
    "name": "30_scan_prefix_sum",
    "parallelism_model": "omp",
    "prompt": "#include <omp.h>\n\n/* Compute the prefix sum of the vector x into output.\n   Use OpenMP to compute in parallel.\n   Example:\n   \n   input: [1, 7, 4, 6, 6, 2]\n   output: [1, 8, 12, 18, 24, 26]\n*/\nvoid prefixSum(std::vector<double> const& x, std::vector<double> &output) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n{\n    size_t n = x.size();\n    output.resize(n);\n    if (n == 0) return;\n\n    size_t num_threads = 32;\n    omp_set_num_threads(num_threads);\n\n    std::vector<double> thread_sums(num_threads, 0.0);\n    std::vector<double> prefix_sums(n);\n\n    #pragma omp parallel\n    {\n        int tid = omp_get_thread_num();\n        int nthr = omp_get_num_threads();\n\n        size_t chunk_size = (n + nthr - 1) / nthr;\n        size_t start = tid * chunk_size;\n        size_t end = std::min(start + chunk_size, n);\n\n        double local_sum = 0.0;\n        for (size_t i = start; i < end; ++i) {\n            local_sum += x[i];\n            prefix_sums[i] = local_sum;\n        }\n\n        thread_sums[tid] = local_sum;\n        #pragma omp barrier\n\n        double prefix = 0.0;\n        #pragma omp for schedule(static)\n        for (int i = 0; i < nthr; ++i) {\n            for (int j = 0; j < i; ++j) {\n                prefix += thread_sums[j];\n            }\n            if (i == 0) {\n                #pragma omp simd\n                for (size_t i = 0; i < chunk_size && i < n; ++i) {\n                    output[i] = prefix_sums[i];\n                }\n            } else {\n                size_t offset = i * chunk_size;\n                double base = prefix;\n                #pragma omp simd\n                for (size_t j = 0; j < chunk_size && (offset + j) < n; ++j) {\n                    output[offset + j] = base + prefix_sums[offset + j];\n                }\n            }\n            prefix = 0.0;\n        }\n    }\n}\n"
    ]
  },
  {
    "problem_type": "scan",
    "language": "cpp",
    "name": "30_scan_prefix_sum",
    "parallelism_model": "cuda",
    "prompt": "/* Compute the prefix sum of the vector x into output.\n   Use CUDA to compute in parallel. The kernel is launched with at least as many threads as elements in x.\n   Example:\n   \n   input: [1, 7, 4, 6, 6, 2]\n   output: [1, 8, 12, 18, 24, 26]\n*/\n__global__ void prefixSum(const double *x, double *output, size_t N) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n    extern __shared__ double s_data[];\n    unsigned int tid = threadIdx.x;\n    unsigned int i = blockIdx.x * blockDim.x + threadIdx.x;\n\n    if (i < N) {\n        s_data[tid] = x[i];\n    } else {\n        s_data[tid] = 0;\n    }\n\n    for (unsigned int s = 1; s < blockDim.x; s *= 2) {\n        __syncthreads();\n        if (tid >= s) {\n            s_data[tid] += s_data[tid - s];\n        }\n    }\n\n    __syncthreads();\n\n    if (i < N) {\n        output[i] = s_data[tid];\n    }\n}\n"
    ]
  },
  {
    "problem_type": "scan",
    "language": "cpp",
    "name": "30_scan_prefix_sum",
    "parallelism_model": "serial",
    "prompt": "/* Compute the prefix sum of the vector x into output.\n   Example:\n   \n   input: [1, 7, 4, 6, 6, 2]\n   output: [1, 8, 12, 18, 24, 26]\n*/\nvoid prefixSum(std::vector<double> const& x, std::vector<double> &output) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\nvoid prefixSum(std::vector<double> const& x, std::vector<double> &output) {\n    output.resize(x.size());\n    if (x.empty()) return;\n    double sum = 0.0;\n    for (size_t i = 0; i < x.size(); ++i) {\n        sum += x[i];\n        output[i] = sum;\n    }\n}\n"
    ]
  },
  {
    "problem_type": "scan",
    "language": "cpp",
    "name": "34_scan_largest_contiguous_subarray_sum",
    "parallelism_model": "omp",
    "prompt": "#include <omp.h>\n\n/* Return the largest sum of any contiguous subarray in the vector x.\n   i.e. if x=[\u22122, 1, \u22123, 4, \u22121, 2, 1, \u22125, 4] then [4, \u22121, 2, 1] is the contiguous\n   subarray with the largest sum of 6.\n   Use OpenMP to compute in parallel.\n   Example:\n\n   input: [\u22122, 1, \u22123, 4, \u22121, 2, 1, \u22125, 4]\n   output: 6\n*/\nint maximumSubarray(std::vector<int> const& x) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n    int n = x.size();\n    if (n == 0) return 0;\n\n    int global_max = x[0];\n    std::vector<int> local_max(n);\n    int num_threads = 32;\n\n    #pragma omp parallel num_threads(num_threads) shared(x, n, global_max)\n    {\n        int tid = omp_get_thread_num();\n        int chunk_size = (n + num_threads - 1) / num_threads;\n        int start = tid * chunk_size;\n        int end = std::min(start + chunk_size, n);\n\n        if (start >= n) return;\n\n        int current_sum = x[start];\n        int max_sum = x[start];\n\n        for (int i = start + 1; i < end; ++i) {\n            current_sum = std::max(x[i], current_sum + x[i]);\n            max_sum = std::max(max_sum, current_sum);\n        }\n\n        #pragma omp critical\n        {\n            if (tid == 0) {\n                global_max = max_sum;\n            } else {\n                global_max = std::max(global_max, max_sum);\n            }\n        }\n    }\n\n    return global_max;\n}\n"
    ]
  },
  {
    "problem_type": "scan",
    "language": "cpp",
    "name": "34_scan_largest_contiguous_subarray_sum",
    "parallelism_model": "cuda",
    "prompt": "/* Compute the largest sum of any contiguous subarray in the vector x.\n   i.e. if x=[\u22122, 1, \u22123, 4, \u22121, 2, 1, \u22125, 4] then [4, \u22121, 2, 1] is the contiguous\n   subarray with the largest sum of 6.\n   Store the result in sum.\n   Use CUDA to compute in parallel. The kernel is launched with at least as many threads as values in x.\n   Example:\n\n   input: [\u22122, 1, \u22123, 4, \u22121, 2, 1, \u22125, 4]\n   output: 6\n*/\n__global__ void maximumSubarray(const int *x, size_t N, int *sum) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n    extern __shared__ int s_data[];\n    int tid = threadIdx.x;\n    int global_tid = blockIdx.x * blockDim.x + threadIdx.x;\n\n    if (global_tid < N) {\n        s_data[tid] = x[global_tid];\n    }\n    __syncthreads();\n\n    int max_ending_here = s_data[tid];\n    int max_so_far = s_data[tid];\n    for (int i = 1; i < blockDim.x && (global_tid + i) < N; ++i) {\n        max_ending_here = max(s_data[tid + i], max_ending_here + s_data[tid + i]);\n        max_so_far = max(max_so_far, max_ending_here);\n    }\n\n    s_data[tid] = max_so_far;\n    __syncthreads();\n\n    for (int s = blockDim.x / 2; s > 0; s >>= 1) {\n        if (tid < s) {\n            s_data[tid] = max(s_data[tid], s_data[tid + s]);\n        }\n        __syncthreads();\n    }\n\n    if (tid == 0) {\n        atomicMax(sum, s_data[0]);\n    }\n}\n"
    ]
  },
  {
    "problem_type": "scan",
    "language": "cpp",
    "name": "34_scan_largest_contiguous_subarray_sum",
    "parallelism_model": "serial",
    "prompt": "/* Return the largest sum of any contiguous subarray in the vector x.\n   i.e. if x=[\u22122, 1, \u22123, 4, \u22121, 2, 1, \u22125, 4] then [4, \u22121, 2, 1] is the contiguous\n   subarray with the largest sum of 6.\n   Example:\n\n   input: [\u22122, 1, \u22123, 4, \u22121, 2, 1, \u22125, 4]\n   output: 6\n*/\nint maximumSubarray(std::vector<int> const& x) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n    if (x.empty()) return 0;\n    int maxSoFar = x[0];\n    int currentMax = x[0];\n    for (size_t i = 1; i < x.size(); ++i) {\n        currentMax = std::max(x[i], currentMax + x[i]);\n        maxSoFar = std::max(maxSoFar, currentMax);\n    }\n    return maxSoFar;\n}\n"
    ]
  },
  {
    "problem_type": "scan",
    "language": "cpp",
    "name": "32_scan_sum_of_prefix_sum_array",
    "parallelism_model": "omp",
    "prompt": "#include <omp.h>\n\n/* Compute the prefix sum array of the vector x and return its sum.\n   Use OpenMP to compute in parallel.\n   Example:\n\n   input: [-7, 2, 1, 9, 4, 8]\n   output: 15\n*/\ndouble sumOfPrefixSum(std::vector<double> const& x) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\ndouble sum = 0.0;\ndouble prefix_sum = 0.0;\n#pragma omp parallel for reduction(+:prefix_sum) schedule(guided) num_threads(32)\nfor (size_t i = 0; i < x.size(); ++i) {\n    prefix_sum += x[i];\n    sum += prefix_sum;\n}\nreturn sum;\n}\n"
    ]
  },
  {
    "problem_type": "scan",
    "language": "cpp",
    "name": "32_scan_sum_of_prefix_sum_array",
    "parallelism_model": "cuda",
    "prompt": "/* Compute the prefix sum array of the vector x and compute its sum. Store the result in sum.\n   Use CUDA to compute in parallel. The kernel is launched with at least as many threads as values in x.\n   Example:\n\n   input: [-7, 2, 1, 9, 4, 8]\n   output: 15\n*/\n__global__ void sumOfPrefixSum(const double *x, size_t N, double *sum) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n    extern __shared__ double s_data[];\n    size_t tid = threadIdx.x;\n    size_t i = blockIdx.x * blockDim.x + threadIdx.x;\n\n    if (i < N) {\n        s_data[tid] = x[i];\n    } else {\n        s_data[tid] = 0.0;\n    }\n\n    __syncthreads();\n\n    for (size_t s = 1; s < blockDim.x; s *= 2) {\n        if (tid >= s) {\n            s_data[tid] += s_data[tid - s];\n        }\n        __syncthreads();\n    }\n\n    if (tid == blockDim.x - 1) {\n        atomicAdd(sum, s_data[tid]);\n    }\n}\n"
    ]
  },
  {
    "problem_type": "scan",
    "language": "cpp",
    "name": "32_scan_sum_of_prefix_sum_array",
    "parallelism_model": "serial",
    "prompt": "/* Compute the prefix sum array of the vector x and return its sum.\n   Example:\n\n   input: [-7, 2, 1, 9, 4, 8]\n   output: 15\n*/\ndouble sumOfPrefixSum(std::vector<double> const& x) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\ndouble sum = 0.0;\ndouble prefix = 0.0;\nfor (size_t i = 0; i < x.size(); ++i) {\n    prefix += x[i];\n    sum += prefix;\n}\nreturn sum;\n}\n"
    ]
  },
  {
    "problem_type": "scan",
    "language": "cpp",
    "name": "31_scan_scan_with_min_function",
    "parallelism_model": "omp",
    "prompt": "#include <omp.h>\n\n/* Replace the i-th element of the vector x with the minimum value from indices 0 through i.\n   Use OpenMP to compute in parallel.\n   Examples:\n\n   input: [8, 6, -1, 7, 3, 4, 4]\n   output: [8, 6, -1, -1, -1, -1, -1]\n\n   input: [5, 4, 6, 4, 3, 6, 1, 1]\n   output: [5, 4, 4, 4, 3, 3, 1, 1]\n*/\nvoid partialMinimums(std::vector<float> &x) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\nvoid partialMinimums(std::vector<float> &x) {\n    int n = x.size();\n    #pragma omp parallel\n    {\n        int num_threads = omp_get_num_threads();\n        int thread_id = omp_get_thread_num();\n        int chunk_size = (n + num_threads - 1) / num_threads;\n        int start = thread_id * chunk_size;\n        int end = std::min(start + chunk_size, n);\n\n        float min_val = std::numeric_limits<float>::infinity();\n        for (int i = start; i < end; ++i) {\n            min_val = std::min(min_val, x[i]);\n            #pragma omp critical\n            {\n                x[i] = std::min(x[i], (i == 0 ? x[0] : x[i-1]));\n            }\n        }\n    }\n}\n"
    ]
  },
  {
    "problem_type": "scan",
    "language": "cpp",
    "name": "31_scan_scan_with_min_function",
    "parallelism_model": "cuda",
    "prompt": "/* Replace the i-th element of the vector x with the minimum value from indices 0 through i.\n   Use CUDA to compute in parallel. The kernel is launched with at least as many threads as values in x.\n   Examples:\n\n   input: [8, 6, -1, 7, 3, 4, 4]\n   output: [8, 6, -1, -1, -1, -1, -1]\n\n   input: [5, 4, 6, 4, 3, 6, 1, 1]\n   output: [5, 4, 4, 4, 3, 3, 1, 1]\n*/\n__global__ void partialMinimums(float *x, size_t N) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n    extern __shared__ float smin[];\n    unsigned int tid = threadIdx.x;\n    unsigned int i = blockIdx.x * blockDim.x + threadIdx.x;\n\n    if (i < N) {\n        smin[tid] = x[i];\n        for (unsigned int d = 1; d < blockDim.x; d *= 2) {\n            __syncthreads();\n            if (tid >= d) {\n                smin[tid] = fminf(smin[tid], smin[tid - d]);\n            }\n        }\n        __syncthreads();\n        if (i < N) {\n            x[i] = smin[tid];\n        }\n    }\n}\n"
    ]
  },
  {
    "problem_type": "scan",
    "language": "cpp",
    "name": "31_scan_scan_with_min_function",
    "parallelism_model": "serial",
    "prompt": "/* Replace the i-th element of the vector x with the minimum value from indices 0 through i.\n   Examples:\n\n   input: [8, 6, -1, 7, 3, 4, 4]\n   output: [8, 6, -1, -1, -1, -1, -1]\n\n   input: [5, 4, 6, 4, 3, 6, 1, 1]\n   output: [5, 4, 4, 4, 3, 3, 1, 1]\n*/\nvoid partialMinimums(std::vector<float> &x) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\nvoid partialMinimums(std::vector<float> &x) {\n    if (x.empty()) return;\n    float min_val = x[0];\n    for (size_t i = 1; i < x.size(); ++i) {\n        min_val = std::min(min_val, x[i]);\n        x[i] = min_val;\n    }\n}\n"
    ]
  },
  {
    "problem_type": "graph",
    "language": "cpp",
    "name": "17_graph_highest_degree",
    "parallelism_model": "omp",
    "prompt": "#include <omp.h>\n\n/* Compute the highest node degree in the undirected graph. The graph is defined in the adjacency matrix A.\n   A is an NxN adjacency matrix stored in row-major. A is an undirected graph.\n   Use OpenMP to compute in parallel.\n   Example:\n\n\t input: [[0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 0, 1], [1, 1, 1, 0]]\n   output: 3\n*/\nint maxDegree(std::vector<int> const& A, size_t N) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\nint maxDegree(std::vector<int> const& A, size_t N) {\n    int max_deg = 0;\n    #pragma omp parallel\n    {\n        int local_max = 0;\n        #pragma omp for schedule(guided)\n        for (size_t i = 0; i < N; ++i) {\n            int deg = 0;\n            for (size_t j = 0; j < N; ++j) {\n                deg += A[i * N + j];\n            }\n            if (deg > local_max) {\n                local_max = deg;\n            }\n        }\n        #pragma omp critical\n        {\n            if (local_max > max_deg) {\n                max_deg = local_max;\n            }\n        }\n    }\n    return max_deg;\n}\n"
    ]
  },
  {
    "problem_type": "graph",
    "language": "cpp",
    "name": "17_graph_highest_degree",
    "parallelism_model": "cuda",
    "prompt": "/* Compute the highest node degree in the undirected graph. The graph is defined in the adjacency matrix A.\n   A is an NxN adjacency matrix stored in row-major. A is an undirected graph. \n   Store the result in maxDegree.\n   Use CUDA to compute in parallel. The kernel is launched with at least N threads.\n   Example:\n\n\t input: [[0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 0, 1], [1, 1, 1, 0]]\n   output: 3\n*/\n__global__ void maxDegree(const int *A, size_t N, int *maxDegree) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n    extern __shared__ int sharedDegrees[];\n    size_t tid = threadIdx.x;\n    size_t i = blockIdx.x * blockDim.x + tid;\n\n    int degree = 0;\n    if (i < N) {\n        for (size_t j = 0; j < N; ++j) {\n            degree += A[i * N + j];\n        }\n        sharedDegrees[tid] = degree;\n    } else {\n        sharedDegrees[tid] = 0;\n    }\n\n    __syncthreads();\n\n    // Reduce within the block\n    for (size_t s = blockDim.x / 2; s > 0; s >>= 1) {\n        if (tid < s) {\n            sharedDegrees[tid] = max(sharedDegrees[tid], sharedDegrees[tid + s]);\n        }\n        __syncthreads();\n    }\n\n    if (tid == 0) {\n        atomicMax(maxDegree, sharedDegrees[0]);\n    }\n}\n"
    ]
  },
  {
    "problem_type": "graph",
    "language": "cpp",
    "name": "17_graph_highest_degree",
    "parallelism_model": "serial",
    "prompt": "/* Compute the highest node degree in the undirected graph. The graph is defined in the adjacency matrix A.\n   A is an NxN adjacency matrix stored in row-major. A is an undirected graph.\n   Example:\n\n\t input: [[0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 0, 1], [1, 1, 1, 0]]\n   output: 3\n*/\nint maxDegree(std::vector<int> const& A, size_t N) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\nint maxDegree(std::vector<int> const& A, size_t N) {\n    int max_deg = 0;\n    for (size_t i = 0; i < N; ++i) {\n        int deg = 0;\n        for (size_t j = 0; j < N; ++j) {\n            deg += A[i * N + j];\n        }\n        if (deg > max_deg) {\n            max_deg = deg;\n        }\n    }\n    return max_deg;\n}\n"
    ]
  },
  {
    "problem_type": "graph",
    "language": "cpp",
    "name": "16_graph_largest_component",
    "parallelism_model": "omp",
    "prompt": "#include <omp.h>\n\n/* Return the number of vertices in the largest component of the undirected graph defined by the adjacency matrix A.\n   A is an NxN adjacency matrix stored in row-major. A is an undirected graph.\n   Use OpenMP to compute in parallel.\n   Example:\n\n\t input: [[0, 1, 0, 0], [1, 0, 0, 0], [0, 0, 0, 1], [0, 0, 1, 0]]\n   output: 2\n*/\nint largestComponent(std::vector<int> const& A, size_t N) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n    std::vector<bool> visited(N, false);\n    int max_size = 0;\n\n    #pragma omp parallel\n    {\n        std::vector<bool> local_visited(N, false);\n        int local_max = 0;\n\n        #pragma omp for schedule(dynamic)\n        for (size_t i = 0; i < N; ++i) {\n            if (!visited[i]) {\n                std::queue<size_t> q;\n                q.push(i);\n                local_visited[i] = true;\n                int component_size = 0;\n\n                while (!q.empty()) {\n                    size_t v = q.front();\n                    q.pop();\n                    component_size++;\n\n                    for (size_t u = 0; u < N; ++u) {\n                        if (A[v * N + u] && !local_visited[u]) {\n                            local_visited[u] = true;\n                            q.push(u);\n                        }\n                    }\n                }\n\n                if (component_size > local_max) {\n                    local_max = component_size;\n                }\n            }\n        }\n\n        #pragma omp critical\n        {\n            if (local_max > max_size) {\n                max_size = local_max;\n            }\n        }\n    }\n\n    return max_size;\n}\n"
    ]
  },
  {
    "problem_type": "graph",
    "language": "cpp",
    "name": "16_graph_largest_component",
    "parallelism_model": "cuda",
    "prompt": "/* Compute the number of vertices in the largest component of the undirected graph defined by the adjacency matrix A.\n   Store the result in largestComponentSize.\n   A is an NxN adjacency matrix stored in row-major. A is an undirected graph.\n   Use CUDA to compute in parallel. The kernel is launched on an NxN grid of threads.\n   Example:\n\n\t input: [[0, 1, 0, 0], [1, 0, 0, 0], [0, 0, 0, 1], [0, 0, 1, 0]]\n   output: 2\n*/\n__global__ void largestComponent(const int *A, size_t N, int *largestComponentSize) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n  extern __shared__ int visited[];\n  int tid = threadIdx.x + blockIdx.x * blockDim.x;\n  int currentSize = 0;\n  if (tid < N) {\n    bool *localVisited = (bool *)malloc(N * sizeof(bool));\n    for (size_t i = 0; i < N; ++i) localVisited[i] = false;\n    currentSize = dfs(A, N, tid, localVisited);\n    free(localVisited);\n  }\n  __syncthreads();\n  if (currentSize > *largestComponentSize) {\n    atomicMax(largestComponentSize, currentSize);\n  }\n}\n"
    ]
  },
  {
    "problem_type": "graph",
    "language": "cpp",
    "name": "16_graph_largest_component",
    "parallelism_model": "serial",
    "prompt": "/* Return the number of vertices in the largest component of the undirected graph defined by the adjacency matrix A.\n   A is an NxN adjacency matrix stored in row-major. A is an undirected graph.\n   Example:\n\n\t input: [[0, 1, 0, 0], [1, 0, 0, 0], [0, 0, 0, 1], [0, 0, 1, 0]]\n   output: 2\n*/\nint largestComponent(std::vector<int> const& A, size_t N) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n    std::vector<bool> visited(N, false);\n    int max_size = 0;\n\n    for (size_t i = 0; i < N; ++i) {\n        if (!visited[i]) {\n            std::vector<size_t> stack;\n            stack.push_back(i);\n            visited[i] = true;\n            int component_size = 0;\n\n            while (!stack.empty()) {\n                size_t node = stack.back();\n                stack.pop_back();\n                component_size++;\n\n                for (size_t neighbor = 0; neighbor < N; ++neighbor) {\n                    if (A[node * N + neighbor] && !visited[neighbor]) {\n                        visited[neighbor] = true;\n                        stack.push_back(neighbor);\n                    }\n                }\n            }\n\n            if (component_size > max_size) {\n                max_size = component_size;\n            }\n        }\n    }\n\n    return max_size;\n}\n"
    ]
  },
  {
    "problem_type": "graph",
    "language": "cpp",
    "name": "19_graph_shortest_path",
    "parallelism_model": "omp",
    "prompt": "#include <omp.h>\n\n/* Return the length of the shortest path from source to dest in the undirected graph defined by the adjacency matrix A.\n   A is an NxN adjacency matrix stored in row-major. A is an undirected graph.\n   Use OpenMP to compute in parallel.\n   Example:\n\n\t input: [[0, 1, 1, 0], [1, 0, 0, 1], [1, 0, 0, 1], [0, 1, 1, 0]], source=0, dest=3\n   output: 2\n*/\nint shortestPathLength(std::vector<int> const& A, size_t N, int source, int dest) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n    if (source == dest) return 0;\n    std::vector<int> distance(N, -1);\n    distance[source] = 0;\n    #pragma omp parallel\n    {\n        std::queue<int> q;\n        #pragma omp single\n        q.push(source);\n        while (!q.empty()) {\n            int u = q.front();\n            q.pop();\n            #pragma omp for schedule(guided)\n            for (size_t v = 0; v < N; ++v) {\n                if (A[u * N + v] && distance[v] == -1) {\n                    distance[v] = distance[u] + 1;\n                    #pragma omp critical\n                    q.push(v);\n                    if (v == dest) {\n                        #pragma omp cancel for\n                    }\n                }\n            }\n        }\n    }\n    return distance[dest];\n}\n"
    ]
  },
  {
    "problem_type": "graph",
    "language": "cpp",
    "name": "19_graph_shortest_path",
    "parallelism_model": "cuda",
    "prompt": "/* Compute the length of the shortest path from source to dest in the undirected graph defined by the adjacency matrix A.\n   A is an NxN adjacency matrix stored in row-major. A is an undirected graph.\n   Store the result in pathLength.\n   Use CUDA to compute in parallel. The kernel is launched on an NxN grid of threads.\n   Example:\n\n\t input: [[0, 1, 1, 0], [1, 0, 0, 1], [1, 0, 0, 1], [0, 1, 1, 0]], source=0, dest=3\n   output: 2\n*/\n__global__ void shortestPathLength(const int *A, size_t N, int source, int dest, int *pathLength) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n    // Shared memory for BFS queues and visited flags\n    extern __shared__ int sharedMem[];\n    int tid = threadIdx.x + blockIdx.x * blockDim.x;\n    int *queue = sharedMem;\n    int *visited = sharedMem + N;\n    int *dist = sharedMem + 2 * N;\n\n    // Initialize queues and visited on first thread block\n    if (blockIdx.x == 0 && threadIdx.x == 0) {\n        for (size_t i = 0; i < N; ++i) {\n            queue[i] = -1;\n            visited[i] = 0;\n            dist[i] = -1;\n        }\n        queue[0] = source;\n        visited[source] = 1;\n        dist[source] = 0;\n    }\n    __syncthreads();\n\n    int currentQueueSize = 1;\n    int found = 0;\n\n    while (currentQueueSize > 0 && !found) {\n        int current = queue[threadIdx.x];\n        if (current == -1) {\n            __syncthreads();\n            continue;\n        }\n\n        // Explore neighbors\n        for (size_t i = 0; i < N; ++i) {\n            if (A[current * N + i] == 1 && !visited[i]) {\n                visited[i] = 1;\n                dist[i] = dist[current] + 1;\n                queue[currentQueueSize++] = i;\n                if (i == dest) {\n                    found = 1;\n                    break;\n                }\n            }\n        }\n\n        queue[threadIdx.x] = -1;\n        __syncthreads();\n    }\n\n    if (blockIdx.x == 0 && threadIdx.x == 0) {\n        *pathLength = dist[dest];\n    }\n}\n"
    ]
  },
  {
    "problem_type": "graph",
    "language": "cpp",
    "name": "19_graph_shortest_path",
    "parallelism_model": "serial",
    "prompt": "/* Return the length of the shortest path from source to dest in the undirected graph defined by the adjacency matrix A.\n   A is an NxN adjacency matrix stored in row-major. A is an undirected graph.\n   Example:\n\n\t input: [[0, 1, 1, 0], [1, 0, 0, 1], [1, 0, 0, 1], [0, 1, 1, 0]], source=0, dest=3\n   output: 2\n*/\nint shortestPathLength(std::vector<int> const& A, size_t N, int source, int dest) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n    if (source == dest) return 0;\n    std::vector<bool> visited(N, false);\n    std::queue<int> q;\n    q.push(source);\n    visited[source] = true;\n    int level = 0;\n    while (!q.empty()) {\n        int size = q.size();\n        for (int i = 0; i < size; ++i) {\n            int curr = q.front();\n            q.pop();\n            for (size_t j = 0; j < N; ++j) {\n                if (A[curr * N + j] && !visited[j]) {\n                    if (j == dest) return level + 1;\n                    visited[j] = true;\n                    q.push(j);\n                }\n            }\n        }\n        ++level;\n    }\n    return -1;\n}\n"
    ]
  },
  {
    "problem_type": "graph",
    "language": "cpp",
    "name": "15_graph_edge_count",
    "parallelism_model": "omp",
    "prompt": "#include <omp.h>\n\n/* Count the number of edges in the directed graph defined by the adjacency matrix A.\n   A is an NxN adjacency matrix stored in row-major. A represents a directed graph.\n   Use OpenMP to compute in parallel.\n   Example:\n\n\t input: [[0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 0, 1], [1, 1, 1, 0]]\n   output: 6\n*/\nint edgeCount(std::vector<int> const& A, size_t N) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\nint count = 0;\n#pragma omp parallel for reduction(+:count) schedule(guided)\nfor (size_t i = 0; i < N; ++i) {\n    for (size_t j = 0; j < N; ++j) {\n        count += A[i * N + j];\n    }\n}\nreturn count;\n}\n"
    ]
  },
  {
    "problem_type": "graph",
    "language": "cpp",
    "name": "15_graph_edge_count",
    "parallelism_model": "cuda",
    "prompt": "/* Count the number of edges in the directed graph defined by the adjacency matrix A.\n   Store the result in numEdges. A represents a directed graph.\n   A is an NxN adjacency matrix stored in row-major.\n   Use CUDA to compute in parallel. The kernel is launched with at least N threads.\n   Example:\n\n\t input: [[0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 0, 1], [1, 1, 1, 0]]\n   output: 6\n*/\n__global__ void edgeCount(const int *A, size_t N, int *numEdges) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n    __shared__ int sharedCount;\n    if (threadIdx.x == 0) {\n        sharedCount = 0;\n    }\n    __syncthreads();\n\n    size_t row = blockIdx.x * blockDim.x + threadIdx.x;\n    if (row < N) {\n        for (size_t col = 0; col < N; ++col) {\n            if (A[row * N + col] != 0) {\n                atomicAdd(&sharedCount, 1);\n            }\n        }\n    }\n\n    __syncthreads();\n\n    if (threadIdx.x == 0) {\n        atomicAdd(numEdges, sharedCount);\n    }\n}\n"
    ]
  },
  {
    "problem_type": "graph",
    "language": "cpp",
    "name": "15_graph_edge_count",
    "parallelism_model": "serial",
    "prompt": "/* Count the number of edges in the directed graph defined by the adjacency matrix A.\n   A is an NxN adjacency matrix stored in row-major. A represents a directed graph.\n   Example:\n\n\t input: [[0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 0, 1], [1, 1, 1, 0]]\n   output: 6\n*/\nint edgeCount(std::vector<int> const& A, size_t N) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\nint count = 0;\n    for (size_t i = 0; i < N; ++i) {\n        for (size_t j = 0; j < N; ++j) {\n            count += A[i * N + j];\n        }\n    }\n    return count;\n"
    ]
  },
  {
    "problem_type": "graph",
    "language": "cpp",
    "name": "18_graph_count_components",
    "parallelism_model": "omp",
    "prompt": "#include <omp.h>\n\n/* Count the number of connected components in the undirected graph defined by the adjacency matrix A.\n   A is an NxN adjacency matrix stored in row-major. A is an undirected graph.\n\t Use OpenMP to compute in parallel.\n   Example:\n\n\t input: [[0, 1, 0, 0], [1, 0, 0, 0], [0, 0, 0, 1], [0, 0, 1, 0]]\n   output: 2\n*/\nint componentCount(std::vector<int> const& A, size_t N) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n{\n    std::vector<int> visited(N, 0);\n    int count = 0;\n    #pragma omp parallel\n    {\n        std::vector<int> local_visited(N, 0);\n        #pragma omp for schedule(dynamic)\n        for (size_t i = 0; i < N; ++i) {\n            if (!visited[i]) {\n                std::stack<size_t> stack;\n                stack.push(i);\n                local_visited[i] = 1;\n                while (!stack.empty()) {\n                    size_t node = stack.top();\n                    stack.pop();\n                    for (size_t j = 0; j < N; ++j) {\n                        if (A[node * N + j] && !local_visited[j]) {\n                            local_visited[j] = 1;\n                            stack.push(j);\n                        }\n                    }\n                }\n                #pragma omp atomic\n                count++;\n            }\n        }\n        #pragma omp critical\n        {\n            for (size_t i = 0; i < N; ++i) {\n                visited[i] |= local_visited[i];\n            }\n        }\n    }\n    return count;\n}\n"
    ]
  },
  {
    "problem_type": "graph",
    "language": "cpp",
    "name": "18_graph_count_components",
    "parallelism_model": "cuda",
    "prompt": "/* Count the number of connected components in the undirected graph defined by the adjacency matrix A.\n   A is an NxN adjacency matrix stored in row-major. A is an undirected graph.\n\t Use CUDA to compute in parallel. The kernel is launched on an NxN grid of threads.\n   Example:\n\n\t input: [[0, 1, 0, 0], [1, 0, 0, 0], [0, 0, 0, 1], [0, 0, 1, 0]]\n   output: 2\n*/\n__global__ void componentCount(const int *A, size_t N, int *numComponents) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n  extern __shared__ int visited[];\n  int row = blockIdx.y * blockDim.y + threadIdx.y;\n  int col = blockIdx.x * blockDim.x + threadIdx.x;\n  if (row < N && col < N) {\n    if (A[row * N + col]) {\n      if (visited[row] == -1) {\n        visited[row] = row;\n      }\n      if (visited[col] == -1) {\n        visited[col] = col;\n      }\n      int rootRow = visited[row];\n      int rootCol = visited[col];\n      while (visited[rootRow] != rootRow) {\n        rootRow = visited[rootRow];\n      }\n      while (visited[rootCol] != rootCol) {\n        rootCol = visited[rootCol];\n      }\n      if (rootRow != rootCol) {\n        if (rootRow < rootCol) {\n          visited[rootCol] = rootRow;\n        } else {\n          visited[rootRow] = rootCol;\n        }\n      }\n    }\n  }\n  __syncthreads();\n  if (threadIdx.x == 0 && threadIdx.y == 0) {\n    int count = 0;\n    for (int i = 0; i < N; ++i) {\n      if (visited[i] == i) {\n        ++count;\n      }\n    }\n    *numComponents = count;\n  }\n}\n"
    ]
  },
  {
    "problem_type": "graph",
    "language": "cpp",
    "name": "18_graph_count_components",
    "parallelism_model": "serial",
    "prompt": "/* Count the number of connected components in the undirected graph defined by the adjacency matrix A.\n   A is an NxN adjacency matrix stored in row-major. A is an undirected graph.\n   Example:\n\n\t input: [[0, 1, 0, 0], [1, 0, 0, 0], [0, 0, 0, 1], [0, 0, 1, 0]]\n   output: 2\n*/\nint componentCount(std::vector<int> const& A, size_t N) {",
    "temperature": 0.2,
    "top_p": 0.9,
    "do_sample": true,
    "max_new_tokens": 1024,
    "outputs": [
      "\n{\n    std::vector<bool> visited(N, false);\n    int components = 0;\n\n    for (size_t i = 0; i < N; ++i) {\n        if (!visited[i]) {\n            ++components;\n            std::queue<size_t> q;\n            q.push(i);\n            visited[i] = true;\n            while (!q.empty()) {\n                size_t v = q.front();\n                q.pop();\n                for (size_t u = 0; u < N; ++u) {\n                    if (A[v * N + u] && !visited[u]) {\n                        visited[u] = true;\n                        q.push(u);\n                    }\n                }\n            }\n        }\n    }\n\n    return components;\n}\n"
    ]
  }
]