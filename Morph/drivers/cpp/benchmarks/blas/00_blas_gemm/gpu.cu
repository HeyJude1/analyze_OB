// CUDA driver for 00_blas_gemm
// Matrix-Matrix Multiplication: C = alpha * A * B + beta * C

#include <algorithm>
#include <cmath>
#include <numeric>
#include <random>
#include <vector>
#include <cuda_runtime.h>

#include "utilities.hpp"
#include "baseline.hpp"
#include "generated-code.hpp"   // CUDA code generated by LLM

struct Context {
    // Host data
    std::vector<double> A_host;
    std::vector<double> B_host;
    std::vector<double> C_host;
    std::vector<double> C_ref;
    
    // Device data
    double *A_dev;
    double *B_dev;
    double *C_dev;
    
    BLASLONG M, N, K;
    BLASLONG lda, ldb, ldc;
    double alpha, beta;
};

void reset(Context *ctx) {
    // Fill host matrices with random values
    fillRand(ctx->A_host, -1.0, 1.0);
    fillRand(ctx->B_host, -1.0, 1.0);
    fillRand(ctx->C_host, -1.0, 1.0);
    
    // Copy to device
    cudaMemcpy(ctx->A_dev, ctx->A_host.data(), 
               ctx->M * ctx->K * sizeof(double), cudaMemcpyHostToDevice);
    cudaMemcpy(ctx->B_dev, ctx->B_host.data(), 
               ctx->K * ctx->N * sizeof(double), cudaMemcpyHostToDevice);
    cudaMemcpy(ctx->C_dev, ctx->C_host.data(), 
               ctx->M * ctx->N * sizeof(double), cudaMemcpyHostToDevice);
    
    // Copy C for reference computation
    ctx->C_ref = ctx->C_host;
}

Context *init() {
    Context *ctx = new Context();
    
    // Problem size
    ctx->M = DRIVER_PROBLEM_SIZE;
    ctx->N = DRIVER_PROBLEM_SIZE;
    ctx->K = DRIVER_PROBLEM_SIZE;
    
    // Leading dimensions
    ctx->lda = ctx->K;
    ctx->ldb = ctx->N;
    ctx->ldc = ctx->N;
    
    // BLAS parameters
    ctx->alpha = 1.0;
    ctx->beta = 0.0;
    
    // Allocate host memory
    ctx->A_host.resize(ctx->M * ctx->K);
    ctx->B_host.resize(ctx->K * ctx->N);
    ctx->C_host.resize(ctx->M * ctx->N);
    ctx->C_ref.resize(ctx->M * ctx->N);
    
    // Allocate device memory
    cudaMalloc(&ctx->A_dev, ctx->M * ctx->K * sizeof(double));
    cudaMalloc(&ctx->B_dev, ctx->K * ctx->N * sizeof(double));
    cudaMalloc(&ctx->C_dev, ctx->M * ctx->N * sizeof(double));
    
    reset(ctx);
    return ctx;
}

void NO_OPTIMIZE compute(Context *ctx) {
    // Call the LLM-generated CUDA kernel
    // Expected signature: gemm_cuda(M, N, K, alpha, A_dev, lda, B_dev, ldb, beta, C_dev, ldc)
    gemm_cuda(ctx->M, ctx->N, ctx->K, ctx->alpha,
              ctx->A_dev, ctx->lda, ctx->B_dev, ctx->ldb,
              ctx->beta, ctx->C_dev, ctx->ldc);
    
    // Copy result back to host
    cudaMemcpy(ctx->C_host.data(), ctx->C_dev, 
               ctx->M * ctx->N * sizeof(double), cudaMemcpyDeviceToHost);
}

void NO_OPTIMIZE best(Context *ctx) {
    // Call the reference implementation on host
    correctGemm(ctx->M, ctx->N, ctx->K, ctx->alpha,
                ctx->A_host, ctx->lda, ctx->B_host, ctx->ldb,
                ctx->beta, ctx->C_ref, ctx->ldc);
}

bool validate(Context *ctx) {
    const double tolerance = 1e-6;
    
    // Compute reference result
    std::vector<double> C_test = ctx->C_host;
    correctGemm(ctx->M, ctx->N, ctx->K, ctx->alpha,
                ctx->A_host, ctx->lda, ctx->B_host, ctx->ldb,
                ctx->beta, C_test, ctx->ldc);
    
    // Compare with GPU result
    bool isValid = blas_utils::compareMatrices(ctx->C_host, C_test,
                                               ctx->M, ctx->N, tolerance);
    
    if (!isValid) {
        double error = blas_utils::relativeError(ctx->C_host, C_test);
        printf("GEMM CUDA validation failed: relative error = %e\n", error);
    }
    
    return isValid;
}

void destroy(Context *ctx) {
    // Free device memory
    cudaFree(ctx->A_dev);
    cudaFree(ctx->B_dev);
    cudaFree(ctx->C_dev);
    
    delete ctx;
}
