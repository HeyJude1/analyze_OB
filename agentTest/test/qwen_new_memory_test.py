from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.output_parsers import StrOutputParser
from langchain_core.chat_history import BaseChatMessageHistory
from langchain_core.runnables.history import RunnableWithMessageHistory
# 1. å¯¼å…¥æ–°çš„ã€æ­£ç¡®çš„æ‘˜è¦å†å²è®°å½•ç±»
from langchain_community.chat_message_histories import ConversationSummaryBufferChatMessageHistory
from dotenv import load_dotenv
import os

load_dotenv(override=True)
Qwen_api_key = os.getenv("DASHSCOPE_API_KEY")

# --- æ¨¡å‹ã€Promptã€è§£æå™¨ã€åŸºç¡€é“¾çš„å®šä¹‰å®Œå…¨ä¸å˜ ---
model = ChatOpenAI(
    model="qwen-plus",
    api_key=Qwen_api_key,
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
    temperature=0.7,
    max_tokens=2048,
    top_p=0.9,
)
prompt = ChatPromptTemplate.from_messages([
    ("system", "ä½ å«å°æ™ºï¼Œæ˜¯ä¸€åä¹äºåŠ©äººçš„åŠ©æ‰‹ã€‚"),
    MessagesPlaceholder(variable_name="history"),
    ("human", "{input}")
])
parser = StrOutputParser()
base_chain = prompt | model | parser

# --- 2. åˆ›å»ºä¼šè¯å†å²å­˜å‚¨åº“ ---
store = {}

def get_session_history(session_id: str) -> BaseChatMessageHistory:
    """æ ¹æ® session_id è·å–å†å²è®°å½•"""
    if session_id not in store:
        # æ ¸å¿ƒä¿®æ”¹ç‚¹ï¼šä½¿ç”¨æ–°çš„ ConversationSummaryBufferChatMessageHistory ç±»
        store[session_id] = ConversationSummaryBufferChatMessageHistory(
            llm=model,             # å®ƒéœ€è¦ä¸€ä¸ª LLM æ¥ç”Ÿæˆæ‘˜è¦
            max_token_limit=400,   # å½“å†å²è®°å½•è¶…è¿‡ 400 token æ—¶ï¼Œå¼€å§‹è¿›è¡Œæ‘˜è¦
            return_messages=True,
        )
    return store[session_id]

# --- 3. RunnableWithMessageHistory çš„åˆ›å»ºå’Œä½¿ç”¨å®Œå…¨ä¸å˜ ---
chain_with_history = RunnableWithMessageHistory(
    base_chain,
    get_session_history,
    input_messages_key="input",
    history_messages_key="history",
)

# --- 4. è°ƒç”¨å¾ªç¯å®Œå…¨ä¸å˜ ---
print("ğŸ”¹ è¾“å…¥ exit ç»“æŸå¯¹è¯")
while True:
    user_query = input("ğŸ‘¤ ä½ ï¼š")
    if user_query.lower() in {"exit", "quit"}:
        break
    
    config = {"configurable": {"session_id": "default_session"}}
    response = chain_with_history.invoke({"input": user_query}, config=config)
    print("ğŸ¤– å°æ™ºï¼š", response)