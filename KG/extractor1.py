#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
OpenBLASçŸ¥è¯†å›¾è°±å®ä½“æŠ½å–å™¨v1
æ”¯æŒæ–­ç‚¹ç»­ä¼ çš„å®ä½“å’Œå…³ç³»æŠ½å–
"""

import os
import json
import uuid
import hashlib
from typing import Dict, List, Any, Optional
from pathlib import Path
from pymilvus import connections, Collection, FieldSchema, CollectionSchema, DataType, utility
from pymilvus import Index, IndexType, MetricType
from langchain_community.embeddings import DashScopeEmbeddings
import argparse
from dotenv import load_dotenv

load_dotenv()


class KnowledgeGraphExtractor:
    """çŸ¥è¯†å›¾è°±å®ä½“æŠ½å–å™¨"""
    
    def __init__(self, config_path: str = "kg_config.json"):
        """åˆå§‹åŒ–æŠ½å–å™¨"""
        self.config = self._load_config(config_path)
        self.milvus_config = self.config.get("milvus", {})
        self.embedding_config = self.config.get("dashscope_embeddings", {})
        self.data_source_config = self.config.get("data_source", {})
        
        # åˆå§‹åŒ–å‘é‡åŒ–æ¨¡å‹ï¼ˆLangChain DashScopeEmbeddingsï¼‰
        self.embedding_model_name = self.embedding_config.get("name", "text-embedding-v3")
        api_key = os.getenv("DASHSCOPE_API_KEY")
        if not api_key:
            print("âŒ é”™è¯¯ï¼šæœªæä¾› DashScope API Keyã€‚è¯·è®¾ç½®ç¯å¢ƒå˜é‡ DASHSCOPE_API_KEY æˆ–åœ¨ kg_config.json ä¸­æ·»åŠ  dashscope_api_key å­—æ®µã€‚")
            raise RuntimeError("DashScope API key missing")
        try:
            self.embedding_model = DashScopeEmbeddings(model=self.embedding_model_name, dashscope_api_key=api_key)
        except Exception as e:
            print(f"âŒ æ— æ³•åˆå§‹åŒ– DashScopeEmbeddings: {e}")
            raise
        
        # è¿æ¥Milvus
        self._connect_milvus()
        
        # åˆ›å»ºé›†åˆ
        self._create_collections()
        
        # æ–­ç‚¹ç»­ä¼ çŠ¶æ€
        self.checkpoint_file = "extraction_checkpoint.json"
        self.processed_files = self._load_checkpoint()
        
        print("âœ… çŸ¥è¯†å›¾è°±æŠ½å–å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def _load_config(self, config_path: str) -> Dict[str, Any]:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        if not os.path.exists(config_path):
            return {
                "milvus": {"host": "localhost", "port": 19530, "database": "code_op"},
                "dashscope_embeddings": {"name": "text-embedding-v3", "dimension": 1024}
            }
        
        with open(config_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    def _connect_milvus(self):
        """è¿æ¥Milvusæ•°æ®åº“"""
        host = self.milvus_config.get("host", "localhost")
        port = self.milvus_config.get("port", 19530)
        database = self.milvus_config.get("database", "code_op")
        
        connections.connect(
            alias="default",
            host=host,
            port=port,
            db_name=database
        )
        
        print(f"âœ… å·²è¿æ¥åˆ°Milvus: {host}:{port}/{database}")
    
    def _create_collections(self):
        """åˆ›å»ºMilvusé›†åˆ"""
        dimension = self.embedding_config.get("dimension", 1024)
        
        # å®šä¹‰é›†åˆschema
        collections_schema = {
            "optimization_strategy": [
                FieldSchema(name="uid", dtype=DataType.VARCHAR, max_length=100, is_primary=True),
                FieldSchema(name="name", dtype=DataType.VARCHAR, max_length=500),
                FieldSchema(name="level", dtype=DataType.VARCHAR, max_length=50),
                FieldSchema(name="rationale", dtype=DataType.VARCHAR, max_length=5000),
                FieldSchema(name="implementation", dtype=DataType.VARCHAR, max_length=5000),
                FieldSchema(name="impact", dtype=DataType.VARCHAR, max_length=2000),
                FieldSchema(name="trade_offs", dtype=DataType.VARCHAR, max_length=2000),
                FieldSchema(name="entity_data", dtype=DataType.VARCHAR, max_length=65535),
                FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=dimension)
            ],
            "computational_pattern": [
                FieldSchema(name="uid", dtype=DataType.VARCHAR, max_length=100, is_primary=True),
                FieldSchema(name="name", dtype=DataType.VARCHAR, max_length=100),
                FieldSchema(name="type", dtype=DataType.VARCHAR, max_length=100),
                FieldSchema(name="description", dtype=DataType.VARCHAR, max_length=5000),
                FieldSchema(name="code", dtype=DataType.VARCHAR, max_length=10000),
                FieldSchema(name="numeric_kind", dtype=DataType.VARCHAR, max_length=100),
                FieldSchema(name="numeric_precision", dtype=DataType.VARCHAR, max_length=100),
                FieldSchema(name="structural_properties", dtype=DataType.VARCHAR, max_length=500),
                FieldSchema(name="storage_layout", dtype=DataType.VARCHAR, max_length=500),
                FieldSchema(name="entity_data", dtype=DataType.VARCHAR, max_length=65535),
                FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=dimension)
            ],
            "hardware_feature": [
                FieldSchema(name="uid", dtype=DataType.VARCHAR, max_length=100, is_primary=True),
                FieldSchema(name="name", dtype=DataType.VARCHAR, max_length=500),
                FieldSchema(name="architecture", dtype=DataType.VARCHAR, max_length=100),
                FieldSchema(name="description", dtype=DataType.VARCHAR, max_length=2000),
                FieldSchema(name="entity_data", dtype=DataType.VARCHAR, max_length=65535),
                FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=dimension)
            ],
            "tunable_parameter": [
                FieldSchema(name="uid", dtype=DataType.VARCHAR, max_length=100, is_primary=True),
                FieldSchema(name="name", dtype=DataType.VARCHAR, max_length=500),
                FieldSchema(name="description", dtype=DataType.VARCHAR, max_length=2000),
                FieldSchema(name="impact", dtype=DataType.VARCHAR, max_length=2000),
                FieldSchema(name="value_in_code", dtype=DataType.VARCHAR, max_length=500),
                FieldSchema(name="typical_range", dtype=DataType.VARCHAR, max_length=500),
                FieldSchema(name="entity_data", dtype=DataType.VARCHAR, max_length=65535),
                FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=dimension)
            ],
            "code_example": [
                FieldSchema(name="uid", dtype=DataType.VARCHAR, max_length=100, is_primary=True),
                FieldSchema(name="name", dtype=DataType.VARCHAR, max_length=100),
                FieldSchema(name="snippet", dtype=DataType.VARCHAR, max_length=10000),
                FieldSchema(name="explanation", dtype=DataType.VARCHAR, max_length=5000),
                FieldSchema(name="source_file", dtype=DataType.VARCHAR, max_length=500),
                FieldSchema(name="entity_data", dtype=DataType.VARCHAR, max_length=65535),
                FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=dimension)
            ],
            "relation": [
            FieldSchema(name="relation_id", dtype=DataType.VARCHAR, max_length=100, is_primary=True),
            FieldSchema(name="relation_type", dtype=DataType.VARCHAR, max_length=100),
            FieldSchema(name="head_entity_uid", dtype=DataType.VARCHAR, max_length=100),
            FieldSchema(name="tail_entity_uid", dtype=DataType.VARCHAR, max_length=100),
            FieldSchema(name="head_name", dtype=DataType.VARCHAR, max_length=500),
            FieldSchema(name="tail_name", dtype=DataType.VARCHAR, max_length=500),
            FieldSchema(name="description", dtype=DataType.VARCHAR, max_length=2000),
                FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=dimension)
            ]
        }
        
        # åˆ›å»ºé›†åˆ
        for collection_name, fields in collections_schema.items():
            if not utility.has_collection(collection_name):
                schema = CollectionSchema(fields, f"{collection_name} collection")
                collection = Collection(collection_name, schema)
                print(f"âœ… åˆ›å»ºé›†åˆ: {collection_name}")
            else:
                print(f"âœ… é›†åˆå·²å­˜åœ¨: {collection_name}")
        
        # ä¸ºæ‰€æœ‰é›†åˆåˆ›å»ºç´¢å¼•å¹¶åŠ è½½
        self._create_indexes_and_load()
    
    def _create_indexes_and_load(self):
        """ä¸ºæ‰€æœ‰é›†åˆçš„å‘é‡åˆ—åˆ›å»ºç´¢å¼•å¹¶åŠ è½½é›†åˆåˆ°å†…å­˜"""
        collection_names = ["optimization_strategy", "computational_pattern", "hardware_feature", 
                           "tunable_parameter", "code_example", "relation"]
        
        for collection_name in collection_names:
            if not utility.has_collection(collection_name):
                continue
            
            try:
                collection = Collection(collection_name)
                
                # æ£€æŸ¥æ˜¯å¦å·²æœ‰ç´¢å¼•
                indexes = collection.indexes
                has_embedding_index = False
                for index in indexes:
                    if index.field_name == "embedding":
                        has_embedding_index = True
                        break
                
                # å¦‚æœæ²¡æœ‰ç´¢å¼•ï¼Œåˆ›å»ºç´¢å¼•
                if not has_embedding_index:
                    # å…ˆflushç¡®ä¿æ•°æ®å·²å†™å…¥
                    collection.flush()
                    
                    # æ ¹æ®é›†åˆå¤§å°é€‰æ‹©ç´¢å¼•ç±»å‹
                    num_entities = collection.num_entities
                    if num_entities > 0:
                        if num_entities < 1000:
                            # å°æ•°æ®é›†ä½¿ç”¨FLATç´¢å¼•
                            index_params = {
                                "index_type": IndexType.FLAT,
                                "metric_type": MetricType.L2
                            }
                        else:
                            # å¤§æ•°æ®é›†ä½¿ç”¨IVF_FLATç´¢å¼•
                            index_params = {
                                "index_type": IndexType.IVF_FLAT,
                                "metric_type": MetricType.L2,
                                "params": {"nlist": min(1024, num_entities // 10)}
                            }
                        
                        collection.create_index("embedding", index_params)
                        print(f"âœ… ä¸º {collection_name} åˆ›å»ºå‘é‡ç´¢å¼• (å®ä½“æ•°: {num_entities})")
                
                # åŠ è½½é›†åˆåˆ°å†…å­˜ï¼ˆåªæœ‰åœ¨æœ‰æ•°æ®æ—¶æ‰åŠ è½½ï¼‰
                if num_entities > 0:
                    try:
                        collection.load()
                        print(f"âœ… åŠ è½½é›†åˆåˆ°å†…å­˜: {collection_name}")
                    except Exception as e:
                        # å¦‚æœåŠ è½½å¤±è´¥ï¼Œå¯èƒ½æ˜¯å› ä¸ºæ²¡æœ‰ç´¢å¼•ï¼Œå°è¯•åˆ›å»ºé»˜è®¤ç´¢å¼•åå†åŠ è½½
                        if "index" in str(e).lower() or "Index" in str(e):
                            try:
                                index_params = {
                                    "index_type": IndexType.FLAT,
                                    "metric_type": MetricType.L2
                                }
                                collection.create_index("embedding", index_params)
                                collection.load()
                                print(f"âœ… ä¸º {collection_name} åˆ›å»ºé»˜è®¤ç´¢å¼•å¹¶åŠ è½½")
                            except Exception as e2:
                                print(f"âš ï¸ ä¸º {collection_name} åˆ›å»ºç´¢å¼•å¹¶åŠ è½½å¤±è´¥: {e2}")
                        else:
                            print(f"âš ï¸ åŠ è½½é›†åˆ {collection_name} å¤±è´¥: {e}")
                else:
                    print(f"â„¹ï¸ é›†åˆ {collection_name} æš‚æ— æ•°æ®ï¼Œè·³è¿‡åŠ è½½")
            except Exception as e:
                print(f"âš ï¸ å¤„ç†é›†åˆ {collection_name} å¤±è´¥: {e}")
    
    def _ensure_collection_loaded(self, collection_name: str):
        """ç¡®ä¿é›†åˆå·²åŠ è½½åˆ°å†…å­˜ï¼ˆåœ¨æ•°æ®æ’å…¥åè°ƒç”¨ï¼‰"""
        try:
            if not utility.has_collection(collection_name):
                return
            
            collection = Collection(collection_name)
            
            # æ£€æŸ¥é›†åˆæ˜¯å¦å·²åŠ è½½
            if collection.has_index():
                # å¦‚æœé›†åˆæœ‰ç´¢å¼•ï¼Œå°è¯•åŠ è½½
                try:
                    collection.load()
                except:
                    pass  # å¦‚æœå·²ç»åŠ è½½ï¼Œä¼šæŠ›å‡ºå¼‚å¸¸ï¼Œå¿½ç•¥å³å¯
        except:
            pass  # å¿½ç•¥é”™è¯¯ï¼Œé¿å…å½±å“ä¸»æµç¨‹
    
    def _load_checkpoint(self) -> set:
        """åŠ è½½æ–­ç‚¹ç»­ä¼ çŠ¶æ€"""
        if os.path.exists(self.checkpoint_file):
            with open(self.checkpoint_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                processed = set(data.get("processed_files", []))
                print(f"âœ… æ–­ç‚¹ç»­ä¼ : å·²å¤„ç† {len(processed)} ä¸ªæ–‡ä»¶")
                return processed
        return set()
    
    def _save_checkpoint(self):
        """ä¿å­˜æ–­ç‚¹ç»­ä¼ çŠ¶æ€"""
        with open(self.checkpoint_file, 'w', encoding='utf-8') as f:
            json.dump({"processed_files": list(self.processed_files)}, f, ensure_ascii=False, indent=2)
        print("ğŸ’¾ æ–­ç‚¹å·²ä¿å­˜")
    
    def _generate_uid(self, content: str) -> str:
        """ç”Ÿæˆå”¯ä¸€ID"""
        return hashlib.md5(content.encode('utf-8')).hexdigest()[:8]
    
    def _get_embedding(self, text: str) -> List[float]:
        """è·å–æ–‡æœ¬å‘é‡"""
        try:
            if self.embedding_model is None:
                raise RuntimeError("Embedding model not initialized")
            # LangChain DashScopeEmbeddings provides embed_query / embed_documents
            try:
                emb = self.embedding_model.embed_query(text)
            except TypeError:
                # some versions may expose embed rather than embed_query
                emb = self.embedding_model.embed(text)
            # emb expected to be a list[float]
            if isinstance(emb, (list, tuple)):
                return list(emb)
            # fallback if the returned structure is nested
            if isinstance(emb, dict) and "data" in emb:
                # try to extract vector
                first = emb["data"][0]
                if isinstance(first, dict) and "embedding" in first:
                    return first["embedding"]
            # unknown format
            print("âš ï¸ å‘é‡åŒ–è¿”å›æœªçŸ¥æ ¼å¼ï¼Œä½¿ç”¨é›¶å‘é‡ä½œä¸ºå›é€€")
            return [0.0] * self.embedding_config.get("dimension", 1024)
        except Exception as e:
            print(f"âš ï¸ å‘é‡åŒ–å¼‚å¸¸: {e}")
            return [0.0] * self.embedding_config.get("dimension", 1024)
    
    def _process_optimization(self, opt: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†ä¼˜åŒ–ç­–ç•¥å®ä½“"""
        # è·å– related_patternsï¼Œä¼˜å…ˆä»é¡¶å±‚ï¼Œç„¶åä» description ä¸­
        related_patterns = opt.get('related_patterns', [])
        desc = opt.get('description', {})
        if not related_patterns and isinstance(desc, dict):
            related_patterns = desc.get('related_patterns', [])
        
        strategy = {
            "uid": self._generate_uid(opt.get("optimization_name", "")),
            "name": opt.get("optimization_name", ""),
            "level": opt.get("level", ""),
            "rationale": desc.get("strategy_rationale", "") if isinstance(desc, dict) else "",
            "implementation": desc.get("implementation_pattern", "") if isinstance(desc, dict) else "",
            "impact": desc.get("performance_impact", "") if isinstance(desc, dict) else "",
            "trade_offs": desc.get("trade_offs", "") if isinstance(desc, dict) else "",
            "related_patterns": related_patterns,
            "applicability_conditions": opt.get("applicability_conditions", []),
            "tunable_parameters": opt.get("tunable_parameters", []),
            "target_hardware_feature_name": opt.get("target_hardware_feature_name") or opt.get("target_hardware_feature_name".lower(), ""),
            "target_hardware_feature": opt.get("target_hardware_feature", "")
        }
        
        return strategy
    
    def _save_entity(self, collection_name: str, entity_data: Dict[str, Any]) -> str:
        """ä¿å­˜å®ä½“åˆ°Milvus"""
        collection = Collection(collection_name)
        
        # å‡†å¤‡æ•°æ®
        uid = entity_data["uid"]
        # æ ¹æ®é›†åˆé€‰æ‹©æ›´æœ‰ä¿¡æ¯é‡çš„åµŒå…¥æ–‡æœ¬
        if collection_name == "computational_pattern":
            embedding_text = f"{entity_data.get('type','')} {entity_data.get('name','')} {entity_data.get('description','')} {entity_data.get('code','')}"
        elif collection_name == "optimization_strategy":
            embedding_text = f"{entity_data.get('name','')} {entity_data.get('level','')} {entity_data.get('rationale','')} {entity_data.get('implementation','')}"
        elif collection_name == "hardware_feature":
            embedding_text = f"{entity_data.get('name','')} {entity_data.get('architecture','')} {entity_data.get('description','')}"
        elif collection_name == "tunable_parameter":
            embedding_text = f"{entity_data.get('name','')} {entity_data.get('description','')} {entity_data.get('impact','')}"
        elif collection_name == "code_example":
            embedding_text = f"{entity_data.get('name','')} {entity_data.get('snippet','')} {entity_data.get('explanation','')}"
        else:
            embedding_text = entity_data.get("name", "") + " " + str(entity_data)
        embedding = self._get_embedding(embedding_text)
        
        # æ„å»ºæ’å…¥æ•°æ®
        if collection_name == "optimization_strategy":
            insert_data = [
                [uid],
                [entity_data["name"]],
                [entity_data["level"]],
                [entity_data.get("rationale", "")],
                [entity_data.get("implementation", "")],
                [entity_data.get("impact", "")],
                [entity_data.get("trade_offs", "")],
                [json.dumps(entity_data, ensure_ascii=False)],
                [embedding]
            ]
        elif collection_name == "computational_pattern":
            insert_data = [
                [uid],
                [entity_data.get("name", "")],
                [entity_data.get("type", "")],
                [entity_data.get("description", "")],
                [entity_data.get("code", "")],
                [entity_data.get("numeric_kind", "")],
                [entity_data.get("numeric_precision", "")],
                [entity_data.get("structural_properties", "")],
                [entity_data.get("storage_layout", "")],
                [json.dumps(entity_data, ensure_ascii=False)],
                [embedding]
            ]
        elif collection_name == "hardware_feature":
            insert_data = [
                [uid],
                [entity_data.get("name", "")],
                [entity_data.get("architecture", "")],
                [entity_data.get("description", "")],
                [json.dumps(entity_data, ensure_ascii=False)],
                [embedding]
            ]
        elif collection_name == "tunable_parameter":
            insert_data = [
                [uid],
                [entity_data.get("name", "")],
                [entity_data.get("description", "")],
                [entity_data.get("impact", "")],
                [entity_data.get("value_in_code", "")],
                [entity_data.get("typical_range", "")],
                [json.dumps(entity_data, ensure_ascii=False)],
                [embedding]
            ]
        elif collection_name == "code_example":
            insert_data = [
                [uid],
                [entity_data.get("name", "")],
                [entity_data.get("snippet", "")],
                [entity_data.get("explanation", "")],
                [entity_data.get("source_file", "")],
                [json.dumps(entity_data, ensure_ascii=False)],
                [embedding]
            ]
        else:
            # å…œåº•
            insert_data = [
                [uid],
                [entity_data.get("name", "")],
                [json.dumps(entity_data, ensure_ascii=False)],
                [embedding]
            ]
        
        # æ’å…¥æ•°æ®
        collection.insert(insert_data)
        collection.flush()
        
        return uid
    
    def _save_relation(self, head_uid: str, tail_uid: str, relation_type: str,
                       head_name: str = "", tail_name: str = "", description: str = ""):
        """ä¿å­˜å…³ç³»åˆ°Milvus"""
        collection = Collection("relation")
        
        # æ¸…ç†å­—ç¬¦ä¸²ä¸­çš„NULå­—ç¬¦ï¼Œé¿å…è¾“å‡ºé—®é¢˜
        def clean_str(s: str) -> str:
            if not s:
                return ""
            return s.replace('\x00', '').strip()
        
        head_name = clean_str(head_name)
        tail_name = clean_str(tail_name)
        description = clean_str(description)
        
        relation_uid = self._generate_uid(f"{head_uid}_{tail_uid}_{relation_type}")
        if not description:
            if relation_type == "OPTIMIZES_PATTERN":
                description = f"{tail_name or tail_uid} ä¼˜åŒ–äº†è®¡ç®—æµç¨‹ {head_name or head_uid}"
            elif relation_type == "IS_ILLUSTRATED_BY":
                description = f"{head_name or head_uid} ç”±ä»£ç ç¤ºä¾‹ {tail_name or tail_uid} è¯´æ˜"
            elif relation_type == "TARGETS":
                description = f"{head_name or head_uid} é¢å‘ç¡¬ä»¶ç‰¹æ€§ {tail_name or tail_uid}"
            elif relation_type == "HAS_PARAMETER":
                description = f"{head_name or head_uid} å…·æœ‰å¯è°ƒå‚æ•° {tail_name or tail_uid}"
            else:
                description = relation_type
        embedding_text = f"{relation_type} {head_name} {tail_name} {description}"
        embedding = self._get_embedding(embedding_text)
        
        insert_data = [
            [relation_uid],
            [relation_type],
            [head_uid],
            [tail_uid],
            [head_name],
            [tail_name],
            [description],
            [embedding]
        ]
        
        collection.insert(insert_data)
        collection.flush()
        
        print(f"âœ“ ä¿å­˜å…³ç³»: {relation_type} ({head_name or head_uid} -> {tail_name or tail_uid})")
    
    def extract_from_file(self, file_path: str):
        """ä»å•ä¸ªæ–‡ä»¶ä¸­æŠ½å–å®ä½“å’Œå…³ç³»"""
        if file_path in self.processed_files:
            print(f"â­ï¸ è·³è¿‡å·²å¤„ç†æ–‡ä»¶: {file_path}")
            return
        
        print(f"ğŸ“„ å¤„ç†: {os.path.basename(file_path)}")
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # å¤„ç†æ¯ä¸ªç®—å­åˆ†æ
            for analysis in data.get("individual_analyses", []):
                operator_name = analysis.get("file_path", "").split("/")[-1]
                print(f"  ğŸ” ç®—å­: {operator_name}")
                
                entity_count = 0
                relation_count = 0
                code_counter = 1
                # å»ºç«‹å½“å‰åˆ†æä¸­å·²ä¿å­˜çš„è®¡ç®—æµç¨‹ç±»å‹åˆ°UIDçš„æ˜ å°„ï¼Œç¡®ä¿å…³ç³»æŒ‡å‘å·²å­˜åœ¨çš„å¤´å®ä½“
                pattern_uid_by_type = {}
                
                # å¤„ç†è®¡ç®—æµç¨‹
                for pattern in analysis.get("computational_patterns", []):
                    # è¾“å…¥ç»“æ„å‚è€ƒ agent23 äº§ç‰©
                    ptype = pattern.get("pattern_type", "") or pattern.get("type", "")
                    dof = pattern.get("data_object_features") or {}
                    pattern_entity = {
                        "uid": self._generate_uid(ptype or pattern.get("name", "")),
                        "name": pattern.get("name", ""),
                        "type": ptype,
                        "description": pattern.get("description", ""),
                        "code": pattern.get("code", ""),
                        "numeric_kind": dof.get("numeric_kind", ""),
                        "numeric_precision": dof.get("numeric_precision", ""),
                        "structural_properties": dof.get("structural_properties", ""),
                        "storage_layout": dof.get("storage_layout", "")
                    }
                    saved_uid = self._save_entity("computational_pattern", pattern_entity)
                    if pattern_entity.get("type"):
                        pattern_uid_by_type[pattern_entity["type"]] = saved_uid
                    entity_count += 1
                    print(f"    âœ“ ä¿å­˜computational_pattern: {pattern_entity.get('type', '')} -> {pattern_entity['uid']}")
                
                # å¤„ç†ä¼˜åŒ–ç­–ç•¥
                for level in ["algorithm_level_optimizations", "code_level_optimizations", "instruction_level_optimizations"]:
                    for opt in analysis.get(level, []):
                        strategy = self._process_optimization(opt)
                        strategy_uid = self._save_entity("optimization_strategy", strategy)
                        entity_count += 1
                        print(f"    âœ“ ä¿å­˜optimization_strategy: {strategy['name']} -> {strategy_uid}")
                        
                        # åˆ›å»ºOPTIMIZES_PATTERNå…³ç³»
                        for pattern_type in strategy.get("related_patterns", []):
                            # ä¼˜å…ˆä½¿ç”¨å½“å‰æ–‡ä»¶å·²ä¿å­˜çš„è®¡ç®—æµç¨‹UIDï¼Œé¿å…ä¸ä¸€è‡´
                            pattern_uid = pattern_uid_by_type.get(pattern_type, self._generate_uid(pattern_type))
                            self._save_relation(
                                pattern_uid, strategy_uid, "OPTIMIZES_PATTERN",
                                head_name=pattern_type, tail_name=strategy.get("name", "")
                            )
                            relation_count += 1
                        
                        # å¤„ç†ç¡¬ä»¶ç‰¹å¾
                        hardware_names: List[str] = []
                        if isinstance(opt.get("hardware_features"), list):
                            hardware_names = [str(x) for x in opt.get("hardware_features") if x]
                        else:
                            if strategy.get("target_hardware_feature_name"):
                                hardware_names = [strategy.get("target_hardware_feature_name")]
                        for hw_name in hardware_names:
                            if not hw_name:
                                continue
                            hw_entity = {
                                "uid": self._generate_uid(hw_name),
                                "name": hw_name,
                                "architecture": "",
                                "description": opt.get("target_hardware_feature", "") or f"Hardware feature: {hw_name}"
                            }
                            hw_uid = self._save_entity("hardware_feature", hw_entity)
                            self._save_relation(
                                strategy_uid, hw_uid, "TARGETS",
                                head_name=strategy.get("name", ""), tail_name=hw_name
                            )
                            entity_count += 1
                            relation_count += 1
                            print(f"    âœ“ ä¿å­˜hardware_feature: {hw_name} -> {hw_uid}")
                        
                        # å¤„ç†ä»£ç ç¤ºä¾‹
                        code_examples: List[Dict[str, Any]] = []
                        if isinstance(opt.get("code_example"), dict):
                            code_examples = [opt.get("code_example")]
                        elif isinstance(opt.get("code_examples"), list):
                            code_examples = opt.get("code_examples")
                        for i, code_obj in enumerate(code_examples):
                            snippet = code_obj.get("snippet", "") if isinstance(code_obj, dict) else str(code_obj)
                            explanation = code_obj.get("explanation", "") if isinstance(code_obj, dict) else ""
                            code_entity = {
                                "uid": self._generate_uid(f"{strategy['name']}_code_{code_counter}"),
                                "name": f"code{code_counter}",
                                "snippet": snippet,
                                "explanation": explanation,
                                "source_file": operator_name
                            }
                            code_uid = self._save_entity("code_example", code_entity)
                            self._save_relation(
                                strategy_uid, code_uid, "IS_ILLUSTRATED_BY",
                                head_name=strategy.get("name", ""), tail_name=code_entity["name"]
                            )
                            entity_count += 1
                            relation_count += 1
                            print(f"    âœ“ ä¿å­˜code_example: {code_entity['name']} -> {code_uid}")
                            code_counter += 1
                        
                        # å¤„ç†å¯è°ƒå‚æ•°
                        for param in strategy.get("tunable_parameters", []):
                            if not param:
                                continue
                            if isinstance(param, str):
                                param_name = param
                                param_entity = {
                                    "uid": self._generate_uid(param_name),
                                    "name": param_name,
                                    "description": f"Tunable parameter: {param_name}",
                                    "impact": "",
                                    "value_in_code": "",
                                    "typical_range": ""
                                }
                            else:
                                param_name = param.get("parameter_name") or param.get("name") or ""
                                if not param_name:
                                    continue
                                # å¤„ç† typical_rangeï¼šå¦‚æœæ˜¯åˆ—è¡¨ï¼Œå°†æ¯ä¸ªå…ƒç´ è½¬ä¸ºå­—ç¬¦ä¸²åè¿æ¥
                                typical_range = param.get("typical_range", [])
                                if isinstance(typical_range, list):
                                    typical_range_str = ",".join(str(x) for x in typical_range)
                                else:
                                    typical_range_str = str(typical_range) if typical_range else ""
                                
                                param_entity = {
                                    "uid": self._generate_uid(param_name),
                                    "name": param_name,
                                    "description": param.get("description", ""),
                                    "impact": param.get("impact", ""),
                                    "value_in_code": str(param.get("value_in_code", "")),
                                    "typical_range": typical_range_str
                                }
                            param_uid = self._save_entity("tunable_parameter", param_entity)
                            self._save_relation(
                                strategy_uid, param_uid, "HAS_PARAMETER",
                                head_name=strategy.get("name", ""), tail_name=param_entity["name"]
                            )
                            entity_count += 1
                            relation_count += 1
                            print(f"    âœ“ ä¿å­˜tunable_parameter: {param_entity['name']} -> {param_uid}")
                
                print(f"  ğŸ“Š å®Œæˆ: å®ä½“={entity_count}, å…³ç³»={relation_count}")
            
            # æ ‡è®°æ–‡ä»¶å·²å¤„ç†
            self.processed_files.add(file_path)
            self._save_checkpoint()
            
        except Exception as e:
            print(f"âŒ å¤„ç†æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
    
    def extract_from_directory(self, directory_path: str):
        """ä»ç›®å½•ä¸­æŠ½å–æ‰€æœ‰JSONæ–‡ä»¶"""
        json_files = list(Path(directory_path).glob("*.json"))
        print(f"ğŸ“ å‘ç° {len(json_files)} ä¸ªJSONæ–‡ä»¶")
        
        total_entities = 0
        total_relations = 0
        
        for i, file_path in enumerate(json_files, 1):
            print(f"\n{'='*60}")
            print(f"è¿›åº¦: {i}/{len(json_files)}")
            print(f"{'='*60}")
            
            self.extract_from_file(str(file_path))
        
        # ç»Ÿè®¡æ€»æ•°
        for collection_name in ["optimization_strategy", "computational_pattern", "hardware_feature", "tunable_parameter", "code_example"]:
            collection = Collection(collection_name)
            count = collection.num_entities
            total_entities += count
            print(f"  âœ… {collection_name}: {count} ä¸ª")
        
        relation_collection = Collection("relation")
        total_relations = relation_collection.num_entities
        
        print(f"\n{'='*60}")
        print(f"ğŸ“Š æ€»è®¡: å®ä½“={total_entities}, å…³ç³»={total_relations}")
        print(f"{'='*60}")
        
        # ä¸ºæ‰€æœ‰é›†åˆåˆ›å»ºç´¢å¼•å¹¶åŠ è½½åˆ°å†…å­˜
        print("\nğŸ”§ æ­£åœ¨ä¸ºé›†åˆåˆ›å»ºç´¢å¼•å¹¶åŠ è½½åˆ°å†…å­˜...")
        self._create_indexes_and_load()
        
        print("ğŸ‰ å®Œæˆï¼")
        print("âœ… å·²ä¿å­˜æ–­ç‚¹å¹¶å…³é—­Milvusè¿æ¥")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="OpenBLASçŸ¥è¯†å›¾è°±å®ä½“æŠ½å–å™¨")
    parser.add_argument("--config", type=str, default="kg_config.json", help="é…ç½®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--data_dir", type=str, default=None, help="åˆ†æç»“æœJSONæ–‡ä»¶ç›®å½•ï¼ˆå¯é€‰ï¼Œä¼˜å…ˆä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„è·¯å¾„ï¼‰")
    
    args = parser.parse_args()
    
    print("çŸ¥è¯†å›¾è°±æŠ½å–å™¨ï¼ˆå¸¦æ–­ç‚¹ç»­ä¼ ï¼‰")
    print()
    
    extractor = KnowledgeGraphExtractor(args.config)
    
    # ç¡®å®šè¾“å…¥ç›®å½•ï¼šä¼˜å…ˆä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°ï¼Œå¦åˆ™ä½¿ç”¨é…ç½®æ–‡ä»¶
    if args.data_dir:
        data_dir = args.data_dir
    else:
        data_dir = extractor.data_source_config.get("analysis_results_dir")
        if not data_dir:
            print("âŒ é”™è¯¯ï¼šæœªæŒ‡å®šè¾“å…¥ç›®å½•ã€‚è¯·åœ¨é…ç½®æ–‡ä»¶ä¸­è®¾ç½® data_source.analysis_results_dir æˆ–ä½¿ç”¨ --data_dir å‚æ•°")
            return
    
    # æ ¹æ® extractor1.py çš„ä½ç½®å’Œé…ç½®è·¯å¾„æ„é€ è¾“å…¥ç›®å½•
    # extractor1.py åœ¨ /home/dgc/mjs/project/analyze_OB/KG/extractor1.py
    # é¡¹ç›®æ ¹ç›®å½•æ˜¯ /home/dgc/mjs/project/analyze_OB/
    script_dir = os.path.dirname(os.path.abspath(__file__))
    project_root = os.path.dirname(script_dir)  # /home/dgc/mjs/project/analyze_OB/
    
    cfg_path = data_dir
    if os.path.isabs(cfg_path):
        # å·²ç»æ˜¯ç»å¯¹è·¯å¾„ï¼Œç›´æ¥ä½¿ç”¨
        data_dir = cfg_path
    else:
        # ç›¸å¯¹è·¯å¾„ï¼šå¦‚æœåŒ…å« analyze_OBï¼Œå–å…¶åç¼€æ‹¼æ¥åˆ°é¡¹ç›®æ ¹
        if "analyze_OB" in cfg_path:
            idx = cfg_path.find("analyze_OB")
            suffix = cfg_path[idx + len("analyze_OB"):].lstrip("/\\")
            data_dir = os.path.join(project_root, suffix)
        else:
            # ä¸åŒ…å« analyze_OBï¼Œç›´æ¥æ‹¼æ¥åˆ°é¡¹ç›®æ ¹
            data_dir = os.path.join(project_root, cfg_path.lstrip("/\\"))
    
    if not os.path.exists(data_dir):
        print(f"âŒ é”™è¯¯ï¼šè¾“å…¥ç›®å½•ä¸å­˜åœ¨: {data_dir}")
        return
    
    print(f"ğŸ“ è¾“å…¥ç›®å½•: {data_dir}")
    extractor.extract_from_directory(data_dir)


if __name__ == "__main__":
    main()
