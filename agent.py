#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
OpenBLASä¼˜åŒ–åˆ†æž - å·¥ä½œæµAgentå·¥åŽ‚
æ ¸å¿ƒæ”¹è¿›ï¼šæ–‡ä»¶è·¯å¾„ç”±ä»£ç æŽ§åˆ¶ï¼ŒAgentåªè´Ÿè´£å†…å®¹ç”Ÿæˆ
"""

import os
import json
import time
from pathlib import Path
from typing import List, Dict, Any, Optional
from dotenv import load_dotenv

from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.tools import tool
from langchain.agents import AgentExecutor, create_openai_tools_agent
from langchain.output_parsers import StructuredOutputParser, ResponseSchema
from pydantic import BaseModel, Field

load_dotenv()


# ===== ç»“æž„åŒ–ä»»åŠ¡å®šä¹‰ =====
class AnalysisTask(BaseModel):
    """ç»“æž„åŒ–çš„åˆ†æžä»»åŠ¡ - æ˜Žç¡®çš„è¾“å…¥è¾“å‡º"""
    algorithm: str = Field(description="ç®—å­åç§°")
    input_files: List[Dict[str, str]] = Field(description="è¾“å…¥æ–‡ä»¶åˆ—è¡¨ï¼Œæ¯ä¸ªåŒ…å«pathå’Œtype")
    output_file: str = Field(description="è¾“å‡ºæ–‡ä»¶çš„å®Œæ•´è·¯å¾„")
    report_folder: str = Field(description="æŠ¥å‘Šæ–‡ä»¶å¤¹è·¯å¾„")


# ===== ç®€åŒ–çš„ä¸“ç”¨å·¥å…· - åªåšå†…å®¹å¤„ç† =====
@tool
def read_source_file(file_path: str) -> str:
    """ã€æºç é˜…è¯»å·¥å…·ã€‘è¯»å–OpenBLASæºä»£ç æ–‡ä»¶å†…å®¹
    
    Args:
        file_path: ç›¸å¯¹äºŽopenblas-output/GENERIC/kernelçš„æ–‡ä»¶è·¯å¾„
        
    Returns:
        æ–‡ä»¶å†…å®¹ï¼ˆæˆªå–å‰15000å­—ç¬¦é¿å…è¿‡é•¿ï¼‰
    """
    try:
        full_path = os.path.join("openblas-output/GENERIC/kernel", file_path)
        with open(full_path, 'r', encoding='utf-8', errors='ignore') as f:
            content = f.read(15000)  # é™åˆ¶é•¿åº¦
        return f"æ–‡ä»¶è·¯å¾„: {file_path}\nå†…å®¹:\n{content}\n..."
    except Exception as e:
        return f"è¯»å–å¤±è´¥: {str(e)}"


@tool
def scan_kernel_directory_batch(batch_size: int = 32, batch_index: int = 0) -> str:
    """ã€ç›®å½•æ‰«æå·¥å…·ã€‘åˆ†æ‰¹æ‰«ækernelç›®å½•ä¸‹çš„.cæ–‡ä»¶
    
    Args:
        batch_size: æ¯æ‰¹å¤„ç†çš„æ–‡ä»¶æ•°é‡
        batch_index: æ‰¹æ¬¡ç´¢å¼•ï¼ˆä»Ž0å¼€å§‹ï¼‰
        
    Returns:
        å½“å‰æ‰¹æ¬¡çš„æ–‡ä»¶åˆ—è¡¨å’Œæ€»ä½“ä¿¡æ¯
    """
    try:
        kernel_path = "openblas-output/GENERIC/kernel"
        if not os.path.exists(kernel_path):
            return f"ç›®å½•ä¸å­˜åœ¨: {kernel_path}"
        
        # èŽ·å–æ‰€æœ‰.cæ–‡ä»¶
        all_files = []
        for file in os.listdir(kernel_path):
            if file.endswith('.c') and 'clean' in file:
                all_files.append(file)
        
        all_files.sort()
        total_files = len(all_files)
        
        # è®¡ç®—æ‰¹æ¬¡èŒƒå›´
        start_idx = batch_index * batch_size
        end_idx = min(start_idx + batch_size, total_files)
        
        if start_idx >= total_files:
            return f"æ‰¹æ¬¡ç´¢å¼•è¶…å‡ºèŒƒå›´ã€‚æ€»æ–‡ä»¶æ•°: {total_files}, è¯·æ±‚æ‰¹æ¬¡: {batch_index}"
        
        batch_files = all_files[start_idx:end_idx]
        total_batches = (total_files + batch_size - 1) // batch_size
        
        return f"""æ‰¹æ¬¡ä¿¡æ¯:
- å½“å‰æ‰¹æ¬¡: {batch_index + 1}/{total_batches}
- æ€»æ–‡ä»¶æ•°: {total_files}
- å½“å‰æ‰¹æ¬¡æ–‡ä»¶æ•°: {len(batch_files)}
- æ–‡ä»¶åˆ—è¡¨:
{chr(10).join(batch_files)}"""
    except Exception as e:
        return f"æ‰«æå¤±è´¥: {str(e)}"


@tool
def read_analysis_file(file_path: str) -> str:
    """ã€åˆ†æžç»“æžœé˜…è¯»å·¥å…·ã€‘è¯»å–å·²ä¿å­˜çš„åˆ†æžç»“æžœ
    
    Args:
        file_path: åˆ†æžç»“æžœæ–‡ä»¶çš„å®Œæ•´è·¯å¾„
        
    Returns:
        æ–‡ä»¶å†…å®¹
    """
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return f.read()
    except Exception as e:
        return f"è¯»å–å¤±è´¥: {str(e)}"


# ===== Agentå·¥åŽ‚ =====
class AgentFactory:
    """Agentå·¥åŽ‚"""
    
    def __init__(self):
        with open("config.json", "r", encoding="utf-8") as f:
            config = json.load(f)
            model_config = config["model"]
        
        self.llm = ChatOpenAI(
            model=model_config["name"],
            temperature=model_config["temperature"],
            max_tokens=model_config["max_tokens"],
            api_key=os.getenv("DASHSCOPE_API_KEY"),
            base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
        )
    
    def create_scout_specialist(self) -> AgentExecutor:
        """Scoutä¸“å®¶ - åªè´Ÿè´£ç”Ÿæˆå‘çŽ°æŠ¥å‘Šå†…å®¹"""
        
        tools = [scan_kernel_directory_batch, read_source_file]
        
        # å®šä¹‰Scoutè¾“å‡ºæ ¼å¼çš„ResponseSchema
        scout_schemas = [
            ResponseSchema(name="algorithms", description="ç®—å­ç§ç±»åˆ—è¡¨ï¼Œæ¯ä¸ªç®—å­åŒ…å«algorithmï¼ˆç®—å­ç§ç±»åï¼‰å’Œfilesï¼ˆè¯¥ç§ç±»ä¸‹çš„æ‰€æœ‰å®žä¾‹æ–‡ä»¶ï¼Œæ¯ä¸ªæ–‡ä»¶åŒ…å«nameå­—æ®µï¼‰"),
            ResponseSchema(name="total_algorithms", description="å‘çŽ°çš„ç®—å­ç§ç±»æ€»æ•°"),
            ResponseSchema(name="total_files", description="å‘çŽ°çš„æ–‡ä»¶æ€»æ•°"),
            ResponseSchema(name="timestamp", description="æ‰«ææ—¶é—´æˆ³")
        ]
        scout_parser = StructuredOutputParser.from_response_schemas(scout_schemas)
        
        prompt = ChatPromptTemplate.from_messages([
            ("system", """ä½ æ˜¯OpenBLASç®—å­åˆ†ç±»ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯æ‰«ækernelç›®å½•ä¸‹çš„æ‰€æœ‰.cæ–‡ä»¶ï¼ŒæŒ‰ç®—å­ç§ç±»è¿›è¡Œåˆ†ç»„ã€‚

ðŸŽ¯ **ä½ çš„èŒè´£ï¼š**
1. ä½¿ç”¨scan_kernel_directory_batchå·¥å…·åˆ†æ‰¹æ‰«æ.cæ–‡ä»¶
2. æ ¹æ®æ–‡ä»¶åè¯†åˆ«ç®—å­ç§ç±»ï¼ˆå¦‚axpyã€gemmã€dotç­‰ï¼‰
3. å°†åŒä¸€ç®—å­ç§ç±»çš„æ‰€æœ‰æ–‡ä»¶å½’ç±»åˆ°ä¸€èµ·
4. ç”ŸæˆJSONæ ¼å¼çš„ç®—å­åˆ†ç±»æŠ¥å‘Š

ðŸ“‹ **ç®—å­ç§ç±»è¯†åˆ«è§„åˆ™ï¼š**
- **axpy**: æ‰€æœ‰åŒ…å«"axpy"çš„æ–‡ä»¶ï¼ˆå¦‚saxpy_k.clean.c, daxpy_k.clean.c, caxpy_k.clean.cç­‰ï¼‰
- **gemm**: æ‰€æœ‰åŒ…å«"gemm"çš„æ–‡ä»¶ï¼ˆå¦‚sgemm_*, dgemm_*, cgemm_*, zgemm_*ç­‰ï¼‰
- **dot**: æ‰€æœ‰åŒ…å«"dot"çš„æ–‡ä»¶ï¼ˆå¦‚sdot_*, ddot_*, cdot_*ç­‰ï¼‰
- **asum**: æ‰€æœ‰åŒ…å«"asum"çš„æ–‡ä»¶
- **nrm2**: æ‰€æœ‰åŒ…å«"nrm2"çš„æ–‡ä»¶
- **scal**: æ‰€æœ‰åŒ…å«"scal"çš„æ–‡ä»¶
- **copy**: æ‰€æœ‰åŒ…å«"copy"çš„æ–‡ä»¶
- **swap**: æ‰€æœ‰åŒ…å«"swap"çš„æ–‡ä»¶
- **amax**: æ‰€æœ‰åŒ…å«"amax"çš„æ–‡ä»¶
- **å…¶ä»–**: æ ¹æ®æ–‡ä»¶åä¸­çš„å…³é”®è¯è¯†åˆ«æ›´å¤šç®—å­ç§ç±»

ðŸ” **åˆ†æžè¦æ±‚ï¼š**
- æ‰«ædgc/mjs/project/analyze_OB/openblas-output/GENERIC/kernelç›®å½•
- åªå¤„ç†.clean.cæ–‡ä»¶
- æŒ‰ç®—å­ç§ç±»åˆ†ç»„ï¼Œæ¯ä¸ªç§ç±»åŒ…å«è¯¥ç§ç±»ä¸‹çš„æ‰€æœ‰æ–‡ä»¶å®žä¾‹
- æ¯ä¸ªæ–‡ä»¶è®°å½•nameï¼ˆæ–‡ä»¶åï¼‰

âš ï¸ **é‡è¦ï¼š** 
- ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¾“å‡º
- algorithmså­—æ®µæ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«algorithmå’Œfiles
- filesæ˜¯è¯¥ç®—å­ç§ç±»ä¸‹æ‰€æœ‰æ–‡ä»¶çš„åˆ—è¡¨ï¼Œæ¯ä¸ªæ–‡ä»¶åŒ…å«nameå­—æ®µ

{format_instructions}"""),
            ("human", "{input}"),
            ("placeholder", "{agent_scratchpad}")
        ])
        
        # åœ¨æç¤ºè¯ä¸­æ·»åŠ æ ¼å¼è¯´æ˜Ž
        formatted_prompt = prompt.partial(format_instructions=scout_parser.get_format_instructions())
        
        agent = create_openai_tools_agent(self.llm, tools, formatted_prompt)
        return AgentExecutor(agent=agent, tools=tools, verbose=False, max_iterations=10)
    
    def create_analyzer_specialist(self) -> AgentExecutor:
        """Analyzerä¸“å®¶ - åªè´Ÿè´£ç”Ÿæˆåˆ†æžæŠ¥å‘Šå†…å®¹"""
        
        tools = [read_source_file, read_analysis_file]
        
        # å®šä¹‰Analyzerè¾“å‡ºæ ¼å¼çš„ResponseSchema - å•ä¸ªæ–‡ä»¶åˆ†æžï¼ˆç»“æž„åŒ–ä¼˜åŒ–ç­–ç•¥ï¼‰
        analyzer_schemas = [
            ResponseSchema(name="algorithm", description="ç®—å­åç§°"),
            ResponseSchema(name="file_path", description="å½“å‰åˆ†æžçš„æ–‡ä»¶è·¯å¾„"),
            ResponseSchema(name="file_type", description="æ–‡ä»¶å®žçŽ°ç±»åž‹ï¼ˆgenericã€optimizedã€microkernelç­‰ï¼‰"),
            ResponseSchema(name="architecture", description="ç›®æ ‡æž¶æž„ï¼ˆx86ã€ARMã€é€šç”¨ç­‰ï¼‰"),
            ResponseSchema(name="algorithm_level_optimizations", description="è¯¥æ–‡ä»¶ä¸­ç®—æ³•è®¾è®¡å±‚æ¬¡å‘çŽ°çš„ä¼˜åŒ–ç­–ç•¥åˆ—è¡¨ï¼Œæ¯ä¸ªç­–ç•¥åŒ…å«nameã€description_detailsï¼ˆåŒ…å«strategy_rationaleã€implementation_patternã€performance_impactã€trade_offsï¼‰å’Œcode_contextï¼ˆåŒ…å«snippetã€highlighted_codeã€explanationï¼‰å­—æ®µ"),
            ResponseSchema(name="code_level_optimizations", description="è¯¥æ–‡ä»¶ä¸­ä»£ç ä¼˜åŒ–å±‚æ¬¡å‘çŽ°çš„ä¼˜åŒ–ç­–ç•¥åˆ—è¡¨ï¼Œæ¯ä¸ªç­–ç•¥åŒ…å«nameã€description_detailsï¼ˆåŒ…å«strategy_rationaleã€implementation_patternã€performance_impactã€trade_offsï¼‰å’Œcode_contextï¼ˆåŒ…å«snippetã€highlighted_codeã€explanationï¼‰å­—æ®µ"),
            ResponseSchema(name="instruction_level_optimizations", description="è¯¥æ–‡ä»¶ä¸­ç‰¹æœ‰æŒ‡ä»¤å±‚æ¬¡å‘çŽ°çš„ä¼˜åŒ–ç­–ç•¥åˆ—è¡¨ï¼Œæ¯ä¸ªç­–ç•¥åŒ…å«nameã€description_detailsï¼ˆåŒ…å«strategy_rationaleã€implementation_patternã€performance_impactã€trade_offsï¼‰å’Œcode_contextï¼ˆåŒ…å«snippetã€highlighted_codeã€explanationï¼‰å­—æ®µ"),
            ResponseSchema(name="implementation_details", description="è¯¥æ–‡ä»¶çš„å…³é”®å®žçŽ°ç»†èŠ‚"),
            ResponseSchema(name="performance_insights", description="è¯¥æ–‡ä»¶çš„æ€§èƒ½åˆ†æž"),
            ResponseSchema(name="timestamp", description="åˆ†æžæ—¶é—´æˆ³")
        ]
        analyzer_parser = StructuredOutputParser.from_response_schemas(analyzer_schemas)
        
        prompt = ChatPromptTemplate.from_messages([
            ("system", """ä½ æ˜¯é«˜æ€§èƒ½è®¡ç®—åˆ†æžä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯åˆ†æžä»£ç å¹¶ç”ŸæˆJSONæ ¼å¼çš„ä¼˜åŒ–æŠ€æœ¯æŠ¥å‘Šã€‚

ðŸŽ¯ **ä½ çš„èŒè´£ï¼š**
1. è¯»å–æŒ‡å®šçš„å•ä¸ªæºæ–‡ä»¶ï¼ˆä½¿ç”¨read_source_fileå·¥å…·ï¼‰
2. ä»”ç»†é˜…è¯»è¯¥æ–‡ä»¶çš„ä»£ç ï¼Œå®Œå…¨åŸºäºŽä»£ç å†…å®¹è¿›è¡Œåˆ†æž
3. æŒ‰ä¸‰å±‚ä¼˜åŒ–ç­–ç•¥æ¡†æž¶ç”ŸæˆJSONæ ¼å¼çš„åˆ†æžæŠ¥å‘Š

âš ï¸ **é‡è¦**ï¼šä½ åªéœ€è¦åˆ†æžæŒ‡å®šçš„å•ä¸ªæ–‡ä»¶ï¼Œä¸è¦åˆ†æžå…¶ä»–æ–‡ä»¶ã€‚ä¸“æ³¨äºŽè¯¥æ–‡ä»¶ä¸­çš„å…·ä½“ä¼˜åŒ–æŠ€æœ¯å®žçŽ°ã€‚

ðŸ“‹ **ä¸‰å±‚ä¼˜åŒ–ç­–ç•¥åˆ†æžæ¡†æž¶ï¼š**
è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ä¸‰ä¸ªå±‚æ¬¡åˆ†æžä»£ç ä¸­çš„ä¼˜åŒ–ç­–ç•¥ï¼š

**ðŸ”¹ ç®—æ³•è®¾è®¡å±‚æ¬¡åˆ†æžï¼š**
è¯†åˆ«è¯¥æ–‡ä»¶ä¸­çš„ç®—æ³•å±‚ä¼˜åŒ–ç­–ç•¥ï¼Œæ¯ä¸ªç­–ç•¥åŒ…å«ï¼š
- name: è§„èŒƒåŒ–ç­–ç•¥åç§°ï¼ˆå¦‚"å¤æ•°è¿ç®—å±•å¼€"ã€"åˆ†å—è®¡ç®—"ã€"é¢„è®¡ç®—ä¼˜åŒ–"ç­‰ï¼‰
- description_details: åŒ…å«4ä¸ªå­å­—æ®µçš„è¯¦ç»†åˆ†æžå¯¹è±¡
  - strategy_rationale: è§£é‡Š"ä¸ºä»€ä¹ˆ"è¦è¿™ä¹ˆåšçš„ç†è®ºåŽŸç†ï¼ˆåŸºäºŽè®¡ç®—æœºä½“ç³»ç»“æž„æˆ–ç®—æ³•ç†è®ºï¼‰
  - implementation_pattern: è§£é‡Š"æ€Žä¹ˆåš"çš„ä»£ç å®žçŽ°æ¨¡å¼ï¼ˆè¯¥ä¼˜åŒ–åœ¨ä»£ç å±‚é¢çš„å…¸åž‹è¡¨çŽ°ï¼‰
  - performance_impact: è§£é‡Š"æœ‰ä»€ä¹ˆç”¨"çš„æ€§èƒ½æå‡ï¼ˆå‡å°‘CPUå‘¨æœŸã€æé«˜ç¼“å­˜å‘½ä¸­çŽ‡ç­‰ï¼‰
  - trade_offs: è§£é‡Šè¯¥ä¼˜åŒ–çš„å±€é™æ€§æˆ–ä»£ä»·ï¼ˆå¯é€‰ï¼Œå¦‚å¢žåŠ ä»£ç å¤æ‚åº¦ã€é¢å¤–å†…å­˜å¼€é”€ç­‰ï¼‰
- code_context: åŒ…å«3ä¸ªå­å­—æ®µçš„ä»£ç ä¸Šä¸‹æ–‡å¯¹è±¡
  - snippet: åŒ…å«å¿…è¦ä¸Šä¸‹æ–‡çš„å®Œæ•´ä»£ç å—ï¼ˆä¸æ˜¯å•è¡Œï¼Œè¦èƒ½è‡ªè§£é‡Šä¼˜åŒ–æ„å›¾ï¼‰
  - highlighted_code: è¯¥ä¼˜åŒ–ç­–ç•¥çš„æ ¸å¿ƒæ‰§è¡Œè¯­å¥
  - explanation: è‡ªç„¶è¯­è¨€è§£é‡Šä»£ç å—ä¸Žä¼˜åŒ–ç­–ç•¥çš„å…³è”

**ðŸ”¹ ä»£ç ä¼˜åŒ–å±‚æ¬¡åˆ†æžï¼š**
è¯†åˆ«è¯¥æ–‡ä»¶ä¸­çš„ä»£ç å±‚ä¼˜åŒ–ç­–ç•¥ï¼Œæ¯ä¸ªç­–ç•¥åŒ…å«ï¼š
- name: è§„èŒƒåŒ–ç­–ç•¥åç§°ï¼ˆå¦‚"å¾ªçŽ¯å±•å¼€"ã€"æŒ‡é’ˆé€’å¢ž"ã€"æ¡ä»¶åˆ†æ”¯ä¼˜åŒ–"ç­‰ï¼‰
- description_details: åŒ…å«4ä¸ªå­å­—æ®µçš„è¯¦ç»†åˆ†æžå¯¹è±¡
  - strategy_rationale: è§£é‡Š"ä¸ºä»€ä¹ˆ"è¦è¿™ä¹ˆåšçš„ç†è®ºåŽŸç†
  - implementation_pattern: è§£é‡Š"æ€Žä¹ˆåš"çš„ä»£ç å®žçŽ°æ¨¡å¼
  - performance_impact: è§£é‡Š"æœ‰ä»€ä¹ˆç”¨"çš„æ€§èƒ½æå‡
  - trade_offs: è§£é‡Šè¯¥ä¼˜åŒ–çš„å±€é™æ€§æˆ–ä»£ä»·ï¼ˆå¯é€‰ï¼‰
- code_context: åŒ…å«3ä¸ªå­å­—æ®µçš„ä»£ç ä¸Šä¸‹æ–‡å¯¹è±¡
  - snippet: åŒ…å«å¿…è¦ä¸Šä¸‹æ–‡çš„å®Œæ•´ä»£ç å—
  - highlighted_code: è¯¥ä¼˜åŒ–ç­–ç•¥çš„æ ¸å¿ƒæ‰§è¡Œè¯­å¥
  - explanation: è‡ªç„¶è¯­è¨€è§£é‡Šä»£ç å—ä¸Žä¼˜åŒ–ç­–ç•¥çš„å…³è”

**ðŸ”¹ ç‰¹æœ‰æŒ‡ä»¤å±‚æ¬¡åˆ†æžï¼š**
è¯†åˆ«è¯¥æ–‡ä»¶ä¸­çš„æŒ‡ä»¤å±‚ä¼˜åŒ–ç­–ç•¥ï¼Œæ¯ä¸ªç­–ç•¥åŒ…å«ï¼š
- name: è§„èŒƒåŒ–ç­–ç•¥åç§°ï¼ˆå¦‚"SIMDå‘é‡åŒ–"ã€"è‡ªåŠ¨å‘é‡åŒ–é€‚é…"ã€"å†…è”æ±‡ç¼–"ç­‰ï¼‰
- description_details: åŒ…å«4ä¸ªå­å­—æ®µçš„è¯¦ç»†åˆ†æžå¯¹è±¡
  - strategy_rationale: è§£é‡Š"ä¸ºä»€ä¹ˆ"è¦è¿™ä¹ˆåšçš„ç†è®ºåŽŸç†
  - implementation_pattern: è§£é‡Š"æ€Žä¹ˆåš"çš„ä»£ç å®žçŽ°æ¨¡å¼
  - performance_impact: è§£é‡Š"æœ‰ä»€ä¹ˆç”¨"çš„æ€§èƒ½æå‡
  - trade_offs: è§£é‡Šè¯¥ä¼˜åŒ–çš„å±€é™æ€§æˆ–ä»£ä»·ï¼ˆå¯é€‰ï¼‰
- code_context: åŒ…å«3ä¸ªå­å­—æ®µçš„ä»£ç ä¸Šä¸‹æ–‡å¯¹è±¡
  - snippet: åŒ…å«å¿…è¦ä¸Šä¸‹æ–‡çš„å®Œæ•´ä»£ç å—ï¼ˆå¾ªçŽ¯ä½“ã€æ¡ä»¶åˆ†æ”¯ã€å˜é‡å£°æ˜Žå’Œä½¿ç”¨ç­‰ï¼‰
  - highlighted_code: è¯¥ä¼˜åŒ–ç­–ç•¥çš„æ ¸å¿ƒæ‰§è¡Œè¯­å¥
  - explanation: è‡ªç„¶è¯­è¨€è§£é‡Šä»£ç å—ä¸Žä¼˜åŒ–ç­–ç•¥çš„å…³è”

ðŸ” **åˆ†æžè¦æ±‚ï¼š**
- ä¸è¦é¢„è®¾ä»»ä½•ä¼˜åŒ–æŠ€æœ¯ç±»åž‹
- å®Œå…¨åŸºäºŽä»£ç å†…å®¹å‘çŽ°ä¼˜åŒ–ç­–ç•¥
- è§‚å¯Ÿä»£ç ä¸­å®žé™…ä½¿ç”¨çš„æŠ€æœ¯å’Œæ–¹æ³•
- åˆ†æžä»£ç çš„å®žçŽ°ç»†èŠ‚å’Œè®¾è®¡æ€è·¯

âš ï¸ **é‡è¦ï¼š**
- ä½ ä¸éœ€è¦å†³å®šä¿å­˜è·¯å¾„
- ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¾“å‡º
- å®Œå…¨åŸºäºŽä»£ç åˆ†æžï¼Œä¸è¦é¢„è®¾ä¼˜åŒ–ç±»åž‹
- ç›´æŽ¥è¾“å‡ºå®Œæ•´çš„JSONå†…å®¹

ðŸ“‹ **JSONæ ¼å¼ç¤ºä¾‹ï¼š**
```json
{{
  "algorithm_level_optimizations": [
    {{
      "name": "å¤æ•°è¿ç®—å±•å¼€",
      "description_details": {{
        "strategy_rationale": "é¿å…å¤æ•°ç»“æž„ä½“è®¿é—®å¼€é”€ï¼Œå°†å¤æ•°çš„å®žéƒ¨å’Œè™šéƒ¨è¿ç®—ç›´æŽ¥å±•å¼€ä¸ºæ ‡é‡è¿ç®—ï¼Œå‡å°‘å†…å­˜è®¿é—®å’Œç»“æž„ä½“æ“ä½œçš„å¤æ‚åº¦ã€‚",
        "implementation_pattern": "å°†å¤æ•°ä¹˜æ³• (a+bi)*(c+di) å±•å¼€ä¸ºå››ä¸ªæ ‡é‡ä¹˜æ³•å’Œä¸¤ä¸ªæ ‡é‡åŠ å‡æ³•ï¼Œç›´æŽ¥æ“ä½œå®žéƒ¨è™šéƒ¨æ•°ç»„å…ƒç´ ã€‚",
        "performance_impact": "å‡å°‘ç»“æž„ä½“è®¿é—®å¼€é”€ï¼Œæé«˜æŒ‡ä»¤çº§å¹¶è¡Œæ€§ï¼Œé™ä½Žå†…å­˜è®¿é—®å»¶è¿Ÿã€‚",
        "trade_offs": "å¢žåŠ äº†ä»£ç é•¿åº¦å’Œå¤æ‚æ€§ï¼Œå¯èƒ½å½±å“ä»£ç å¯è¯»æ€§ã€‚"
      }},
      "code_context": {{
        "snippet": "temp_r = alpha_r * x[ix] - alpha_i * x[ix+1];\\ntemp_i = alpha_r * x[ix+1] + alpha_i * x[ix];",
        "highlighted_code": "temp_r = alpha_r * x[ix] - alpha_i * x[ix+1];",
        "explanation": "è¿™é‡Œç›´æŽ¥è®¡ç®—å¤æ•°ä¹˜æ³•çš„å®žéƒ¨ï¼Œé¿å…äº†å¤æ•°ç»“æž„ä½“çš„ä½¿ç”¨ï¼Œå°†å¤æ•°è¿ç®—å±•å¼€ä¸ºä¸¤ä¸ªæ ‡é‡ä¹˜æ³•å’Œä¸€ä¸ªå‡æ³•ã€‚"
      }}
    }}
  ]
}}
```

{format_instructions}"""),
            ("human", "{input}"),
            ("placeholder", "{agent_scratchpad}")
        ])
        
        # åœ¨æç¤ºè¯ä¸­æ·»åŠ æ ¼å¼è¯´æ˜Ž
        formatted_prompt = prompt.partial(format_instructions=analyzer_parser.get_format_instructions())
        
        agent = create_openai_tools_agent(self.llm, tools, formatted_prompt)
        return AgentExecutor(agent=agent, tools=tools, verbose=False, max_iterations=15)
    
    
    def create_individual_summarizer(self) -> AgentExecutor:
        """Individual Summarizer - å•ç®—å­æ€»ç»“"""
        
        tools = [read_analysis_file]
        
        # å®šä¹‰Individual Summarizerè¾“å‡ºæ ¼å¼çš„ResponseSchemaï¼ˆå¤„ç†ç»“æž„åŒ–ä¼˜åŒ–ç­–ç•¥ï¼‰
        individual_schemas = [
            ResponseSchema(name="algorithm", description="ç®—å­åç§°"),
            ResponseSchema(name="algorithm_characteristics", description="åŸºäºŽdiscoveryæ–‡ä»¶çš„ç®—å­ç‰¹å¾å’Œæ–‡ä»¶ç±»åž‹"),
            ResponseSchema(name="algorithm_level_optimizations", description="ç®—æ³•è®¾è®¡å±‚æ¬¡æ•´åˆçš„ä¼˜åŒ–ç­–ç•¥åˆ—è¡¨ï¼Œæ¯ä¸ªç­–ç•¥åŒ…å«nameå’Œunified_descriptionå­—æ®µï¼ˆåˆå¹¶ç›¸ä¼¼ç­–ç•¥çš„ç»Ÿä¸€æè¿°ï¼‰"),
            ResponseSchema(name="code_level_optimizations", description="ä»£ç ä¼˜åŒ–å±‚æ¬¡æ•´åˆçš„ä¼˜åŒ–ç­–ç•¥åˆ—è¡¨ï¼Œæ¯ä¸ªç­–ç•¥åŒ…å«nameå’Œunified_descriptionå­—æ®µï¼ˆåˆå¹¶ç›¸ä¼¼ç­–ç•¥çš„ç»Ÿä¸€æè¿°ï¼‰"),
            ResponseSchema(name="instruction_level_optimizations", description="ç‰¹æœ‰æŒ‡ä»¤å±‚æ¬¡æ•´åˆçš„ä¼˜åŒ–ç­–ç•¥åˆ—è¡¨ï¼Œæ¯ä¸ªç­–ç•¥åŒ…å«nameå’Œunified_descriptionå­—æ®µï¼ˆåˆå¹¶ç›¸ä¼¼ç­–ç•¥çš„ç»Ÿä¸€æè¿°ï¼‰"),
            ResponseSchema(name="implementation_details", description="å…³é”®å®žçŽ°ç»†èŠ‚"),
            ResponseSchema(name="performance_insights", description="æ€§èƒ½æå‡é¢„æœŸ"),
            ResponseSchema(name="timestamp", description="æ€»ç»“æ—¶é—´æˆ³")
        ]
        individual_parser = StructuredOutputParser.from_response_schemas(individual_schemas)
        
        prompt = ChatPromptTemplate.from_messages([
            ("system", """ä½ æ˜¯å•ç®—å­å¢žé‡æ•´åˆä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯å°†æ–°çš„åˆ†æžç»“æžœæ•´åˆåˆ°å·²æœ‰çš„ä¼˜åŒ–ç­–ç•¥ä¸­ã€‚

ðŸŽ¯ **ä½ çš„èŒè´£ï¼š**
1. è¯»å–discoveryæ–‡ä»¶äº†è§£ç®—å­ç‰¹å¾
2. è¯»å–analysisæ–‡ä»¶èŽ·å–ç»“æž„åŒ–åˆ†æžç»“æžœ
3. å¦‚æžœå·²æœ‰summaryæ–‡ä»¶ï¼Œå…ˆè¯»å–å·²æœ‰çš„ä¼˜åŒ–ç­–ç•¥
4. å°†æ–°çš„ä¼˜åŒ–ç­–ç•¥ä¸Žå·²æœ‰ç­–ç•¥è¿›è¡Œå¯¹æ¯”å’Œæ•´åˆ
5. ç”Ÿæˆæ›´æ–°åŽçš„JSONæ ¼å¼æ€»ç»“æŠ¥å‘Š

ðŸ“‹ **ç»“æž„åŒ–ç­–ç•¥å¤„ç†ï¼š**
**ðŸ”¹ è¾“å…¥æ ¼å¼ç†è§£ï¼š**
- analysisæ–‡ä»¶ä¸­æ¯ä¸ªä¼˜åŒ–ç­–ç•¥åŒ…å«ï¼š
  - name: ç­–ç•¥åç§°
  - description_details: è¯¦ç»†æè¿°å¯¹è±¡ï¼ˆåŒ…å«strategy_rationaleã€implementation_patternã€performance_impactã€trade_offsï¼‰
  - code_context: ä»£ç ä¸Šä¸‹æ–‡å¯¹è±¡ï¼ˆåŒ…å«snippetã€highlighted_codeã€explanationï¼‰

**ðŸ”¹ æ•´åˆè¾“å‡ºæ ¼å¼ï¼š**
- æ•´åˆåŽçš„ç­–ç•¥åªåŒ…å«ï¼š
  - name: ç»Ÿä¸€çš„ç­–ç•¥åç§°
  - unified_description: åˆå¹¶å¤šä¸ªç›¸ä¼¼ç­–ç•¥åŽçš„ç»Ÿä¸€æè¿°ï¼ˆç»¼åˆå¤šä¸ªdescription_detailsçš„æ ¸å¿ƒå†…å®¹ï¼‰

**ðŸ”¹ ç­–ç•¥åˆå¹¶è§„åˆ™ï¼š**
- å¦‚æžœæ–°ç­–ç•¥ä¸Žå·²æœ‰ç­–ç•¥ç›¸ä¼¼ï¼Œåˆå¹¶ä¸ºç»Ÿä¸€å‘½åçš„ç­–ç•¥
- åˆå¹¶æ—¶æå–å¤šä¸ªdescription_detailsçš„æ ¸å¿ƒè¦ç‚¹ï¼Œå½¢æˆç»Ÿä¸€æè¿°
- å¦‚æžœæ–°ç­–ç•¥æ˜¯å…¨æ–°çš„ï¼Œç›´æŽ¥æ·»åŠ åˆ°ç­–ç•¥åˆ—è¡¨ä¸­
- ä¿æŒç­–ç•¥åç§°çš„è§„èŒƒåŒ–å’Œä¸€è‡´æ€§

**ðŸ”¹ ä¸‰å±‚ä¼˜åŒ–ç­–ç•¥æ•´åˆï¼š**
- **ç®—æ³•è®¾è®¡å±‚æ¬¡**ï¼šæ•´åˆè®¡ç®—é€»è¾‘ã€åˆ†å—ã€é¢„è®¡ç®—ç­‰ç­–ç•¥
- **ä»£ç ä¼˜åŒ–å±‚æ¬¡**ï¼šæ•´åˆå¾ªçŽ¯å±•å¼€ã€æŒ‡é’ˆä¼˜åŒ–ã€åˆ†æ”¯ä¼˜åŒ–ç­‰ç­–ç•¥  
- **ç‰¹æœ‰æŒ‡ä»¤å±‚æ¬¡**ï¼šæ•´åˆSIMDã€å‘é‡åŒ–ã€å†…è”æ±‡ç¼–ç­‰ç­–ç•¥

ðŸ” **æ•´åˆè¦æ±‚ï¼š**
- å¯¹ç›¸è¿‘ç­–ç•¥è¿›è¡Œåç§°å¯¹é½ï¼ˆå¦‚"æŒ‡é’ˆé€’å¢žä¼˜åŒ–"ç»Ÿä¸€ä¸º"æŒ‡é’ˆé€’å¢ž"ï¼‰
- åˆå¹¶ç›¸ä¼¼ç­–ç•¥çš„æè¿°ï¼Œå½¢æˆé€šç”¨æè¿°
- ä¿æŒç­–ç•¥åˆ—è¡¨çš„ç®€æ´æ€§ï¼Œé¿å…é‡å¤

âš ï¸ **é‡è¦ï¼š**
- æ”¯æŒå¢žé‡æ•´åˆï¼Œæ¯æ¬¡å¯èƒ½åªå¤„ç†éƒ¨åˆ†æ–‡ä»¶çš„åˆ†æžç»“æžœ
- ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¾“å‡º
- é‡ç‚¹å…³æ³¨ä¸‰ç§ç±»åž‹çš„ä¼˜åŒ–ç­–ç•¥æå–å’Œåˆå¹¶

{format_instructions}"""),
            ("human", "{input}"),
            ("placeholder", "{agent_scratchpad}")
        ])
        
        # åœ¨æç¤ºè¯ä¸­æ·»åŠ æ ¼å¼è¯´æ˜Ž
        formatted_prompt = prompt.partial(format_instructions=individual_parser.get_format_instructions())
        
        agent = create_openai_tools_agent(self.llm, tools, formatted_prompt)
        return AgentExecutor(agent=agent, tools=tools, verbose=False, max_iterations=15)
    
    def create_final_summarizer(self) -> AgentExecutor:
        """Final Summarizer - è·¨ç®—å­æ€»ç»“"""
        
        tools = [read_analysis_file]
        
        # å®šä¹‰Final Summarizerè¾“å‡ºæ ¼å¼çš„ResponseSchemaï¼ˆè·¨ç®—å­ä¼˜åŒ–ç­–ç•¥åº“ï¼‰
        final_schemas = [
            ResponseSchema(name="analyzed_algorithms", description="åˆ†æžçš„ç®—å­åˆ—è¡¨"),
            ResponseSchema(name="algorithm_level_optimizations", description="ç®—æ³•è®¾è®¡å±‚æ¬¡çš„OpenBLASä¼˜åŒ–ç­–ç•¥åº“ï¼Œæç‚¼è·¨ç®—å­çš„ç›¸è¿‘ç­–ç•¥å¹¶ç»Ÿä¸€å‘½åï¼Œæ¯ä¸ªç­–ç•¥åŒ…å«nameå’Œuniversal_descriptionå­—æ®µï¼ˆé€šç”¨æè¿°å’Œåº”ç”¨åœºæ™¯ï¼‰"),
            ResponseSchema(name="code_level_optimizations", description="ä»£ç ä¼˜åŒ–å±‚æ¬¡çš„OpenBLASä¼˜åŒ–ç­–ç•¥åº“ï¼Œæç‚¼è·¨ç®—å­çš„ç›¸è¿‘ç­–ç•¥å¹¶ç»Ÿä¸€å‘½åï¼Œæ¯ä¸ªç­–ç•¥åŒ…å«nameå’Œuniversal_descriptionå­—æ®µï¼ˆé€šç”¨æè¿°å’Œåº”ç”¨åœºæ™¯ï¼‰"),
            ResponseSchema(name="instruction_level_optimizations", description="ç‰¹æœ‰æŒ‡ä»¤å±‚æ¬¡çš„OpenBLASä¼˜åŒ–ç­–ç•¥åº“ï¼Œæç‚¼è·¨ç®—å­çš„ç›¸è¿‘ç­–ç•¥å¹¶ç»Ÿä¸€å‘½åï¼Œæ¯ä¸ªç­–ç•¥åŒ…å«nameå’Œuniversal_descriptionå­—æ®µï¼ˆé€šç”¨æè¿°å’Œåº”ç”¨åœºæ™¯ï¼‰"),
            ResponseSchema(name="cross_algorithm_insights", description="è·¨ç®—å­ä¼˜åŒ–æ´žå¯Ÿ"),
            ResponseSchema(name="best_practices", description="æœ€ä½³å®žè·µå»ºè®®"),
            ResponseSchema(name="timestamp", description="æ€»ç»“æ—¶é—´æˆ³")
        ]
        final_parser = StructuredOutputParser.from_response_schemas(final_schemas)
        
        prompt = ChatPromptTemplate.from_messages([
            ("system", """ä½ æ˜¯è·¨ç®—å­æ€»ç»“ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯å‘çŽ°å¤šä¸ªç®—å­çš„é€šç”¨ä¼˜åŒ–è§„å¾‹ï¼Œç”ŸæˆJSONæ ¼å¼çš„æœ€ç»ˆæ€»ç»“ã€‚

ðŸŽ¯ **ä½ çš„èŒè´£ï¼š**
1. è¯»å–æ‰€æœ‰ç®—å­çš„summaryæ–‡ä»¶
2. åŸºäºŽä¸‰å±‚ä¼˜åŒ–ç­–ç•¥æ¡†æž¶è¯†åˆ«é€šç”¨ä¼˜åŒ–æ¨¡å¼
3. ç”ŸæˆJSONæ ¼å¼çš„æœ€ç»ˆä¼˜åŒ–ç­–ç•¥åº“

ðŸ“‹ **è¾“å…¥æ ¼å¼ç†è§£ï¼š**
**ðŸ”¹ Individual Summaryæ ¼å¼ï¼š**
- æ¯ä¸ªç®—å­çš„summaryæ–‡ä»¶åŒ…å«å·²æ•´åˆçš„ä¼˜åŒ–ç­–ç•¥
- æ¯ä¸ªç­–ç•¥åŒ…å«ï¼šnameï¼ˆç»Ÿä¸€åç§°ï¼‰å’Œunified_descriptionï¼ˆç»Ÿä¸€æè¿°ï¼‰

**ðŸ”¹ è·¨ç®—å­æ•´åˆç›®æ ‡ï¼š**
- è¾“å‡ºæ ¼å¼ï¼šnameï¼ˆé€šç”¨ç­–ç•¥åç§°ï¼‰å’Œuniversal_descriptionï¼ˆé€šç”¨æè¿°å’Œåº”ç”¨åœºæ™¯ï¼‰
- è¯†åˆ«åœ¨å¤šä¸ªç®—å­ä¸­éƒ½å‡ºçŽ°çš„ä¼˜åŒ–æ¨¡å¼
- æç‚¼å‡ºé€‚ç”¨äºŽæ•´ä¸ªOpenBLASåº“çš„é€šç”¨ä¼˜åŒ–ç­–ç•¥

ðŸ“‹ **ä¸‰å±‚ä¼˜åŒ–ç­–ç•¥æ¡†æž¶åˆ†æžï¼š**
è¯·æŒ‰ç…§ä»¥ä¸‹ä¸‰ä¸ªå±‚æ¬¡åˆ†æžè·¨ç®—å­çš„ä¼˜åŒ–è§„å¾‹ï¼š

**ðŸ”¹ ç®—æ³•è®¾è®¡å±‚æ¬¡è·¨ç®—å­åˆ†æžï¼š**
- åˆ†æžå„ç®—å­åœ¨è®¡ç®—é€»è¾‘ä¼˜åŒ–ä¸Šçš„å…±æ€§å’Œå·®å¼‚
- è¯†åˆ«è·¨ç®—å­çš„é€šç”¨ç®—æ³•ä¼˜åŒ–æ¨¡å¼ï¼ˆå¦‚åˆ†å—ã€é¢„è®¡ç®—ã€æ•°æ®é‡ç”¨ç­‰ï¼‰
- æ€»ç»“ç©ºé—´æ¢æ—¶é—´å’Œæ—¶é—´æ¢ç©ºé—´ä¼˜åŒ–çš„é€šç”¨è§„å¾‹

**ðŸ”¹ ä»£ç ä¼˜åŒ–å±‚æ¬¡è·¨ç®—å­åˆ†æžï¼š**  
- åˆ†æžå„ç®—å­åœ¨æ€§èƒ½åŠ é€Ÿä¼˜åŒ–ä¸Šçš„å…±æ€§å’Œå·®å¼‚
- è¯†åˆ«è·¨ç®—å­çš„é€šç”¨ä»£ç ä¼˜åŒ–æ¨¡å¼ï¼ˆå¦‚å¾ªçŽ¯å±•å¼€ã€æŒ‡é’ˆä¼˜åŒ–ã€åˆ†æ”¯ä¼˜åŒ–ç­‰ï¼‰
- æ€»ç»“ä»£ç ç»“æž„è°ƒæ•´çš„é€šç”¨ä¼˜åŒ–ç­–ç•¥

**ðŸ”¹ ç‰¹æœ‰æŒ‡ä»¤å±‚æ¬¡è·¨ç®—å­åˆ†æžï¼š**
- åˆ†æžå„ç®—å­åœ¨ä¸“æœ‰æŒ‡ä»¤ä½¿ç”¨ä¸Šçš„å…±æ€§å’Œå·®å¼‚
- è¯†åˆ«è·¨ç®—å­çš„é€šç”¨æŒ‡ä»¤çº§ä¼˜åŒ–æ¨¡å¼ï¼ˆå¦‚SIMDã€å‘é‡åŒ–ã€å†…è”æ±‡ç¼–ç­‰ï¼‰
- æ€»ç»“å›´ç»•ç¡¬ä»¶ç‰¹æ€§çš„é€šç”¨ä¼˜åŒ–è®¾è®¡æ¨¡å¼

âš ï¸ **é‡è¦ï¼š**
- åŸºäºŽä¸‰å±‚ä¼˜åŒ–ç­–ç•¥æ¡†æž¶è¿›è¡Œè·¨ç®—å­åˆ†æž
- ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¾“å‡º
- é‡ç‚¹å…³æ³¨ä¸‰ç§ç±»åž‹çš„ä¼˜åŒ–ç­–ç•¥çš„é€šç”¨æ¨¡å¼æå–

{format_instructions}"""),
            ("human", "{input}"),
            ("placeholder", "{agent_scratchpad}")
        ])
        
        # åœ¨æç¤ºè¯ä¸­æ·»åŠ æ ¼å¼è¯´æ˜Ž
        formatted_prompt = prompt.partial(format_instructions=final_parser.get_format_instructions())
        
        agent = create_openai_tools_agent(self.llm, tools, formatted_prompt)
        return AgentExecutor(agent=agent, tools=tools, verbose=False, max_iterations=20)


# ===== æ–‡ä»¶ç®¡ç†å™¨ =====
class FileManager:
    """æ–‡ä»¶ç®¡ç†å™¨"""
    
    @staticmethod
    def ensure_directories(report_folder: str):
        """åˆ›å»ºæ‰€æœ‰å¿…è¦çš„ç›®å½•"""
        Path(report_folder).mkdir(parents=True, exist_ok=True)
        Path(f"{report_folder}/discovery_results").mkdir(exist_ok=True)
        Path(f"{report_folder}/analysis_results").mkdir(exist_ok=True)
        Path(f"{report_folder}/strategy_reports").mkdir(exist_ok=True)
    
    @staticmethod
    def get_discovery_output_path(report_folder: str, algorithm: str) -> str:
        """èŽ·å–discoveryè¾“å‡ºè·¯å¾„"""
        return f"{report_folder}/discovery_results/{algorithm}_discovery.json"
    
    @staticmethod
    def get_analysis_output_path(report_folder: str, algorithm: str) -> str:
        """èŽ·å–analysisè¾“å‡ºè·¯å¾„"""
        return f"{report_folder}/analysis_results/{algorithm}_analysis.json"
    
    
    @staticmethod
    def get_individual_summary_path(report_folder: str, algorithm: str) -> str:
        """èŽ·å–individual summaryè¾“å‡ºè·¯å¾„"""
        return f"{report_folder}/strategy_reports/{algorithm}_summary.json"
    
    @staticmethod
    def get_final_summary_path(report_folder: str) -> str:
        """èŽ·å–final summaryè¾“å‡ºè·¯å¾„"""
        return f"{report_folder}/strategy_reports/final_optimization_summary.json"
    
    @staticmethod
    def save_content(file_path: str, content: str) -> bool:
        """ä¿å­˜å†…å®¹åˆ°æ–‡ä»¶"""
        try:
            Path(file_path).parent.mkdir(parents=True, exist_ok=True)
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(content)
            return True
        except Exception as e:
            print(f"ä¿å­˜æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            return False
    
    @staticmethod
    def load_config() -> dict:
        """åŠ è½½config.json"""
        with open("config.json", "r", encoding="utf-8") as f:
            return json.load(f)
    


# ===== å¯¼å‡º =====
__all__ = [
    'AgentFactory',
    'FileManager',
    'AnalysisTask'
]

